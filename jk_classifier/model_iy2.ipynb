{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea -> \n",
    "\n",
    "murmur \n",
    "\n",
    "학습 라벨\n",
    "murmur 0 1 \n",
    "unknown 0.5 0.5\n",
    "absent 1 0\n",
    "murmur 다른거 0.5 0.5\n",
    "\n",
    "합칠 때: \n",
    "murmur 가 가장 높은 확률인 벡터 뽑기\n",
    "murmur 확률 과 0, 0.5, 1 과의 거리의 역수를 합이 1이 되게 표준화시켜 점수만들기\n",
    "\n",
    "학습라벨\n",
    "- normal 1 0\n",
    "- abnormal \n",
    "present 0.1 0.9\n",
    "unknown 0.15 0.85\n",
    "absent 0.2 0.8\n",
    "합칠 때: 평균\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/ikwak2/hmd/notebooks')\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/iy_classifier')\n",
    "sys.path.insert(0,'/home/ikwak2/hmd/notebooks/utils')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "from get_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3'\n",
    "training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "Fri Jul  1 23:12:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 35%   33C    P8    13W / 260W |    286MiB / 11011MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       992      G   /usr/lib/xorg/Xorg                 18MiB |\n",
      "|    0   N/A  N/A      1110      G   /usr/bin/gnome-shell               72MiB |\n",
      "|    0   N/A  N/A      1352      G   /usr/lib/xorg/Xorg                146MiB |\n",
      "|    0   N/A  N/A      1472      G   /usr/bin/gnome-shell               27MiB |\n",
      "|    0   N/A  N/A      2063      G   /usr/lib/firefox/firefox           12MiB |\n",
      "|    0   N/A  N/A      2416      G   gnome-control-center                3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Recording locations:</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>Murmur locations</th>\n",
       "      <th>Most audible location</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic murmur pitch</th>\n",
       "      <th>Systolic murmur quality</th>\n",
       "      <th>Diastolic murmur timing</th>\n",
       "      <th>Diastolic murmur shape</th>\n",
       "      <th>Diastolic murmur grading</th>\n",
       "      <th>Diastolic murmur pitch</th>\n",
       "      <th>Diastolic murmur quality</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Additional ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9983</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>115.0</td>\n",
       "      <td>19.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13918</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14241</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>PV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14998</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23625</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>50379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24160</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>17.66</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29045</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29378</td>\n",
       "      <td>AV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID Recording locations:    Age     Sex  Height  Weight  \\\n",
       "0        2530          AV+PV+TV+MV  Child  Female    98.0   15.90   \n",
       "1        9979          AV+PV+TV+MV  Child  Female   103.0   13.10   \n",
       "2        9983          AV+PV+TV+MV  Child    Male   115.0   19.10   \n",
       "3       13918          AV+PV+TV+MV  Child    Male    98.0   15.90   \n",
       "4       14241          AV+PV+TV+MV  Child    Male    87.0   11.20   \n",
       "5       14998          AV+PV+TV+MV  Child    Male     NaN     NaN   \n",
       "6       23625          AV+PV+TV+MV  Child  Female    92.0   14.00   \n",
       "7       24160          AV+PV+TV+MV  Child  Female    98.0   17.66   \n",
       "8       29045          AV+PV+TV+MV  Child  Female    88.0   12.50   \n",
       "9       29378                AV+MV  Child  Female    82.0   10.70   \n",
       "\n",
       "   Pregnancy status   Murmur Murmur locations Most audible location  ...  \\\n",
       "0             False   Absent              NaN                   NaN  ...   \n",
       "1             False  Present      AV+MV+PV+TV                    TV  ...   \n",
       "2             False  Unknown              NaN                   NaN  ...   \n",
       "3             False  Present               TV                    TV  ...   \n",
       "4             False  Present      AV+MV+PV+TV                    PV  ...   \n",
       "5             False   Absent              NaN                   NaN  ...   \n",
       "6             False   Absent              NaN                   NaN  ...   \n",
       "7             False   Absent              NaN                   NaN  ...   \n",
       "8             False  Present      AV+MV+PV+TV                    TV  ...   \n",
       "9             False  Unknown              NaN                   NaN  ...   \n",
       "\n",
       "  Systolic murmur pitch Systolic murmur quality Diastolic murmur timing  \\\n",
       "0                   NaN                     NaN                     NaN   \n",
       "1                  High                   Harsh                     NaN   \n",
       "2                   NaN                     NaN                     NaN   \n",
       "3                   Low                 Blowing                     NaN   \n",
       "4                   Low                   Harsh                     NaN   \n",
       "5                   NaN                     NaN                     NaN   \n",
       "6                   NaN                     NaN                     NaN   \n",
       "7                   NaN                     NaN                     NaN   \n",
       "8                   Low                 Blowing                     NaN   \n",
       "9                   NaN                     NaN                     NaN   \n",
       "\n",
       "  Diastolic murmur shape Diastolic murmur grading Diastolic murmur pitch  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    NaN   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    NaN   \n",
       "5                    NaN                      NaN                    NaN   \n",
       "6                    NaN                      NaN                    NaN   \n",
       "7                    NaN                      NaN                    NaN   \n",
       "8                    NaN                      NaN                    NaN   \n",
       "9                    NaN                      NaN                    NaN   \n",
       "\n",
       "  Diastolic murmur quality   Outcome Campaign Additional ID  \n",
       "0                      NaN  Abnormal   CC2015           NaN  \n",
       "1                      NaN  Abnormal   CC2015           NaN  \n",
       "2                      NaN  Abnormal   CC2015           NaN  \n",
       "3                      NaN  Abnormal   CC2015           NaN  \n",
       "4                      NaN  Abnormal   CC2015           NaN  \n",
       "5                      NaN  Abnormal   CC2015           NaN  \n",
       "6                      NaN  Abnormal   CC2015       50379.0  \n",
       "7                      NaN  Abnormal   CC2015           NaN  \n",
       "8                      NaN  Abnormal   CC2015           NaN  \n",
       "9                      NaN  Abnormal   CC2015           NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(training_data_file)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =  '/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3/training_data'\n",
    "train_folder =  '/home/ubuntu/data/hmd/murmur/train'\n",
    "test_folder = '/home/ubuntu/data/hmd/murmur/test'\n",
    "model_folder = 'tmp_model2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3/training_data'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(data_folder)\n",
    "patient_files_trn = find_patient_files(train_folder)\n",
    "patient_files_test = find_patient_files(test_folder)\n",
    "\n",
    "num_patient_files = len(patient_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46778 1 4000\r\n",
      "MV 46778_MV.hea 46778_MV.wav 46778_MV.tsv\r\n",
      "#Age: Adolescent\r\n",
      "#Sex: Female\r\n",
      "#Height: 150.0\r\n",
      "#Weight: 54.7\r\n",
      "#Pregnancy status: False\r\n",
      "#Murmur: Present\r\n",
      "#Murmur locations: MV\r\n",
      "#Most audible location: MV\r\n",
      "#Systolic murmur timing: Holosystolic\r\n",
      "#Systolic murmur shape: Plateau\r\n",
      "#Systolic murmur grading: I/VI\r\n",
      "#Systolic murmur pitch: Low\r\n",
      "#Systolic murmur quality: Harsh\r\n",
      "#Diastolic murmur timing: Early-diastolic\r\n",
      "#Diastolic murmur shape: Decrescendo\r\n",
      "#Diastolic murmur grading: I/IV\r\n",
      "#Diastolic murmur pitch: Low\r\n",
      "#Diastolic murmur quality: Blowing\r\n",
      "#Outcome: Abnormal\r\n",
      "#Campaign: CC2015\r\n",
      "#Additional ID: 49754\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/ubuntu/data/hmd/murmur/train/46778.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46532 1 4000\r\n",
      "AV 46532_AV.hea 46532_AV.wav 46532_AV.tsv\r\n",
      "#Age: Child\r\n",
      "#Sex: Female\r\n",
      "#Height: 70.0\r\n",
      "#Weight: 9.0\r\n",
      "#Pregnancy status: False\r\n",
      "#Murmur: Absent\r\n",
      "#Murmur locations: nan\r\n",
      "#Most audible location: nan\r\n",
      "#Systolic murmur timing: nan\r\n",
      "#Systolic murmur shape: nan\r\n",
      "#Systolic murmur grading: nan\r\n",
      "#Systolic murmur pitch: nan\r\n",
      "#Systolic murmur quality: nan\r\n",
      "#Diastolic murmur timing: nan\r\n",
      "#Diastolic murmur shape: nan\r\n",
      "#Diastolic murmur grading: nan\r\n",
      "#Diastolic murmur pitch: nan\r\n",
      "#Diastolic murmur quality: nan\r\n",
      "#Outcome: Normal\r\n",
      "#Campaign: CC2015\r\n",
      "#Additional ID: nan\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/ubuntu/data/hmd/murmur/train/46532.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Normal', 'Abnormal']\n",
    "num_mm_classes = len(murmur_classes)\n",
    "num_o_classes = len(outcome_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    for i in range(num_patient_files):\n",
    "\n",
    "i = 1\n",
    "\n",
    "current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "num_locations = get_num_locations(current_patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "num_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV 9979_AV.hea 9979_AV.wav 9979_AV.tsv',\n",
       " 'PV 9979_PV.hea 9979_PV.wav 9979_PV.tsv',\n",
       " 'TV 9979_TV.hea 9979_TV.wav 9979_TV.tsv',\n",
       " 'MV 9979_MV.hea 9979_MV.wav 9979_MV.tsv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9979 4 4000\\nAV 9979_AV.hea 9979_AV.wav 9979_AV.tsv\\nPV 9979_PV.hea 9979_PV.wav 9979_PV.tsv\\nTV 9979_TV.hea 9979_TV.wav 9979_TV.tsv\\nMV 9979_MV.hea 9979_MV.wav 9979_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 103.0\\n#Weight: 13.1\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Diamond\\n#Systolic murmur grading: III/VI\\n#Systolic murmur pitch: High\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        for j in range(num_locations) :\n",
    "j = 0\n",
    "entries = recording_information[j].split(' ')\n",
    "recording_file = entries[2]\n",
    "filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "# Extract id\n",
    "id1 = recording_file.split('_')[0]\n",
    "features['id'].append(id1)\n",
    "\n",
    "# Extract melspec\n",
    "mel1 = feature_extract_melspec(filename)[0]\n",
    "features['mel1'].append(mel1)\n",
    "\n",
    "# Extract age_group\n",
    "age_group = get_age(current_patient_data)\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1\n",
    "features['age'].append(current_age_group)\n",
    "\n",
    "# Extract sex\n",
    "sex = get_sex(current_patient_data)\n",
    "sex_features = np.zeros(2, dtype=int)\n",
    "if compare_strings(sex, 'Female'):\n",
    "    sex_features[0] = 1\n",
    "elif compare_strings(sex, 'Male'):\n",
    "    sex_features[1] = 1\n",
    "features['sex'].append(sex_features)\n",
    "\n",
    "# Extract height and weight.\n",
    "height = get_height(current_patient_data)\n",
    "weight = get_weight(current_patient_data)\n",
    "features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "# Extract pregnancy\n",
    "is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "features['preg'].append(is_pregnant)\n",
    "\n",
    "# Extract location\n",
    "locations = entries[0]\n",
    "num_recording_locations = len(recording_locations)\n",
    "loc_features = np.zeros(num_recording_locations)\n",
    "if locations in recording_locations:\n",
    "    j = recording_locations.index(locations)\n",
    "    loc_features[j] = 1\n",
    "features['loc'].append(loc_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_murmur_loc(data):\n",
    "    murmur_loc = 0\n",
    "    for l in data.split('\\n'):\n",
    "        if l.startswith('#Murmur locations: '):\n",
    "            try:\n",
    "                murmur_loc = l.split(': ')[1]\n",
    "#                murmur_loc = murmur_loc.split('+')\n",
    "            except:\n",
    "                pass\n",
    "    return murmur_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = get_murmur_loc(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV+MV+PV+TV'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9979 4 4000',\n",
       " 'AV 9979_AV.hea 9979_AV.wav 9979_AV.tsv',\n",
       " 'PV 9979_PV.hea 9979_PV.wav 9979_PV.tsv',\n",
       " 'TV 9979_TV.hea 9979_TV.wav 9979_TV.tsv',\n",
       " 'MV 9979_MV.hea 9979_MV.wav 9979_MV.tsv',\n",
       " '#Age: Child',\n",
       " '#Sex: Female',\n",
       " '#Height: 103.0',\n",
       " '#Weight: 13.1',\n",
       " '#Pregnancy status: False',\n",
       " '#Murmur: Present',\n",
       " '#Murmur locations: AV+MV+PV+TV',\n",
       " '#Most audible location: TV',\n",
       " '#Systolic murmur timing: Holosystolic',\n",
       " '#Systolic murmur shape: Diamond',\n",
       " '#Systolic murmur grading: III/VI',\n",
       " '#Systolic murmur pitch: High',\n",
       " '#Systolic murmur quality: Harsh',\n",
       " '#Diastolic murmur timing: nan',\n",
       " '#Diastolic murmur shape: nan',\n",
       " '#Diastolic murmur grading: nan',\n",
       " '#Diastolic murmur pitch: nan',\n",
       " '#Diastolic murmur quality: nan',\n",
       " '#Outcome: Abnormal',\n",
       " '#Campaign: CC2015',\n",
       " '#Additional ID: nan',\n",
       " '']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', 'MV', 'PV', 'TV', 'PhC']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_label = get_murmur(current_patient_data)\n",
    "out_label = get_outcome(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mm_labels = np.zeros(2)\n",
    "current_out_labels = np.zeros(2)\n",
    "if mm_label == 'Absent' :\n",
    "    current_mm_labels = np.array([1, 0])\n",
    "elif mm_label == 'unknown' :\n",
    "    current_mm_labels = np.array([1, 0])\n",
    "else :\n",
    "    mm_loc = get_murmur_loc(current_patient_data)\n",
    "    if mm_loc == 'nan' :\n",
    "        current_mm_labels = np.array([0.2, 0.8])\n",
    "    else :\n",
    "        mm_loc = mm_loc.split('+')\n",
    "        if location in mm_loc :\n",
    "            current_mm_labels = np.array([0, 1])\n",
    "        else :\n",
    "            current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "if out_label == 'Abnormal' :\n",
    "    current_out_labels = np.array([1, 0])\n",
    "else :\n",
    "    current_out_labels = np.array([0, 1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abnormal'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absent'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_label = get_murmur(current_patient_data)\n",
    "out_label = get_outcome(current_patient_data)\n",
    "mm_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = recording_locations.index(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_loc = get_murmur_loc(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_loc = mm_loc.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', 'MV', 'PV', 'TV']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_labels = np.zeros(2)\n",
    "label = get_label(current_patient_data)\n",
    "if label in classes:\n",
    "    j = classes.index(label)\n",
    "    current_labels[j] = 1\n",
    "labels.append(current_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mm_labels = np.zeros((num_patient_files,2))\n",
    "    out_labels = np.zeros((num_patient_files,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "#    mm_labels = np.zeros((num_patient_files,2))\n",
    "#    out_labels = np.zeros((num_patient_files,2))\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "#            current_labels = np.zeros(2)\n",
    "#            label = get_label(current_patient_data)\n",
    "#            if label in classes:\n",
    "#                j = classes.index(label)\n",
    "#                current_labels[j] = 1\n",
    "#            labels.append(current_labels)\n",
    "            mm_label = get_murmur(current_patient_data)\n",
    "            out_label = get_outcome(current_patient_data)\n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.2, 0.8])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if location in mm_loc :\n",
    "                        current_mm_labels = np.array([0, 1])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "            if out_label == 'Abnormal' :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "            else :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features, mm_labels, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', '9979_AV.hea', '9979_AV.wav', '9979_AV.tsv']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "#    labels = []\n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "            mm_label = get_murmur(current_patient_data)\n",
    "            out_label = get_outcome(current_patient_data)\n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.2, 0.8])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if locations in mm_loc :\n",
    "                        current_mm_labels = np.array([0, 1])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "            if out_label == 'Normal' :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "            else :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    mm_labels = np.array(mm_labels)\n",
    "    out_labels = np.array(out_labels)\n",
    "    return features, mm_labels, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_3lb(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "#    labels = []\n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "            mm_label = get_murmur(current_patient_data)\n",
    "            out_label = get_outcome(current_patient_data)\n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([1, 0, 0])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([0, 1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.05, 0.15, 0.8])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if locations in mm_loc :\n",
    "                        current_mm_labels = np.array([0, 0, 1])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.2, 0.3, 0.5])\n",
    "\n",
    "            if out_label == 'Normal' :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "            else :\n",
    "                if mm_label == 'Absent' :\n",
    "                    current_out_labels = np.array([0.2, 0.8])\n",
    "                elif mm_label == 'unknown' :\n",
    "                    current_out_labels = np.array([0.15, 0.85])\n",
    "                else :\n",
    "                    current_out_labels = np.array([0.05, 0.95])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    mm_labels = np.array(mm_labels)\n",
    "    out_labels = np.array(out_labels)\n",
    "    return features, mm_labels, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_wo_labels(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = get_features_3lb(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = get_features_3lb(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = np.random.permutation(942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = patient_files[:800]\n",
    "patient_files_test = patient_files[800:]\n",
    "num_patient_files = len(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "classes = ['Present', 'Unknown', 'Absent']\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels and use one-hot encoding.\n",
    "            current_labels = np.zeros(num_classes, dtype=int)\n",
    "            label = get_label(current_patient_data)\n",
    "            if label in classes:\n",
    "                j = classes.index(label)\n",
    "                current_labels[j] = 1\n",
    "            labels.append(current_labels)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_wo_labels(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = get_features(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2532"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_trn[0]['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = get_features(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_test[0]['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[2][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "current_patient_data = load_patient_data(patient_files_trn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recordings. wav data recording\n",
    "def load_recordings(data_folder, data, get_frequencies=False):\n",
    "    num_locations = get_num_locations(data)\n",
    "    recording_information = data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    recordings = list()\n",
    "    frequencies = list()\n",
    "    for i in range(num_locations):\n",
    "        entries = recording_information[i].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        recording, frequency = load_wav_file(filename)\n",
    "        recordings.append(recording)\n",
    "        frequencies.append(frequency)\n",
    "\n",
    "    if get_frequencies:\n",
    "        return recordings, frequencies\n",
    "    else:\n",
    "        return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(current_patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv', 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv', 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv', 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']\n"
     ]
    }
   ],
   "source": [
    "print(num_locations, recording_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv',\n",
       " 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv',\n",
       " 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv',\n",
       " 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', '2530_AV.hea', '2530_AV.wav', '2530_AV.tsv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = recording_information[i].split(' ')\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_file = entries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530_AV.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/2530_AV.wav'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(data_folder, recording_file)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = recording_file.split('_')[0]\n",
    "features['id'].append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1 = feature_extract_melspec(filename)[0]\n",
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mel1'].append(mel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['2530'],\n",
       " 'age': [],\n",
       " 'sex': [],\n",
       " 'hw': [],\n",
       " 'preg': [],\n",
       " 'loc': [],\n",
       " 'mel1': [array([[-14.24342  , -14.460995 , -12.48743  , ...,  -8.350793 ,\n",
       "           -9.550913 ,  -6.6099434],\n",
       "         [ -8.833427 , -11.78526  , -10.376642 , ..., -10.638776 ,\n",
       "          -14.766047 ,  -2.595482 ],\n",
       "         [ -7.201795 , -11.942595 , -14.396763 , ..., -13.780443 ,\n",
       "          -11.831632 , -10.3140745],\n",
       "         ...,\n",
       "         [-43.652073 , -60.107727 , -58.363945 , ..., -46.318718 ,\n",
       "          -47.93747  , -47.206367 ],\n",
       "         [-42.097    , -59.548874 , -57.106033 , ..., -45.140682 ,\n",
       "          -53.84076  , -53.963337 ],\n",
       "         [-42.240356 , -60.107727 , -60.107727 , ..., -51.811592 ,\n",
       "          -55.905552 , -57.170105 ]], dtype=float32)]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_age = ['Child']\n",
    "age_group = get_age(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = get_age(current_patient_data)\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = 'ddd'\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['age'].append(current_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sex. Use one-hot encoding.\n",
    "sex = get_sex(current_patient_data)\n",
    "sex_features = np.zeros(2, dtype=int)\n",
    "if compare_strings(sex, 'Female'):\n",
    "    sex_features[0] = 1\n",
    "elif compare_strings(sex, 'Male'):\n",
    "    sex_features[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['sex'].append(sex_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract height and weight.\n",
    "height = get_height(current_patient_data)\n",
    "weight = get_weight(current_patient_data)\n",
    "features['hw'].append(np.array([height, weight]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "features['preg'].append(is_pregnant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = entries[0]\n",
    "\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "num_recording_locations = len(recording_locations)\n",
    "loc_features = np.zeros(num_recording_locations)\n",
    "if locations in recording_locations:\n",
    "    j = recording_locations.index(locations)\n",
    "    loc_features[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['2530'],\n",
       " 'age': [array([0, 0, 0, 0, 0, 1])],\n",
       " 'sex': [array([1, 0])],\n",
       " 'hw': [array([98. , 15.9])],\n",
       " 'preg': [False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.])],\n",
       " 'mel1': [array([[-14.24342  , -14.460995 , -12.48743  , ...,  -8.350793 ,\n",
       "           -9.550913 ,  -6.6099434],\n",
       "         [ -8.833427 , -11.78526  , -10.376642 , ..., -10.638776 ,\n",
       "          -14.766047 ,  -2.595482 ],\n",
       "         [ -7.201795 , -11.942595 , -14.396763 , ..., -13.780443 ,\n",
       "          -11.831632 , -10.3140745],\n",
       "         ...,\n",
       "         [-43.652073 , -60.107727 , -58.363945 , ..., -46.318718 ,\n",
       "          -47.93747  , -47.206367 ],\n",
       "         [-42.097    , -59.548874 , -57.106033 , ..., -45.140682 ,\n",
       "          -53.84076  , -53.963337 ],\n",
       "         [-42.240356 , -60.107727 , -60.107727 , ..., -51.811592 ,\n",
       "          -55.905552 , -57.170105 ]], dtype=float32)]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    current_patient_data = load_patient_data(patient_files[i])\n",
    "    current_recordings = load_recordings(data_folder, current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patient_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "labels = []\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "for i in range(num_patient_files):\n",
    "\n",
    "    # Load the current patient data and recordings.\n",
    "    current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "    num_locations = get_num_locations(current_patient_data)\n",
    "    recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        \n",
    "        # Extract id\n",
    "        id1 = recording_file.split('_')[0]\n",
    "        features['id'].append(id1)\n",
    "        \n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "        \n",
    "        # Extract age_group\n",
    "        age_group = get_age(current_patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "        \n",
    "        # Extract sex\n",
    "        sex = get_sex(current_patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "        \n",
    "        # Extract height and weight.\n",
    "        height = get_height(current_patient_data)\n",
    "        weight = get_weight(current_patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "        \n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "\n",
    "        # Extract labels and use one-hot encoding.\n",
    "        current_labels = np.zeros(num_classes, dtype=int)\n",
    "        label = get_label(current_patient_data)\n",
    "        if label in classes:\n",
    "            j = classes.index(label)\n",
    "            current_labels[j] = 1\n",
    "        labels.append(current_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['mel1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "loc = keras.Input(shape=(len(recording_locations),), name = 'loc')\n",
    "mel1 = keras.Input(shape=((100, 313, 1)), name = 'mel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## age embeddig\n",
    "age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "## sex embedding\n",
    "sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "## hw embedding\n",
    "hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "## loc embedding\n",
    "loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "## mel embedding\n",
    "mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "concat2 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "concat3 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = [concat2, concat3] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel (InputLayer)                [(None, 100, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 98, 311, 16)  160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 49, 155, 16)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 45, 151, 32)  12832       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 22, 75, 32)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 73, 32)   9248        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 10, 36, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 34, 64)    18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "age_cat (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex_cat (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "height_weight (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loc (InputLayer)                [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 4, 17, 64)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            14          age_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            3           sex_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            3           height_weight[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 3)            18          loc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "is_preg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 72)           0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 is_preg[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           730         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,548\n",
      "Trainable params: 41,548\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "#    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    concat2 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "#    concat3 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat2 )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy2(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "#    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    concat2 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    concat3 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = [concat2, concat3] )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", \n",
    "             loss = ['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_toy2((100, 313, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98. , 15.9],\n",
       "       [98. , 15.9],\n",
       "       [98. , 15.9],\n",
       "       ...,\n",
       "       [ nan,  nan],\n",
       "       [ nan,  nan],\n",
       "       [ nan,  nan]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['hw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer().fit(features_trn[0]['hw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn[0]['hw'] = imputer.transform(features_trn[0]['hw'])\n",
    "features_test[0]['hw'] = imputer.transform(features_test[0]['hw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 98.        ,  15.9       ],\n",
       "       [ 98.        ,  15.9       ],\n",
       "       [ 98.        ,  15.9       ],\n",
       "       ...,\n",
       "       [115.48300537,  25.12023681],\n",
       "       [115.48300537,  25.12023681],\n",
       "       [115.48300537,  25.12023681]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['hw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel (InputLayer)                [(None, 100, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 98, 311, 16)  160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 49, 155, 16)  0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 45, 151, 32)  12832       max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling2D) (None, 22, 75, 32)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 20, 73, 32)   9248        max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 10, 36, 32)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 34, 64)    18496       max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "age_cat (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex_cat (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "height_weight (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loc (InputLayer)                [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 4, 17, 64)    0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 2)            14          age_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 1)            3           sex_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 1)            3           height_weight[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 3)            18          loc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 64)           0           max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "is_preg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 72)           0           dense_86[0][0]                   \n",
      "                                                                 dense_87[0][0]                   \n",
      "                                                                 dense_88[0][0]                   \n",
      "                                                                 dense_89[0][0]                   \n",
      "                                                                 global_average_pooling2d_13[0][0]\n",
      "                                                                 is_preg[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 10)           730         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 3)            33          dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 2)            22          dense_90[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,559\n",
      "Trainable params: 41,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 18s 231ms/step - loss: 1.3228 - dense_91_loss: 0.6410 - dense_92_loss: 0.6818 - dense_91_accuracy: 0.7492 - dense_92_accuracy: 0.5249 - val_loss: 1.2967 - val_dense_91_loss: 0.6085 - val_dense_92_loss: 0.6882 - val_dense_91_accuracy: 0.7448 - val_dense_92_accuracy: 0.5024\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.2681 - dense_91_loss: 0.5917 - dense_92_loss: 0.6764 - dense_91_accuracy: 0.7622 - dense_92_accuracy: 0.5324 - val_loss: 1.2790 - val_dense_91_loss: 0.6068 - val_dense_92_loss: 0.6722 - val_dense_91_accuracy: 0.7448 - val_dense_92_accuracy: 0.5135\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.2655 - dense_91_loss: 0.5924 - dense_92_loss: 0.6731 - dense_91_accuracy: 0.7595 - dense_92_accuracy: 0.5201 - val_loss: 1.2740 - val_dense_91_loss: 0.6061 - val_dense_92_loss: 0.6679 - val_dense_91_accuracy: 0.7544 - val_dense_92_accuracy: 0.5008\n",
      "Epoch 4/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.2491 - dense_91_loss: 0.5835 - dense_92_loss: 0.6656 - dense_91_accuracy: 0.7733 - dense_92_accuracy: 0.5478 - val_loss: 1.2149 - val_dense_91_loss: 0.5771 - val_dense_92_loss: 0.6378 - val_dense_91_accuracy: 0.7559 - val_dense_92_accuracy: 0.6276\n",
      "Epoch 5/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.2010 - dense_91_loss: 0.5449 - dense_92_loss: 0.6561 - dense_91_accuracy: 0.7871 - dense_92_accuracy: 0.5770 - val_loss: 1.1852 - val_dense_91_loss: 0.5441 - val_dense_92_loss: 0.6411 - val_dense_91_accuracy: 0.7765 - val_dense_92_accuracy: 0.5753\n",
      "Epoch 6/30\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 1.1568 - dense_91_loss: 0.5124 - dense_92_loss: 0.6443 - dense_91_accuracy: 0.8120 - dense_92_accuracy: 0.6003 - val_loss: 1.1571 - val_dense_91_loss: 0.5250 - val_dense_92_loss: 0.6321 - val_dense_91_accuracy: 0.7971 - val_dense_92_accuracy: 0.5864\n",
      "Epoch 7/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.1377 - dense_91_loss: 0.4982 - dense_92_loss: 0.6395 - dense_91_accuracy: 0.8219 - dense_92_accuracy: 0.6011 - val_loss: 1.1435 - val_dense_91_loss: 0.5122 - val_dense_92_loss: 0.6314 - val_dense_91_accuracy: 0.8082 - val_dense_92_accuracy: 0.6355\n",
      "Epoch 8/30\n",
      "80/80 [==============================] - 18s 230ms/step - loss: 1.0939 - dense_91_loss: 0.4658 - dense_92_loss: 0.6280 - dense_91_accuracy: 0.8341 - dense_92_accuracy: 0.6114 - val_loss: 1.0876 - val_dense_91_loss: 0.4784 - val_dense_92_loss: 0.6092 - val_dense_91_accuracy: 0.8177 - val_dense_92_accuracy: 0.6593\n",
      "Epoch 9/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0805 - dense_91_loss: 0.4548 - dense_92_loss: 0.6257 - dense_91_accuracy: 0.8377 - dense_92_accuracy: 0.6141 - val_loss: 1.1477 - val_dense_91_loss: 0.5081 - val_dense_92_loss: 0.6396 - val_dense_91_accuracy: 0.8035 - val_dense_92_accuracy: 0.5895\n",
      "Epoch 10/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0678 - dense_91_loss: 0.4441 - dense_92_loss: 0.6237 - dense_91_accuracy: 0.8452 - dense_92_accuracy: 0.6181 - val_loss: 1.1365 - val_dense_91_loss: 0.5027 - val_dense_92_loss: 0.6337 - val_dense_91_accuracy: 0.8177 - val_dense_92_accuracy: 0.5911\n",
      "Epoch 11/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0773 - dense_91_loss: 0.4556 - dense_92_loss: 0.6217 - dense_91_accuracy: 0.8365 - dense_92_accuracy: 0.6268 - val_loss: 1.1505 - val_dense_91_loss: 0.5080 - val_dense_92_loss: 0.6425 - val_dense_91_accuracy: 0.8193 - val_dense_92_accuracy: 0.5864\n",
      "Epoch 12/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0614 - dense_91_loss: 0.4387 - dense_92_loss: 0.6227 - dense_91_accuracy: 0.8472 - dense_92_accuracy: 0.6228 - val_loss: 1.0725 - val_dense_91_loss: 0.4598 - val_dense_92_loss: 0.6127 - val_dense_91_accuracy: 0.8320 - val_dense_92_accuracy: 0.6307\n",
      "Epoch 13/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0336 - dense_91_loss: 0.4203 - dense_92_loss: 0.6133 - dense_91_accuracy: 0.8551 - dense_92_accuracy: 0.6367 - val_loss: 1.0712 - val_dense_91_loss: 0.4480 - val_dense_92_loss: 0.6232 - val_dense_91_accuracy: 0.8336 - val_dense_92_accuracy: 0.6181\n",
      "Epoch 14/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0304 - dense_91_loss: 0.4201 - dense_92_loss: 0.6103 - dense_91_accuracy: 0.8523 - dense_92_accuracy: 0.6351 - val_loss: 1.1382 - val_dense_91_loss: 0.5058 - val_dense_92_loss: 0.6324 - val_dense_91_accuracy: 0.8257 - val_dense_92_accuracy: 0.6038\n",
      "Epoch 15/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0217 - dense_91_loss: 0.4134 - dense_92_loss: 0.6082 - dense_91_accuracy: 0.8555 - dense_92_accuracy: 0.6473 - val_loss: 1.0548 - val_dense_91_loss: 0.4435 - val_dense_92_loss: 0.6113 - val_dense_91_accuracy: 0.8384 - val_dense_92_accuracy: 0.6355\n",
      "Epoch 16/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0057 - dense_91_loss: 0.4014 - dense_92_loss: 0.6043 - dense_91_accuracy: 0.8614 - dense_92_accuracy: 0.6453 - val_loss: 1.0680 - val_dense_91_loss: 0.4467 - val_dense_92_loss: 0.6212 - val_dense_91_accuracy: 0.8415 - val_dense_92_accuracy: 0.6165\n",
      "Epoch 17/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 1.0096 - dense_91_loss: 0.4030 - dense_92_loss: 0.6066 - dense_91_accuracy: 0.8586 - dense_92_accuracy: 0.6418 - val_loss: 1.0521 - val_dense_91_loss: 0.4422 - val_dense_92_loss: 0.6100 - val_dense_91_accuracy: 0.8415 - val_dense_92_accuracy: 0.6513\n",
      "Epoch 18/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9971 - dense_91_loss: 0.3951 - dense_92_loss: 0.6020 - dense_91_accuracy: 0.8626 - dense_92_accuracy: 0.6442 - val_loss: 1.0957 - val_dense_91_loss: 0.4683 - val_dense_92_loss: 0.6275 - val_dense_91_accuracy: 0.8384 - val_dense_92_accuracy: 0.6054\n",
      "Epoch 19/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9878 - dense_91_loss: 0.3897 - dense_92_loss: 0.5981 - dense_91_accuracy: 0.8637 - dense_92_accuracy: 0.6473 - val_loss: 1.0319 - val_dense_91_loss: 0.4277 - val_dense_92_loss: 0.6042 - val_dense_91_accuracy: 0.8463 - val_dense_92_accuracy: 0.6498\n",
      "Epoch 20/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9835 - dense_91_loss: 0.3869 - dense_92_loss: 0.5966 - dense_91_accuracy: 0.8669 - dense_92_accuracy: 0.6532 - val_loss: 1.0770 - val_dense_91_loss: 0.4437 - val_dense_92_loss: 0.6333 - val_dense_91_accuracy: 0.8447 - val_dense_92_accuracy: 0.6165\n",
      "Epoch 21/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9740 - dense_91_loss: 0.3777 - dense_92_loss: 0.5963 - dense_91_accuracy: 0.8709 - dense_92_accuracy: 0.6556 - val_loss: 1.0301 - val_dense_91_loss: 0.4241 - val_dense_92_loss: 0.6060 - val_dense_91_accuracy: 0.8463 - val_dense_92_accuracy: 0.6498\n",
      "Epoch 22/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9696 - dense_91_loss: 0.3762 - dense_92_loss: 0.5934 - dense_91_accuracy: 0.8681 - dense_92_accuracy: 0.6521 - val_loss: 1.0316 - val_dense_91_loss: 0.4287 - val_dense_92_loss: 0.6029 - val_dense_91_accuracy: 0.8494 - val_dense_92_accuracy: 0.6403\n",
      "Epoch 23/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9492 - dense_91_loss: 0.3609 - dense_92_loss: 0.5883 - dense_91_accuracy: 0.8744 - dense_92_accuracy: 0.6552 - val_loss: 1.1006 - val_dense_91_loss: 0.4599 - val_dense_92_loss: 0.6407 - val_dense_91_accuracy: 0.8273 - val_dense_92_accuracy: 0.6070\n",
      "Epoch 24/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9559 - dense_91_loss: 0.3625 - dense_92_loss: 0.5934 - dense_91_accuracy: 0.8716 - dense_92_accuracy: 0.6596 - val_loss: 1.0715 - val_dense_91_loss: 0.4555 - val_dense_92_loss: 0.6160 - val_dense_91_accuracy: 0.8463 - val_dense_92_accuracy: 0.6292\n",
      "Epoch 25/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9433 - dense_91_loss: 0.3555 - dense_92_loss: 0.5878 - dense_91_accuracy: 0.8776 - dense_92_accuracy: 0.6603 - val_loss: 1.0525 - val_dense_91_loss: 0.4267 - val_dense_92_loss: 0.6258 - val_dense_91_accuracy: 0.8368 - val_dense_92_accuracy: 0.6260\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9407 - dense_91_loss: 0.3546 - dense_92_loss: 0.5860 - dense_91_accuracy: 0.8760 - dense_92_accuracy: 0.6619 - val_loss: 1.0393 - val_dense_91_loss: 0.4167 - val_dense_92_loss: 0.6226 - val_dense_91_accuracy: 0.8574 - val_dense_92_accuracy: 0.6355\n",
      "Epoch 27/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9456 - dense_91_loss: 0.3597 - dense_92_loss: 0.5859 - dense_91_accuracy: 0.8752 - dense_92_accuracy: 0.6647 - val_loss: 1.0203 - val_dense_91_loss: 0.4201 - val_dense_92_loss: 0.6001 - val_dense_91_accuracy: 0.8494 - val_dense_92_accuracy: 0.6418\n",
      "Epoch 28/30\n",
      "80/80 [==============================] - 18s 229ms/step - loss: 0.9449 - dense_91_loss: 0.3574 - dense_92_loss: 0.5876 - dense_91_accuracy: 0.8776 - dense_92_accuracy: 0.6564 - val_loss: 1.0292 - val_dense_91_loss: 0.4174 - val_dense_92_loss: 0.6118 - val_dense_91_accuracy: 0.8479 - val_dense_92_accuracy: 0.6434\n",
      "Epoch 29/30\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 0.9208 - dense_91_loss: 0.3413 - dense_92_loss: 0.5795 - dense_91_accuracy: 0.8835 - dense_92_accuracy: 0.6682 - val_loss: 1.0333 - val_dense_91_loss: 0.4260 - val_dense_92_loss: 0.6074 - val_dense_91_accuracy: 0.8399 - val_dense_92_accuracy: 0.6450\n",
      "Epoch 30/30\n",
      "80/80 [==============================] - 18s 228ms/step - loss: 0.9296 - dense_91_loss: 0.3476 - dense_92_loss: 0.5819 - dense_91_accuracy: 0.8799 - dense_92_accuracy: 0.6746 - val_loss: 1.0343 - val_dense_91_loss: 0.4212 - val_dense_92_loss: 0.6131 - val_dense_91_accuracy: 0.8479 - val_dense_92_accuracy: 0.6307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1205939198>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([features_trn[0]['age'],features_trn[0]['sex'], features_trn[0]['hw'], features_trn[0]['preg'], features_trn[0]['loc'], \n",
    "           features_trn[0]['mel1']], [features_trn[1],features_trn[2]],\n",
    "          validation_data = ([features_test[0]['age'],features_test[0]['sex'], features_test[0]['hw'], \n",
    "                              features_test[0]['preg'], features_test[0]['loc'], features_test[0]['mel1']], \n",
    "                             [features_test[1], features_test[2]]), \n",
    "          epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model2(model_folder, model, m_name, mel_shape = (100, 313, 1)) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename = os.path.join(model_folder, m_name + '_model.hdf5')\n",
    "    model.save(filename)\n",
    "    d = {'model': m_name, 'mel_shape': mel_shape, 'model_fnm': filename}    \n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(d, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model.\n",
    "save_challenge_model2(model_folder, model, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    with open(info_fnm, 'rb') as f:\n",
    "        info_m = pk.load(f)\n",
    "#    if info_m['model'] == 'toy' :\n",
    "#        model = get_toy(info_m['mel_shape'])\n",
    "#    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "#    model.load_weights(filename)\n",
    "    return info_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat1 )\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_challenge_model2(model_folder, model, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_challenge_model(model_folder, verbose = 1) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model2/toy_model.hdf5'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[0])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    \n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(model['mel_shape'])\n",
    "    model1.load_weights(model['model_fnm'])\n",
    "    \n",
    "    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "    features['mel1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_melspec(recordings[i])[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)   \n",
    "        \n",
    "    features['mel1'] = np.array(features['mel1'])\n",
    "#    print(features)\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    prob1 = res1.mean(axis = 0) ## simple rule for now\n",
    "    idx = np.argmax(prob1)\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model2/toy_model.hdf5'}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if model1['model'] == 'toy' :\n",
    "        model2 = get_toy2(model1['mel_shape'])\n",
    "    model2.load_weights(model1['model_fnm'])\n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Normal', 'Abnormal']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "    features['mel1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_melspec(recordings[i])[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)   \n",
    "        \n",
    "    features['mel1'] = np.array(features['mel1'])\n",
    "    res1 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "    res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "    res1 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2.2546257e-16, 1.2601602e-16, 1.0000000e+00],\n",
       "        [6.9195350e-16, 3.9185369e-16, 1.0000000e+00],\n",
       "        [1.3673014e-16, 7.5975606e-17, 1.0000000e+00],\n",
       "        [4.0297731e-17, 2.2074177e-17, 1.0000000e+00]], dtype=float32),\n",
       " array([[1.7146952e-09, 1.0000000e+00],\n",
       "        [3.1972824e-09, 1.0000000e+00],\n",
       "        [1.2986671e-09, 1.0000000e+00],\n",
       "        [6.5870259e-10, 1.0000000e+00]], dtype=float32)]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33151 4 4000\\nAV 33151_AV.hea 33151_AV.wav 33151_AV.tsv\\nPV 33151_PV.hea 33151_PV.wav 33151_PV.tsv\\nTV 33151_TV.hea 33151_TV.wav 33151_TV.tsv\\nMV 33151_MV.hea 33151_MV.wav 33151_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 141.0\\n#Weight: 30.9\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: MV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Plateau\\n#Systolic murmur grading: I/VI\\n#Systolic murmur pitch: Low\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if model1['model'] == 'toy' :\n",
    "        model2 = get_toy2(model1['mel_shape'])\n",
    "    model2.load_weights(model1['model_fnm'])\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Normal', 'Abnormal']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "    features['mel1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_melspec(recordings[i])[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)   \n",
    "        \n",
    "    features['mel1'] = np.array(features['mel1'])\n",
    "#    print(features)\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    prob1 = res1.mean(axis = 0) ## simple rule for now\n",
    "    idx = np.argmax(prob1)\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    labels[idx] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_one(patient_data, verbose = 0) :\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "    \n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    recording_information = patient_data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    features = dict()\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "#    features['mel1'] = []\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "#        filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "        # Extract id\n",
    "    #    id1 = recording_file.split('_')[0]\n",
    "    #    features['id'].append(id1)\n",
    "\n",
    "        # Extract melspec\n",
    "#        mel1 = feature_extract_melspec(filename)[0]\n",
    "#        features['mel1'].append(mel1)\n",
    "\n",
    "        # Extract age_group\n",
    "        age_group = get_age(patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "\n",
    "        # Extract sex\n",
    "        sex = get_sex(patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "\n",
    "        # Extract height and weight.\n",
    "        height = get_height(patient_data)\n",
    "        weight = get_weight(patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "        \n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "        \n",
    "    if verbose :\n",
    "        label = get_label(patient_data)\n",
    "        print(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33151 4 4000\\nAV 33151_AV.hea 33151_AV.wav 33151_AV.tsv\\nPV 33151_PV.hea 33151_PV.wav 33151_PV.tsv\\nTV 33151_TV.hea 33151_TV.wav 33151_TV.tsv\\nMV 33151_MV.hea 33151_MV.wav 33151_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 141.0\\n#Weight: 30.9\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: MV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Plateau\\n#Systolic murmur grading: I/VI\\n#Systolic murmur pitch: Low\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Normal', 'Abnormal']\n",
    "num_mm_classes = len(murmur_classes)\n",
    "num_o_classes = len(outcome_classes)\n",
    "\n",
    "if model1['model'] == 'toy' :\n",
    "    model2 = get_toy(model1['mel_shape'])\n",
    "model2.load_weights(model1['model_fnm'])\n",
    "\n",
    "features = get_feature_one(data, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ -455,  1009,   729, ..., -2099, -1931, -1825], dtype=int16),\n",
       " array([1174, 4679, 5900, ...,  -36, -171,  -73], dtype=int16),\n",
       " array([7710, 5756, 2397, ...,  950,  784,  923], dtype=int16),\n",
       " array([14951,  7497,  -352, ...,  1297,   811,    61], dtype=int16)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mel1'] = []\n",
    "for i in range(len(recordings)) :\n",
    "    mel1 = feature_extract_melspec(recordings[i])[0]\n",
    "    features['mel1'].append(mel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = features['mel1'][0].shape\n",
    "for i in range(len(features['mel1'])) :\n",
    "    features['mel1'][i] = features['mel1'][i].reshape(M,N,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mel1'] = np.array(features['mel1'])\n",
    "#    print(features)\n",
    "# Impute missing data.\n",
    "res1 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=float32),\n",
       " array([[nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan],\n",
       "        [nan, nan]], dtype=float32)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Normal', 'Abnormal']\n",
    "num_mm_classes = len(murmur_classes)\n",
    "num_o_classes = len(outcome_classes)\n",
    "\n",
    "if model['model'] == 'toy' :\n",
    "    model1 = get_toy(model['mel_shape'])\n",
    "model1.load_weights(model['model_fnm'])\n",
    "\n",
    "features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "\n",
    "#imputer = model['imputer']\n",
    "classifier = model['classifier']\n",
    "\n",
    "if model['model'] == 'toy' :\n",
    "    model1 = get_toy(info_m['mel_shape'])\n",
    "filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "model.load_weights(filename)\n",
    "\n",
    "# Load features.\n",
    "features = get_features(data, recordings)\n",
    "\n",
    "# Impute missing data.\n",
    "features = features.reshape(1, -1)\n",
    "features = imputer.transform(features)\n",
    "\n",
    "# Get classifier probabilities.\n",
    "probabilities = classifier.predict_proba(features)\n",
    "probabilities = np.asarray(probabilities, dtype=np.float32)[:, 0, 1]\n",
    "\n",
    "# Choose label with higher probability.\n",
    "labels = np.zeros(len(classes), dtype=np.int_)\n",
    "idx = np.argmax(probabilities)\n",
    "labels[idx] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_challenge_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-54acaecfd6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_challenge_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecordings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### Teams: Implement this function!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_challenge_model' is not defined"
     ]
    }
   ],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model1, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(current_patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(current_patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(current_patient_data)\n",
    "    weight = get_weight(current_patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2032033e-03, 2.9272465e-03, 9.9586958e-01],\n",
       "       [3.2206599e-02, 7.0056088e-02, 8.9773726e-01],\n",
       "       [1.4683392e-04, 7.0860866e-04, 9.9914455e-01],\n",
       "       [1.8912905e-03, 6.9301804e-03, 9.9117857e-01]], dtype=float32)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    classes = model['classes']\n",
    "    imputer = model['imputer']\n",
    "    classifier = model['classifier']\n",
    "\n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(info_m['mel_shape'])\n",
    "    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "    model.load_weights(filename)\n",
    "    \n",
    "    # Load features.\n",
    "    features = get_features(data, recordings)\n",
    "\n",
    "    # Impute missing data.\n",
    "    features = features.reshape(1, -1)\n",
    "    features = imputer.transform(features)\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    probabilities = classifier.predict_proba(features)\n",
    "    probabilities = np.asarray(probabilities, dtype=np.float32)[:, 0, 1]\n",
    "\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    idx = np.argmax(probabilities)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1)}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[1])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85112 4 4000\\nAV 85112_AV.hea 85112_AV.wav 85112_AV.tsv\\nPV 85112_PV.hea 85112_PV.wav 85112_PV.tsv\\nTV 85112_TV.hea 85112_TV.wav 85112_TV.tsv\\nMV 85112_MV.hea 85112_MV.wav 85112_MV.tsv\\n#Age: Child\\n#Sex: Male\\n#Height: 136.0\\n#Weight: 26.3\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(patient_data)\n",
    "    weight = get_weight(patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0])],\n",
       " 'sex': [array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])],\n",
       " 'hw': [array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3])],\n",
       " 'preg': [False, False, False, False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 0., 1., 0.]),\n",
       "  array([0., 1., 0., 0., 0.])],\n",
       " 'mel1': [array([[  5.5544219 ,   5.25430448,   5.85624965, ...,  -4.01180172,\n",
       "           -2.62854908,  -2.5042349 ],\n",
       "         [ 10.42099442,   9.87717865,  14.38695231, ...,  -2.46004349,\n",
       "            1.79924639,  -4.51349842],\n",
       "         [ 11.33310424,  13.78394537,  13.1335616 , ...,   1.08339154,\n",
       "           -1.01365032,  -7.04751297],\n",
       "         ...,\n",
       "         [-18.90015848, -54.90594607, -58.1136186 , ..., -59.42052707,\n",
       "          -56.90998361, -48.85066669],\n",
       "         [-15.42566047, -52.71301415, -60.73131942, ..., -58.35870146,\n",
       "          -54.73361041, -52.19404219],\n",
       "         [-11.15672201, -51.57177258, -58.63095591, ..., -58.79083737,\n",
       "          -54.01102379, -52.62385897]]),\n",
       "  array([[ -5.34669814,   0.67031571,  -3.17846399, ..., -12.92143893,\n",
       "          -14.6734528 , -14.4765515 ],\n",
       "         [ -3.95126843,   6.31637984,  -4.64244314, ..., -10.39461407,\n",
       "          -10.63099409, -11.15637501],\n",
       "         [ -7.16954755,   2.46297333,  -0.85409502, ..., -10.59649951,\n",
       "          -12.49328981,   0.34125863],\n",
       "         ...,\n",
       "         [-34.42811144, -45.71171169, -59.00138537, ..., -50.40057535,\n",
       "          -56.65142888, -48.37946025],\n",
       "         [-36.29212611, -45.72542494, -61.35395916, ..., -49.05170214,\n",
       "          -58.97230698, -49.21394806],\n",
       "         [-34.86969307, -47.60865986, -61.69973905, ..., -51.1567752 ,\n",
       "          -61.31127645, -49.37548589]]),\n",
       "  array([[  1.68180672,  -3.96855903,  -9.31777817, ...,   0.59115272,\n",
       "          -13.3020849 , -12.12625751],\n",
       "         [  1.26698714,  -2.99167064, -12.70066591, ...,   6.97196192,\n",
       "          -11.43713667,  -3.81615562],\n",
       "         [  3.43579033,  -9.09430088, -10.03208319, ...,   6.05637143,\n",
       "          -11.2431155 ,  -4.3648029 ],\n",
       "         ...,\n",
       "         [-43.69433129, -54.66976803, -52.25798263, ..., -53.96021268,\n",
       "          -50.90066326, -48.80887587],\n",
       "         [-48.28895934, -55.59192024, -55.07810207, ..., -55.17842987,\n",
       "          -54.19418911, -49.81082227],\n",
       "         [-46.75922137, -56.52883698, -58.63612156, ..., -59.24551201,\n",
       "          -54.76376578, -48.53233825]]),\n",
       "  array([[-1.05357382e+01, -1.01090303e+01, -8.64615922e+00, ...,\n",
       "          -1.89183902e+01, -1.21077508e+01, -5.23639113e+00],\n",
       "         [-1.00548815e+01, -7.11764236e+00,  5.00336436e-02, ...,\n",
       "          -1.23953922e+01, -5.09774962e+00, -1.88250036e+00],\n",
       "         [-1.14629545e+01, -4.32136781e+00, -9.34656013e-02, ...,\n",
       "          -8.60415821e+00, -4.33791884e+00, -7.56818893e-01],\n",
       "         ...,\n",
       "         [-4.77923995e+01, -5.19989387e+01, -4.48201872e+01, ...,\n",
       "          -6.13758177e+01, -6.03041781e+01, -5.60282865e+01],\n",
       "         [-4.92251434e+01, -5.02118889e+01, -4.98856292e+01, ...,\n",
       "          -6.18184748e+01, -6.27257506e+01, -5.94607551e+01],\n",
       "         [-4.99104228e+01, -5.20431292e+01, -5.46581665e+01, ...,\n",
       "          -6.14256151e+01, -6.38957486e+01, -6.03423585e+01]])]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_one(patient_data, verbose = 0) :\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    recording_information = patient_data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    features = dict()\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "        # Extract id\n",
    "    #    id1 = recording_file.split('_')[0]\n",
    "    #    features['id'].append(id1)\n",
    "\n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "        # Extract age_group\n",
    "        age_group = get_age(patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "\n",
    "        # Extract sex\n",
    "        sex = get_sex(patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "\n",
    "        # Extract height and weight.\n",
    "        height = get_height(patient_data)\n",
    "        weight = get_weight(patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "        \n",
    "        \n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "        \n",
    "    if verbose :\n",
    "        label = get_label(patient_data)\n",
    "        print(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = res1.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "probargmax = prob1.argmax()\n",
    "labels = np.zeros((3,))\n",
    "labels[probargmax] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(model['mel_shape'])\n",
    "    filename = os.path.join(model_folder, model['model'] + '_model.hdf5')\n",
    "    model1.load_weights(filename)\n",
    "    \n",
    "    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose)\n",
    "\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "    \n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    prob1 = res1.mean(axis = 0) ## simple rule for now\n",
    "    idx = np.argmax(prob1)\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.42289853, 0.02808568, 0.5490158 ], dtype=float32))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[0]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.21346666, 0.03261768, 0.7539156 ], dtype=float32))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[1]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.11145334, 0.01811697, 0.8704297 ], dtype=float32))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[2]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0769320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.09037623, 0.00931931, 0.90030444], dtype=float32))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[3]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0769710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.04683066, 0.00709078, 0.94607854], dtype=float32))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[4]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ones1 = []\n",
    "for i in range(100) :\n",
    "    patient_data = load_patient_data(patient_files_test[i])\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    if(num_locations == 1) :\n",
    "        ones1.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 32, 80, 94, 98]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0538710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.02266924, 0.06886302, 0.90846777], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[24]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d07699e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([5.9274078e-04, 1.3342367e-02, 9.8606491e-01], dtype=float32))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[32]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0538a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.01424488, 0.0106928 , 0.97506225], dtype=float32))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[80]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
