{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea -> \n",
    "\n",
    "murmur \n",
    "\n",
    "학습 라벨\n",
    "murmur 0 1 \n",
    "unknown 0.5 0.5\n",
    "absent 1 0\n",
    "murmur 다른거 0.5 0.5\n",
    "\n",
    "합칠 때: \n",
    "murmur 가 가장 높은 확률인 벡터 뽑기\n",
    "murmur 확률 과 0, 0.5, 1 과의 거리의 역수를 합이 1이 되게 표준화시켜 점수만들기\n",
    "\n",
    "학습라벨\n",
    "- normal 1 0\n",
    "- abnormal \n",
    "present 0.1 0.9\n",
    "unknown 0.15 0.85\n",
    "absent 0.2 0.8\n",
    "합칠 때: 평균\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/ikwak2/hmd/notebooks')\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/iy_classifier')\n",
    "sys.path.insert(0,'/home/ikwak2/hmd/notebooks/utils')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "from get_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3'\n",
    "training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for usage information.\n",
      "\n",
      "\n",
      "Fri Jul  1 23:12:36 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.80       Driver Version: 460.80       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 35%   33C    P8    13W / 260W |    286MiB / 11011MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       992      G   /usr/lib/xorg/Xorg                 18MiB |\n",
      "|    0   N/A  N/A      1110      G   /usr/bin/gnome-shell               72MiB |\n",
      "|    0   N/A  N/A      1352      G   /usr/lib/xorg/Xorg                146MiB |\n",
      "|    0   N/A  N/A      1472      G   /usr/bin/gnome-shell               27MiB |\n",
      "|    0   N/A  N/A      2063      G   /usr/lib/firefox/firefox           12MiB |\n",
      "|    0   N/A  N/A      2416      G   gnome-control-center                3MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Recording locations:</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>Murmur locations</th>\n",
       "      <th>Most audible location</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic murmur pitch</th>\n",
       "      <th>Systolic murmur quality</th>\n",
       "      <th>Diastolic murmur timing</th>\n",
       "      <th>Diastolic murmur shape</th>\n",
       "      <th>Diastolic murmur grading</th>\n",
       "      <th>Diastolic murmur pitch</th>\n",
       "      <th>Diastolic murmur quality</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Additional ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9983</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>115.0</td>\n",
       "      <td>19.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13918</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14241</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>PV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14998</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23625</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>50379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24160</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>17.66</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29045</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29378</td>\n",
       "      <td>AV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID Recording locations:    Age     Sex  Height  Weight  \\\n",
       "0        2530          AV+PV+TV+MV  Child  Female    98.0   15.90   \n",
       "1        9979          AV+PV+TV+MV  Child  Female   103.0   13.10   \n",
       "2        9983          AV+PV+TV+MV  Child    Male   115.0   19.10   \n",
       "3       13918          AV+PV+TV+MV  Child    Male    98.0   15.90   \n",
       "4       14241          AV+PV+TV+MV  Child    Male    87.0   11.20   \n",
       "5       14998          AV+PV+TV+MV  Child    Male     NaN     NaN   \n",
       "6       23625          AV+PV+TV+MV  Child  Female    92.0   14.00   \n",
       "7       24160          AV+PV+TV+MV  Child  Female    98.0   17.66   \n",
       "8       29045          AV+PV+TV+MV  Child  Female    88.0   12.50   \n",
       "9       29378                AV+MV  Child  Female    82.0   10.70   \n",
       "\n",
       "   Pregnancy status   Murmur Murmur locations Most audible location  ...  \\\n",
       "0             False   Absent              NaN                   NaN  ...   \n",
       "1             False  Present      AV+MV+PV+TV                    TV  ...   \n",
       "2             False  Unknown              NaN                   NaN  ...   \n",
       "3             False  Present               TV                    TV  ...   \n",
       "4             False  Present      AV+MV+PV+TV                    PV  ...   \n",
       "5             False   Absent              NaN                   NaN  ...   \n",
       "6             False   Absent              NaN                   NaN  ...   \n",
       "7             False   Absent              NaN                   NaN  ...   \n",
       "8             False  Present      AV+MV+PV+TV                    TV  ...   \n",
       "9             False  Unknown              NaN                   NaN  ...   \n",
       "\n",
       "  Systolic murmur pitch Systolic murmur quality Diastolic murmur timing  \\\n",
       "0                   NaN                     NaN                     NaN   \n",
       "1                  High                   Harsh                     NaN   \n",
       "2                   NaN                     NaN                     NaN   \n",
       "3                   Low                 Blowing                     NaN   \n",
       "4                   Low                   Harsh                     NaN   \n",
       "5                   NaN                     NaN                     NaN   \n",
       "6                   NaN                     NaN                     NaN   \n",
       "7                   NaN                     NaN                     NaN   \n",
       "8                   Low                 Blowing                     NaN   \n",
       "9                   NaN                     NaN                     NaN   \n",
       "\n",
       "  Diastolic murmur shape Diastolic murmur grading Diastolic murmur pitch  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    NaN   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    NaN   \n",
       "5                    NaN                      NaN                    NaN   \n",
       "6                    NaN                      NaN                    NaN   \n",
       "7                    NaN                      NaN                    NaN   \n",
       "8                    NaN                      NaN                    NaN   \n",
       "9                    NaN                      NaN                    NaN   \n",
       "\n",
       "  Diastolic murmur quality   Outcome Campaign Additional ID  \n",
       "0                      NaN  Abnormal   CC2015           NaN  \n",
       "1                      NaN  Abnormal   CC2015           NaN  \n",
       "2                      NaN  Abnormal   CC2015           NaN  \n",
       "3                      NaN  Abnormal   CC2015           NaN  \n",
       "4                      NaN  Abnormal   CC2015           NaN  \n",
       "5                      NaN  Abnormal   CC2015           NaN  \n",
       "6                      NaN  Abnormal   CC2015       50379.0  \n",
       "7                      NaN  Abnormal   CC2015           NaN  \n",
       "8                      NaN  Abnormal   CC2015           NaN  \n",
       "9                      NaN  Abnormal   CC2015           NaN  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(training_data_file)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =  '/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3/training_data'\n",
    "train_folder =  '/home/ubuntu/data/hmd/murmur/train'\n",
    "test_folder = '/home/ubuntu/data/hmd/murmur/test'\n",
    "model_folder = 'tmp_model2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ikwak2/hmd/physionet.org/files/circor-heart-sound/1.0.3/training_data'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(data_folder)\n",
    "patient_files_trn = find_patient_files(train_folder)\n",
    "patient_files_test = find_patient_files(test_folder)\n",
    "\n",
    "num_patient_files = len(patient_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46778 1 4000\r\n",
      "MV 46778_MV.hea 46778_MV.wav 46778_MV.tsv\r\n",
      "#Age: Adolescent\r\n",
      "#Sex: Female\r\n",
      "#Height: 150.0\r\n",
      "#Weight: 54.7\r\n",
      "#Pregnancy status: False\r\n",
      "#Murmur: Present\r\n",
      "#Murmur locations: MV\r\n",
      "#Most audible location: MV\r\n",
      "#Systolic murmur timing: Holosystolic\r\n",
      "#Systolic murmur shape: Plateau\r\n",
      "#Systolic murmur grading: I/VI\r\n",
      "#Systolic murmur pitch: Low\r\n",
      "#Systolic murmur quality: Harsh\r\n",
      "#Diastolic murmur timing: Early-diastolic\r\n",
      "#Diastolic murmur shape: Decrescendo\r\n",
      "#Diastolic murmur grading: I/IV\r\n",
      "#Diastolic murmur pitch: Low\r\n",
      "#Diastolic murmur quality: Blowing\r\n",
      "#Outcome: Abnormal\r\n",
      "#Campaign: CC2015\r\n",
      "#Additional ID: 49754\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/ubuntu/data/hmd/murmur/train/46778.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46532 1 4000\r\n",
      "AV 46532_AV.hea 46532_AV.wav 46532_AV.tsv\r\n",
      "#Age: Child\r\n",
      "#Sex: Female\r\n",
      "#Height: 70.0\r\n",
      "#Weight: 9.0\r\n",
      "#Pregnancy status: False\r\n",
      "#Murmur: Absent\r\n",
      "#Murmur locations: nan\r\n",
      "#Most audible location: nan\r\n",
      "#Systolic murmur timing: nan\r\n",
      "#Systolic murmur shape: nan\r\n",
      "#Systolic murmur grading: nan\r\n",
      "#Systolic murmur pitch: nan\r\n",
      "#Systolic murmur quality: nan\r\n",
      "#Diastolic murmur timing: nan\r\n",
      "#Diastolic murmur shape: nan\r\n",
      "#Diastolic murmur grading: nan\r\n",
      "#Diastolic murmur pitch: nan\r\n",
      "#Diastolic murmur quality: nan\r\n",
      "#Outcome: Normal\r\n",
      "#Campaign: CC2015\r\n",
      "#Additional ID: nan\r\n"
     ]
    }
   ],
   "source": [
    "!cat /home/ubuntu/data/hmd/murmur/train/46532.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Normal', 'Abnormal']\n",
    "num_mm_classes = len(murmur_classes)\n",
    "num_o_classes = len(outcome_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    for i in range(num_patient_files):\n",
    "\n",
    "i = 1\n",
    "\n",
    "current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "num_locations = get_num_locations(current_patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "num_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV 9979_AV.hea 9979_AV.wav 9979_AV.tsv',\n",
       " 'PV 9979_PV.hea 9979_PV.wav 9979_PV.tsv',\n",
       " 'TV 9979_TV.hea 9979_TV.wav 9979_TV.tsv',\n",
       " 'MV 9979_MV.hea 9979_MV.wav 9979_MV.tsv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9979 4 4000\\nAV 9979_AV.hea 9979_AV.wav 9979_AV.tsv\\nPV 9979_PV.hea 9979_PV.wav 9979_PV.tsv\\nTV 9979_TV.hea 9979_TV.wav 9979_TV.tsv\\nMV 9979_MV.hea 9979_MV.wav 9979_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 103.0\\n#Weight: 13.1\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Diamond\\n#Systolic murmur grading: III/VI\\n#Systolic murmur pitch: High\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#        for j in range(num_locations) :\n",
    "j = 0\n",
    "entries = recording_information[j].split(' ')\n",
    "recording_file = entries[2]\n",
    "filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "# Extract id\n",
    "id1 = recording_file.split('_')[0]\n",
    "features['id'].append(id1)\n",
    "\n",
    "# Extract melspec\n",
    "mel1 = feature_extract_melspec(filename)[0]\n",
    "features['mel1'].append(mel1)\n",
    "\n",
    "# Extract age_group\n",
    "age_group = get_age(current_patient_data)\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1\n",
    "features['age'].append(current_age_group)\n",
    "\n",
    "# Extract sex\n",
    "sex = get_sex(current_patient_data)\n",
    "sex_features = np.zeros(2, dtype=int)\n",
    "if compare_strings(sex, 'Female'):\n",
    "    sex_features[0] = 1\n",
    "elif compare_strings(sex, 'Male'):\n",
    "    sex_features[1] = 1\n",
    "features['sex'].append(sex_features)\n",
    "\n",
    "# Extract height and weight.\n",
    "height = get_height(current_patient_data)\n",
    "weight = get_weight(current_patient_data)\n",
    "features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "# Extract pregnancy\n",
    "is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "features['preg'].append(is_pregnant)\n",
    "\n",
    "# Extract location\n",
    "locations = entries[0]\n",
    "num_recording_locations = len(recording_locations)\n",
    "loc_features = np.zeros(num_recording_locations)\n",
    "if locations in recording_locations:\n",
    "    j = recording_locations.index(locations)\n",
    "    loc_features[j] = 1\n",
    "features['loc'].append(loc_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_murmur_loc(data):\n",
    "    murmur_loc = 0\n",
    "    for l in data.split('\\n'):\n",
    "        if l.startswith('#Murmur locations: '):\n",
    "            try:\n",
    "                murmur_loc = l.split(': ')[1]\n",
    "#                murmur_loc = murmur_loc.split('+')\n",
    "            except:\n",
    "                pass\n",
    "    return murmur_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = get_murmur_loc(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV+MV+PV+TV'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9979 4 4000',\n",
       " 'AV 9979_AV.hea 9979_AV.wav 9979_AV.tsv',\n",
       " 'PV 9979_PV.hea 9979_PV.wav 9979_PV.tsv',\n",
       " 'TV 9979_TV.hea 9979_TV.wav 9979_TV.tsv',\n",
       " 'MV 9979_MV.hea 9979_MV.wav 9979_MV.tsv',\n",
       " '#Age: Child',\n",
       " '#Sex: Female',\n",
       " '#Height: 103.0',\n",
       " '#Weight: 13.1',\n",
       " '#Pregnancy status: False',\n",
       " '#Murmur: Present',\n",
       " '#Murmur locations: AV+MV+PV+TV',\n",
       " '#Most audible location: TV',\n",
       " '#Systolic murmur timing: Holosystolic',\n",
       " '#Systolic murmur shape: Diamond',\n",
       " '#Systolic murmur grading: III/VI',\n",
       " '#Systolic murmur pitch: High',\n",
       " '#Systolic murmur quality: Harsh',\n",
       " '#Diastolic murmur timing: nan',\n",
       " '#Diastolic murmur shape: nan',\n",
       " '#Diastolic murmur grading: nan',\n",
       " '#Diastolic murmur pitch: nan',\n",
       " '#Diastolic murmur quality: nan',\n",
       " '#Outcome: Abnormal',\n",
       " '#Campaign: CC2015',\n",
       " '#Additional ID: nan',\n",
       " '']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', 'MV', 'PV', 'TV', 'PhC']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_label = get_murmur(current_patient_data)\n",
    "out_label = get_outcome(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_mm_labels = np.zeros(2)\n",
    "current_out_labels = np.zeros(2)\n",
    "if mm_label == 'Absent' :\n",
    "    current_mm_labels = np.array([1, 0])\n",
    "elif mm_label == 'unknown' :\n",
    "    current_mm_labels = np.array([1, 0])\n",
    "else :\n",
    "    mm_loc = get_murmur_loc(current_patient_data)\n",
    "    if mm_loc == 'nan' :\n",
    "        current_mm_labels = np.array([0.2, 0.8])\n",
    "    else :\n",
    "        mm_loc = mm_loc.split('+')\n",
    "        if location in mm_loc :\n",
    "            current_mm_labels = np.array([0, 1])\n",
    "        else :\n",
    "            current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "if out_label == 'Abnormal' :\n",
    "    current_out_labels = np.array([1, 0])\n",
    "else :\n",
    "    current_out_labels = np.array([0, 1])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abnormal'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absent'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_label = get_murmur(current_patient_data)\n",
    "out_label = get_outcome(current_patient_data)\n",
    "mm_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = recording_locations.index(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_loc = get_murmur_loc(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_loc = mm_loc.split('+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', 'MV', 'PV', 'TV']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_labels = np.zeros(2)\n",
    "label = get_label(current_patient_data)\n",
    "if label in classes:\n",
    "    j = classes.index(label)\n",
    "    current_labels[j] = 1\n",
    "labels.append(current_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mm_labels = np.zeros((num_patient_files,2))\n",
    "    out_labels = np.zeros((num_patient_files,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "#    mm_labels = np.zeros((num_patient_files,2))\n",
    "#    out_labels = np.zeros((num_patient_files,2))\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "#            current_labels = np.zeros(2)\n",
    "#            label = get_label(current_patient_data)\n",
    "#            if label in classes:\n",
    "#                j = classes.index(label)\n",
    "#                current_labels[j] = 1\n",
    "#            labels.append(current_labels)\n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.2, 0.8])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if location in mm_loc :\n",
    "                        current_mm_labels = np.array([0, 1])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "            if out_label == 'Abnormal' :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "            else :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features, mm_labels, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "#    labels = []\n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.2, 0.8])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if location in mm_loc :\n",
    "                        current_mm_labels = np.array([0, 1])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.4, 0.6])\n",
    "\n",
    "            if out_label == 'Abnormal' :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "            else :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    mm_labels = np.array(mm_labels)\n",
    "    out_labels = np.array(out_labels)\n",
    "    return features, mm_labels, out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_wo_labels(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = get_features(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = get_features(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = np.random.permutation(942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = patient_files[:800]\n",
    "patient_files_test = patient_files[800:]\n",
    "num_patient_files = len(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "classes = ['Present', 'Unknown', 'Absent']\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels and use one-hot encoding.\n",
    "            current_labels = np.zeros(num_classes, dtype=int)\n",
    "            label = get_label(current_patient_data)\n",
    "            if label in classes:\n",
    "                j = classes.index(label)\n",
    "                current_labels[j] = 1\n",
    "            labels.append(current_labels)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_wo_labels(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = get_features(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2532"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_trn[0]['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = get_features(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_test[0]['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "current_patient_data = load_patient_data(patient_files_trn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recordings. wav data recording\n",
    "def load_recordings(data_folder, data, get_frequencies=False):\n",
    "    num_locations = get_num_locations(data)\n",
    "    recording_information = data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    recordings = list()\n",
    "    frequencies = list()\n",
    "    for i in range(num_locations):\n",
    "        entries = recording_information[i].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        recording, frequency = load_wav_file(filename)\n",
    "        recordings.append(recording)\n",
    "        frequencies.append(frequency)\n",
    "\n",
    "    if get_frequencies:\n",
    "        return recordings, frequencies\n",
    "    else:\n",
    "        return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(current_patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv', 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv', 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv', 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']\n"
     ]
    }
   ],
   "source": [
    "print(num_locations, recording_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv',\n",
       " 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv',\n",
       " 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv',\n",
       " 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', '2530_AV.hea', '2530_AV.wav', '2530_AV.tsv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = recording_information[i].split(' ')\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_file = entries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530_AV.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/2530_AV.wav'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(data_folder, recording_file)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = recording_file.split('_')[0]\n",
    "features['id'].append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1 = feature_extract_melspec(filename)[0]\n",
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mel1'].append(mel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['2530'],\n",
       " 'age': [],\n",
       " 'sex': [],\n",
       " 'hw': [],\n",
       " 'preg': [],\n",
       " 'loc': [],\n",
       " 'mel1': [array([[-14.24342  , -14.460995 , -12.48743  , ...,  -8.350793 ,\n",
       "           -9.550913 ,  -6.6099434],\n",
       "         [ -8.833427 , -11.78526  , -10.376642 , ..., -10.638776 ,\n",
       "          -14.766047 ,  -2.595482 ],\n",
       "         [ -7.201795 , -11.942595 , -14.396763 , ..., -13.780443 ,\n",
       "          -11.831632 , -10.3140745],\n",
       "         ...,\n",
       "         [-43.652073 , -60.107727 , -58.363945 , ..., -46.318718 ,\n",
       "          -47.93747  , -47.206367 ],\n",
       "         [-42.097    , -59.548874 , -57.106033 , ..., -45.140682 ,\n",
       "          -53.84076  , -53.963337 ],\n",
       "         [-42.240356 , -60.107727 , -60.107727 , ..., -51.811592 ,\n",
       "          -55.905552 , -57.170105 ]], dtype=float32)]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_age = ['Child']\n",
    "age_group = get_age(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = get_age(current_patient_data)\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = 'ddd'\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['age'].append(current_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sex. Use one-hot encoding.\n",
    "sex = get_sex(current_patient_data)\n",
    "sex_features = np.zeros(2, dtype=int)\n",
    "if compare_strings(sex, 'Female'):\n",
    "    sex_features[0] = 1\n",
    "elif compare_strings(sex, 'Male'):\n",
    "    sex_features[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['sex'].append(sex_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract height and weight.\n",
    "height = get_height(current_patient_data)\n",
    "weight = get_weight(current_patient_data)\n",
    "features['hw'].append(np.array([height, weight]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "features['preg'].append(is_pregnant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = entries[0]\n",
    "\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "num_recording_locations = len(recording_locations)\n",
    "loc_features = np.zeros(num_recording_locations)\n",
    "if locations in recording_locations:\n",
    "    j = recording_locations.index(locations)\n",
    "    loc_features[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['2530'],\n",
       " 'age': [array([0, 0, 0, 0, 0, 1])],\n",
       " 'sex': [array([1, 0])],\n",
       " 'hw': [array([98. , 15.9])],\n",
       " 'preg': [False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.])],\n",
       " 'mel1': [array([[-14.24342  , -14.460995 , -12.48743  , ...,  -8.350793 ,\n",
       "           -9.550913 ,  -6.6099434],\n",
       "         [ -8.833427 , -11.78526  , -10.376642 , ..., -10.638776 ,\n",
       "          -14.766047 ,  -2.595482 ],\n",
       "         [ -7.201795 , -11.942595 , -14.396763 , ..., -13.780443 ,\n",
       "          -11.831632 , -10.3140745],\n",
       "         ...,\n",
       "         [-43.652073 , -60.107727 , -58.363945 , ..., -46.318718 ,\n",
       "          -47.93747  , -47.206367 ],\n",
       "         [-42.097    , -59.548874 , -57.106033 , ..., -45.140682 ,\n",
       "          -53.84076  , -53.963337 ],\n",
       "         [-42.240356 , -60.107727 , -60.107727 , ..., -51.811592 ,\n",
       "          -55.905552 , -57.170105 ]], dtype=float32)]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    current_patient_data = load_patient_data(patient_files[i])\n",
    "    current_recordings = load_recordings(data_folder, current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patient_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "labels = []\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "for i in range(num_patient_files):\n",
    "\n",
    "    # Load the current patient data and recordings.\n",
    "    current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "    num_locations = get_num_locations(current_patient_data)\n",
    "    recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        \n",
    "        # Extract id\n",
    "        id1 = recording_file.split('_')[0]\n",
    "        features['id'].append(id1)\n",
    "        \n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "        \n",
    "        # Extract age_group\n",
    "        age_group = get_age(current_patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "        \n",
    "        # Extract sex\n",
    "        sex = get_sex(current_patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "        \n",
    "        # Extract height and weight.\n",
    "        height = get_height(current_patient_data)\n",
    "        weight = get_weight(current_patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "        \n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "\n",
    "        # Extract labels and use one-hot encoding.\n",
    "        current_labels = np.zeros(num_classes, dtype=int)\n",
    "        label = get_label(current_patient_data)\n",
    "        if label in classes:\n",
    "            j = classes.index(label)\n",
    "            current_labels[j] = 1\n",
    "        labels.append(current_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313, 1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['mel1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "loc = keras.Input(shape=(len(recording_locations),), name = 'loc')\n",
    "mel1 = keras.Input(shape=((100, 313, 1)), name = 'mel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## age embeddig\n",
    "age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "## sex embedding\n",
    "sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "## hw embedding\n",
    "hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "## loc embedding\n",
    "loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "## mel embedding\n",
    "mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "concat2 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "concat3 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = [concat2, concat3] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel (InputLayer)                [(None, 100, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 98, 311, 16)  160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 49, 155, 16)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 45, 151, 32)  12832       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 22, 75, 32)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 73, 32)   9248        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 10, 36, 32)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 34, 64)    18496       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "age_cat (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex_cat (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "height_weight (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loc (InputLayer)                [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 4, 17, 64)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            14          age_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            3           sex_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            3           height_weight[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 3)            18          loc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 64)           0           max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "is_preg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 72)           0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "                                                                 dense_14[0][0]                   \n",
      "                                                                 dense_15[0][0]                   \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "                                                                 is_preg[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           730         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 2)            22          dense_16[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,548\n",
      "Trainable params: 41,548\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "#    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    concat2 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "    concat3 = layers.Dense(2, activation = \"softmax\")(concat1)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = [concat2, concat3] )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy', 'categorical_crossentropy'], optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", \n",
    "             loss = ['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[0]['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 2)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "80/80 [==============================] - 18s 227ms/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - dense_17_accuracy: 0.9885 - dense_18_accuracy: 1.0000 - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan - val_dense_17_accuracy: 1.0000 - val_dense_18_accuracy: 1.0000\n",
      "Epoch 2/30\n",
      "80/80 [==============================] - 18s 225ms/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - dense_17_accuracy: 1.0000 - dense_18_accuracy: 1.0000 - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan - val_dense_17_accuracy: 1.0000 - val_dense_18_accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "80/80 [==============================] - 18s 225ms/step - loss: nan - dense_17_loss: nan - dense_18_loss: nan - dense_17_accuracy: 1.0000 - dense_18_accuracy: 1.0000 - val_loss: nan - val_dense_17_loss: nan - val_dense_18_loss: nan - val_dense_17_accuracy: 1.0000 - val_dense_18_accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "38/80 [=============>................] - ETA: 8s - loss: nan - dense_17_loss: nan - dense_18_loss: nan - dense_17_accuracy: 1.0000 - dense_18_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-a663d4cf478d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                               features_test[0]['preg'], features_test[0]['loc'], features_test[0]['mel1']], \n\u001b[1;32m      5\u001b[0m                              [features_test[1], features_test[2]]), \n\u001b[0;32m----> 6\u001b[0;31m           epochs = 30)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([features_trn[0]['age'],features_trn[0]['sex'], features_trn[0]['hw'], features_trn[0]['preg'], features_trn[0]['loc'], \n",
    "           features_trn[0]['mel1']], [features_trn[1],features_trn[2] ],\n",
    "          validation_data = ([features_test[0]['age'],features_test[0]['sex'], features_test[0]['hw'], \n",
    "                              features_test[0]['preg'], features_test[0]['loc'], features_test[0]['mel1']], \n",
    "                             [features_test[1], features_test[2]]), \n",
    "          epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model2(model_folder, model, classes, m_name, mel_shape = (100, 313, 1)) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename = os.path.join(model_folder, m_name + '_model.hdf5')\n",
    "    model.save(filename)\n",
    "    d = {'model': m_name, 'classes': classes, 'mel_shape': mel_shape, 'model_fnm': filename}    \n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(d, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model.\n",
    "save_challenge_model2(model_folder, model, classes, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    with open(info_fnm, 'rb') as f:\n",
    "        info_m = pk.load(f)\n",
    "#    if info_m['model'] == 'toy' :\n",
    "#        model = get_toy(info_m['mel_shape'])\n",
    "#    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "#    model.load_weights(filename)\n",
    "    return info_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat1 )\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_challenge_model2(model_folder, classes, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_challenge_model(model_folder, verbose = 1) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[0])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85110 4 4000\\nAV 85110_AV.hea 85110_AV.wav 85110_AV.tsv\\nPV 85110_PV.hea 85110_PV.wav 85110_PV.tsv\\nTV 85110_TV.hea 85110_TV.wav 85110_TV.tsv\\nMV 85110_MV.hea 85110_MV.wav 85110_MV.tsv\\n#Age: Child\\n#Sex: Male\\n#Height: 130.0\\n#Weight: 30.3\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: MV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Plateau\\n#Systolic murmur grading: II/VI\\n#Systolic murmur pitch: Low\\n#Systolic murmur quality: Blowing\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_challenge_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-54acaecfd6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_challenge_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecordings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### Teams: Implement this function!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_challenge_model' is not defined"
     ]
    }
   ],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model1, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(current_patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(current_patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(current_patient_data)\n",
    "    weight = get_weight(current_patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2032033e-03, 2.9272465e-03, 9.9586958e-01],\n",
       "       [3.2206599e-02, 7.0056088e-02, 8.9773726e-01],\n",
       "       [1.4683392e-04, 7.0860866e-04, 9.9914455e-01],\n",
       "       [1.8912905e-03, 6.9301804e-03, 9.9117857e-01]], dtype=float32)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    classes = model['classes']\n",
    "    imputer = model['imputer']\n",
    "    classifier = model['classifier']\n",
    "\n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(info_m['mel_shape'])\n",
    "    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "    model.load_weights(filename)\n",
    "    \n",
    "    # Load features.\n",
    "    features = get_features(data, recordings)\n",
    "\n",
    "    # Impute missing data.\n",
    "    features = features.reshape(1, -1)\n",
    "    features = imputer.transform(features)\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    probabilities = classifier.predict_proba(features)\n",
    "    probabilities = np.asarray(probabilities, dtype=np.float32)[:, 0, 1]\n",
    "\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    idx = np.argmax(probabilities)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1)}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[1])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85112 4 4000\\nAV 85112_AV.hea 85112_AV.wav 85112_AV.tsv\\nPV 85112_PV.hea 85112_PV.wav 85112_PV.tsv\\nTV 85112_TV.hea 85112_TV.wav 85112_TV.tsv\\nMV 85112_MV.hea 85112_MV.wav 85112_MV.tsv\\n#Age: Child\\n#Sex: Male\\n#Height: 136.0\\n#Weight: 26.3\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(patient_data)\n",
    "    weight = get_weight(patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0])],\n",
       " 'sex': [array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])],\n",
       " 'hw': [array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3])],\n",
       " 'preg': [False, False, False, False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 0., 1., 0.]),\n",
       "  array([0., 1., 0., 0., 0.])],\n",
       " 'mel1': [array([[  5.5544219 ,   5.25430448,   5.85624965, ...,  -4.01180172,\n",
       "           -2.62854908,  -2.5042349 ],\n",
       "         [ 10.42099442,   9.87717865,  14.38695231, ...,  -2.46004349,\n",
       "            1.79924639,  -4.51349842],\n",
       "         [ 11.33310424,  13.78394537,  13.1335616 , ...,   1.08339154,\n",
       "           -1.01365032,  -7.04751297],\n",
       "         ...,\n",
       "         [-18.90015848, -54.90594607, -58.1136186 , ..., -59.42052707,\n",
       "          -56.90998361, -48.85066669],\n",
       "         [-15.42566047, -52.71301415, -60.73131942, ..., -58.35870146,\n",
       "          -54.73361041, -52.19404219],\n",
       "         [-11.15672201, -51.57177258, -58.63095591, ..., -58.79083737,\n",
       "          -54.01102379, -52.62385897]]),\n",
       "  array([[ -5.34669814,   0.67031571,  -3.17846399, ..., -12.92143893,\n",
       "          -14.6734528 , -14.4765515 ],\n",
       "         [ -3.95126843,   6.31637984,  -4.64244314, ..., -10.39461407,\n",
       "          -10.63099409, -11.15637501],\n",
       "         [ -7.16954755,   2.46297333,  -0.85409502, ..., -10.59649951,\n",
       "          -12.49328981,   0.34125863],\n",
       "         ...,\n",
       "         [-34.42811144, -45.71171169, -59.00138537, ..., -50.40057535,\n",
       "          -56.65142888, -48.37946025],\n",
       "         [-36.29212611, -45.72542494, -61.35395916, ..., -49.05170214,\n",
       "          -58.97230698, -49.21394806],\n",
       "         [-34.86969307, -47.60865986, -61.69973905, ..., -51.1567752 ,\n",
       "          -61.31127645, -49.37548589]]),\n",
       "  array([[  1.68180672,  -3.96855903,  -9.31777817, ...,   0.59115272,\n",
       "          -13.3020849 , -12.12625751],\n",
       "         [  1.26698714,  -2.99167064, -12.70066591, ...,   6.97196192,\n",
       "          -11.43713667,  -3.81615562],\n",
       "         [  3.43579033,  -9.09430088, -10.03208319, ...,   6.05637143,\n",
       "          -11.2431155 ,  -4.3648029 ],\n",
       "         ...,\n",
       "         [-43.69433129, -54.66976803, -52.25798263, ..., -53.96021268,\n",
       "          -50.90066326, -48.80887587],\n",
       "         [-48.28895934, -55.59192024, -55.07810207, ..., -55.17842987,\n",
       "          -54.19418911, -49.81082227],\n",
       "         [-46.75922137, -56.52883698, -58.63612156, ..., -59.24551201,\n",
       "          -54.76376578, -48.53233825]]),\n",
       "  array([[-1.05357382e+01, -1.01090303e+01, -8.64615922e+00, ...,\n",
       "          -1.89183902e+01, -1.21077508e+01, -5.23639113e+00],\n",
       "         [-1.00548815e+01, -7.11764236e+00,  5.00336436e-02, ...,\n",
       "          -1.23953922e+01, -5.09774962e+00, -1.88250036e+00],\n",
       "         [-1.14629545e+01, -4.32136781e+00, -9.34656013e-02, ...,\n",
       "          -8.60415821e+00, -4.33791884e+00, -7.56818893e-01],\n",
       "         ...,\n",
       "         [-4.77923995e+01, -5.19989387e+01, -4.48201872e+01, ...,\n",
       "          -6.13758177e+01, -6.03041781e+01, -5.60282865e+01],\n",
       "         [-4.92251434e+01, -5.02118889e+01, -4.98856292e+01, ...,\n",
       "          -6.18184748e+01, -6.27257506e+01, -5.94607551e+01],\n",
       "         [-4.99104228e+01, -5.20431292e+01, -5.46581665e+01, ...,\n",
       "          -6.14256151e+01, -6.38957486e+01, -6.03423585e+01]])]}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_one(patient_data, verbose = 0) :\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    recording_information = patient_data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    features = dict()\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "        # Extract id\n",
    "    #    id1 = recording_file.split('_')[0]\n",
    "    #    features['id'].append(id1)\n",
    "\n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "        # Extract age_group\n",
    "        age_group = get_age(patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "\n",
    "        # Extract sex\n",
    "        sex = get_sex(patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "\n",
    "        # Extract height and weight.\n",
    "        height = get_height(patient_data)\n",
    "        weight = get_weight(patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "        \n",
    "        \n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "        \n",
    "    if verbose :\n",
    "        label = get_label(patient_data)\n",
    "        print(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = res1.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "probargmax = prob1.argmax()\n",
    "labels = np.zeros((3,))\n",
    "labels[probargmax] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(model['mel_shape'])\n",
    "    filename = os.path.join(model_folder, model['model'] + '_model.hdf5')\n",
    "    model1.load_weights(filename)\n",
    "    \n",
    "    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose)\n",
    "\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "    \n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    prob1 = res1.mean(axis = 0) ## simple rule for now\n",
    "    idx = np.argmax(prob1)\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.42289853, 0.02808568, 0.5490158 ], dtype=float32))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[0]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.21346666, 0.03261768, 0.7539156 ], dtype=float32))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[1]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.11145334, 0.01811697, 0.8704297 ], dtype=float32))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[2]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0769320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.09037623, 0.00931931, 0.90030444], dtype=float32))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[3]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0769710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.04683066, 0.00709078, 0.94607854], dtype=float32))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[4]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ones1 = []\n",
    "for i in range(100) :\n",
    "    patient_data = load_patient_data(patient_files_test[i])\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    if(num_locations == 1) :\n",
    "        ones1.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 32, 80, 94, 98]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0538710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.02266924, 0.06886302, 0.90846777], dtype=float32))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[24]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d07699e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([5.9274078e-04, 1.3342367e-02, 9.8606491e-01], dtype=float32))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[32]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f79d0538a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.01424488, 0.0106928 , 0.97506225], dtype=float32))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[80]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
