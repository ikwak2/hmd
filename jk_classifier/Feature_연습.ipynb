{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e8ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c749b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  5 16:26:31 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 460.91.03    Driver Version: 460.91.03    CUDA Version: 11.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "| 35%   35C    P8    24W / 260W |    310MiB / 11019MiB |      5%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A       998      G   /usr/lib/xorg/Xorg                 45MiB |\r\n",
      "|    0   N/A  N/A      1794      G   /usr/lib/xorg/Xorg                145MiB |\r\n",
      "|    0   N/A  N/A      2043      G   /usr/bin/gnome-shell               35MiB |\r\n",
      "|    0   N/A  N/A      2461      G   ...547988763393595631,131072       68MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe027b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-05 16:26:38.706652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:38.710488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:38.710816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:38.711270: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-05 16:26:38.712666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:38.713032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:38.713320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:39.140068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:39.140400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:39.140674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-05 16:26:39.140929: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9344 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-08-05 16:26:39.628942: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math\n",
    "import sys\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/notebooks')\n",
    "# sys.path.insert(0,'/home/jk21/Documents/hmd/jk_classifier/lucashnegri-peakutils-51a679cd8428')\n",
    "# sys.path.insert(0,'/home/jk21/Documents/hmd/jk_classifier/S1-S1-Phonocardiogram-Peak-Detection-Method-in-Python')\n",
    "sys.path.insert(0,'utils')\n",
    "from helper_code import *\n",
    "from get_feature import *\n",
    "from models import *\n",
    "from Generator0 import *\n",
    "from keras.preprocessing import sequence\n",
    "# import peakutils\n",
    "from scipy import special\n",
    "import scipy.io as sio\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sys.path.insert(0,'/home/jk21/Documents/hmd/jk_classifier/lucashnegri-peakutils-51a679cd8428')\n",
    "import peakutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad886dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jk21/Documents/hmd/jk_classifier'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a675dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'physionet.org/files/circor-heart-sound/1.0.3'\n",
    "# training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "# training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad114e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder =  'physionet.org/files/circor-heart-sound/1.0.3/training_data'\n",
    "train_folder =  '/home/jk21/Downloads/Data/data/murmur/train'\n",
    "test_folder = '/home/jk21/Downloads/Data/data/murmur/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aee102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'lcnn2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935b47fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fcf28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "    if e < start:\n",
    "        return lr_start\n",
    "    elif e > end:\n",
    "        return lr_end\n",
    "\n",
    "    middle = (start + end) / 2\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a08d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = find_patient_files(train_folder)\n",
    "patient_files_test = find_patient_files(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bc2dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature = {'samp_sec': 30,\n",
    "                  #### melspec, stft 피쳐 옵션들  \n",
    "                  'pre_emphasis': 0,\n",
    "                  'hop_length': 128,\n",
    "                  'win_length':256,\n",
    "                  'n_mels': 100,\n",
    "                  #### cqt 피쳐 옵션들  \n",
    "                  'filter_scale': 1,\n",
    "                  'n_bins': 80,\n",
    "                  'fmin': 10,\n",
    "                  'maxlen1': 120000,\n",
    "                  'min_dist':500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02bbe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_3lb_all(data_folder, patient_files_trn, \n",
    "                          samp_sec=20, pre_emphasis = 0, hop_length=256, win_length = 512, n_mels = 100,\n",
    "                          filter_scale = 1, n_bins = 80, fmin = 10, trim = 4000,maxlen1=120000,min_dist=1000,\n",
    "                         use_mel = True, use_cqt = False, use_stft= False, use_raw = False,use_interval = False,use_wav2=False\n",
    "                         ) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    features['cqt1'] = []\n",
    "    features['stft1'] = []\n",
    "    features['raw1'] = []\n",
    "    features['interval'] = []\n",
    "    features['wav2']=[]\n",
    "#    labels = []\n",
    "    features['mm_labels'] = []\n",
    "    features['out_labels'] = []\n",
    "    tmp_interval=[]\n",
    "    tmp_wav=[]\n",
    "    interval_len=[]\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_patient_files)):\n",
    "        \n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        \n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            if use_mel :\n",
    "                mel1 = feature_extract_melspec(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                               win_length = win_length, n_mels = n_mels, trim = trim)[0]\n",
    "            else :\n",
    "                mel1 = np.zeros( (1,1,1) )\n",
    "            features['mel1'].append(np.array(mel1))\n",
    "\n",
    "            if use_cqt :\n",
    "                mel2 = feature_extract_cqt(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, filter_scale = filter_scale, \n",
    "                                           n_bins = n_bins, fmin = fmin, trim = trim)[0]\n",
    "            else :\n",
    "                mel2 = np.zeros( (1,1,1))                \n",
    "            features['cqt1'].append(np.array(mel2))\n",
    "\n",
    "            if use_stft :\n",
    "                mel3 = feature_extract_stft(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                            win_length = win_length, trim = trim)[0]\n",
    "            else :\n",
    "                mel3 = np.zeros( (1,1,1) )\n",
    "            features['stft1'].append(np.array(mel3))\n",
    "\n",
    "            if use_raw :\n",
    "                recording1,frequency1 = librosa.load(filename)\n",
    "            else :\n",
    "                recording1 = np.zeros( (1) )\n",
    "            features['raw1'].append(recording1)\n",
    "            \n",
    "            if use_wav2:\n",
    "                recording1,frequency1 = librosa.load(filename)\n",
    "            else :\n",
    "                recording1 = np.zeros( (1) )\n",
    "            tmp_wav.append(recording1)                \n",
    "                \n",
    "            \n",
    "            if use_interval :\n",
    "                               \n",
    "                datos=sp.io.wavfile.read(filename)\n",
    "                filtros=sio.loadmat('/home/jk21/Documents/hmd/jk_classifier/S1-S1-Phonocardiogram-Peak-Detection-Method-in-Python/Filters1')\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    X=datos[1]\n",
    "                    X=X[trim*3:-trim*3]\n",
    "                    Fs=datos[0]\n",
    "            \n",
    "                    Fpa20=filtros['Fpa20'];\t\t\t        # High pass filter\n",
    "                    Fpa20=Fpa20[0];\t\t\t\t\t# High pass filter\n",
    "                    Fpb100=filtros['Fpb100'];\t\t        # Low-pass Filter\n",
    "                    Fpb100=Fpb100[0];\t\t\t\t# Low-pass Filter\n",
    "            \n",
    "                    Xf=FpassBand(X,Fpa20,Fpb100); \t                # Apply a passband filter\n",
    "                    Xf=vec_nor(Xf);\t\t\t\n",
    "            \n",
    "                    # Derivate of the Signal\n",
    "                    dX=derivate(Xf);\t\t\t\t# Derivate of the signal\n",
    "                    dX=vec_nor(dX);\t\t\t\t\t# Vector Normalizing\n",
    "                    # Square of the signal\n",
    "                    dy=np.square(Xf);\n",
    "                    dy=vec_nor(dy);\n",
    "                    \n",
    "                    size=np.shape(Xf)\t\t\t\t# Rank or dimension of the array\n",
    "                    fil=size[0];\t\t\t\t\t# Number of rows\n",
    "\n",
    "                    positive=np.zeros((1,fil+1));                   # Initializating Positives Values Vector \n",
    "                    positive=positive[0];                           # Getting the Vector\n",
    "\n",
    "                    points=np.zeros((1,fil));                       # Initializating the all Peak Points Vector\n",
    "                    points=points[0];                               # Getting the point vector\n",
    "\n",
    "                    peaks=np.zeros((1,fil));                        # Initializating the s1-s1 Peak Vector\n",
    "                    peaks=peaks[0];                                 # Getting the point vector\n",
    "\n",
    "            \n",
    "                    for i in range(0,fil):\n",
    "                        if dX[i]>0:\n",
    "                            positive[i]=1;\n",
    "                        else:\n",
    "                            positive[i]=0;\n",
    "\n",
    "                    for i in range(0,fil):\n",
    "                        if (positive[i]==1 and positive[i+1]==0):\n",
    "                            points[i]=Xf[i];\n",
    "                        else:\n",
    "                            points[i]=0;\n",
    "\n",
    "                    indexes=peakutils.indexes(points,thres=0.5/max(points), min_dist=1000);\n",
    "                    lenght=np.shape(indexes)\t\t\t# Get the length of the index vector\t\t\n",
    "                    lenght=lenght[0];\t\t\t\t# Get the value of the index vector\n",
    "\n",
    "                    for i in range(0,lenght):\n",
    "                        p=indexes[i];\n",
    "                        peaks[p]=points[p];\n",
    "        \n",
    "                    n=np.arange(0,fil);                            # Vector to the X axes (Number of Samples)\n",
    "            \n",
    "                    tmp_peaks = np.diff(indexes)\n",
    "                    \n",
    "                    \n",
    "                    tmp_interval.append(tmp_peaks)\n",
    "                    \n",
    "           \n",
    "                except:\n",
    "                    print(filename)\n",
    "                    tmp_peaks = np.zeros(maxlen)\n",
    "                    tmp_interval.append(tmp_peaks)\n",
    "                    \n",
    "            else :\n",
    "                        \n",
    "                tmp_peaks = np.zeros(maxlen)\n",
    "                tmp_interval.append(tmp_peaks)\n",
    "                \n",
    "      \n",
    "            \n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            ## simple impute\n",
    "            if math.isnan(height) :\n",
    "                height = 110.846\n",
    "            if math.isnan(weight) :\n",
    "                weight = 23.767\n",
    "                \n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "            mm_label = get_murmur(current_patient_data)\n",
    "            out_label = get_outcome(current_patient_data)\n",
    "            current_mm_labels = np.zeros(2)\n",
    "            current_out_labels = np.zeros(2)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([0, 0, 1])\n",
    "            elif mm_label == 'unknown' :\n",
    "                current_mm_labels = np.array([0, 1, 0])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.9, 0.05, 0.05])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if locations in mm_loc :\n",
    "                        current_mm_labels = np.array([1, 0, 0])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.7, 0.2, 0.1])\n",
    "\n",
    "            if out_label == 'Normal' :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "            else :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "#                if mm_label == 'Absent' :\n",
    "#                    current_out_labels = np.array([0.8, 0.2])\n",
    "#                elif mm_label == 'unknown' :\n",
    "#                    current_out_labels = np.array([0.85, 0.15])\n",
    "#                else :\n",
    "#                    current_out_labels = np.array([1, 0])\n",
    "                \n",
    "            features['mm_labels'].append(current_mm_labels)\n",
    "            features['out_labels'].append(current_out_labels)\n",
    "\n",
    "    if use_mel :\n",
    "        M, N = features['mel1'][0].shape\n",
    "        for i in range(len(features['mel1'])) :\n",
    "            \n",
    "            features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "            \n",
    "    else :\n",
    "        M, N, _ = features['mel1'][0].shape\n",
    "    print(\"melspec: \", M,N)\n",
    "    \n",
    "    mel_input_shape = (M,N,1)\n",
    "        \n",
    "    if use_cqt :\n",
    "        M, N= features['cqt1'][0].shape\n",
    "        for i in range(len(features['cqt1'])) :\n",
    "            features['cqt1'][i] = features['cqt1'][i].reshape(M,N,1)\n",
    "       \n",
    "    else :\n",
    "        M, N,__ = features['cqt1'][0].shape\n",
    "    print(\"cqt: \", M,N)\n",
    "    cqt_input_shape = (M,N,1)\n",
    "\n",
    "    \n",
    "    if use_stft :\n",
    "        M, N = features['stft1'][0].shape\n",
    "        for i in range(len(features['stft1'])) :\n",
    "            features['stft1'][i] = features['stft1'][i].reshape(M,N,1)\n",
    "        \n",
    "    else :\n",
    "        M, N ,__= features['stft1'][0].shape\n",
    "    print(\"stft: \", M,N)\n",
    "    stft_input_shape = (M,N,1)\n",
    "    \n",
    "    if use_interval:\n",
    "        \n",
    "        for i in range(len(tmp_interval)):\n",
    "            tmp_len = len(tmp_interval[i])\n",
    "            interval_len.append(tmp_len)\n",
    "        \n",
    "        \n",
    "        interval_len = np.array(interval_len)\n",
    "        max_interval_len = np.max(interval_len)\n",
    "        \n",
    "        padded =pad_sequences(tmp_interval, maxlen=max_interval_len, dtype='float64', padding='post', truncating='post', value=0.0)\n",
    "        \n",
    "        for i in range(len(padded)):\n",
    "            features['interval'].append(padded[i])\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(tmp_interval)):\n",
    "            features['interval'].append(tmp_interval[i])\n",
    "\n",
    "    if use_interval:\n",
    "        \n",
    "        for i in range(len(features['interval'])):\n",
    "            features['interval'][i]= features['interval'][i].reshape(-1,1)\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(features['interval'])):\n",
    "            features['interval'][i]= features['interval'][i].reshape(-1,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])          \n",
    "\n",
    "    \n",
    "    if use_wav2:\n",
    "        padded =pad_sequences(tmp_wav, maxlen=maxlen1, dtype='float64', padding='pre', truncating='pre', value=0.0)\n",
    "        tmp_pad = padded[:,np.newaxis,:]\n",
    "        \n",
    "        tmp=[]\n",
    "        for i in range(len(tmp_pad)):\n",
    "            tmp_feature = model(tmp_pad[i])\n",
    "            tmp.append(tmp_feature)\n",
    "            \n",
    "        tmp=np.array(tmp, dtype=np.float32)\n",
    "        new_tmp1=tmp.reshape(-1,374,32)\n",
    "        features['wav2']=new_tmp1\n",
    "        \n",
    "    \n",
    "    interval_input_shape = features['interval'].shape[1:]\n",
    "    \n",
    "    M,N = interval_input_shape\n",
    "    \n",
    "    print(\"interval: \", M,N)\n",
    "    \n",
    "    wav2_input_shape = features['wav2'].shape[1:]\n",
    "    \n",
    "    M,N = wav2_input_shape\n",
    "    \n",
    "    print(\"wav2: \", M,N)\n",
    "    \n",
    "    return features, mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,wav2_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ab5d137",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [01:08<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melspec:  100 938\n",
      "cqt:  1 1\n",
      "stft:  1 1\n",
      "interval:  52 1\n",
      "wav2:  374 32\n"
     ]
    }
   ],
   "source": [
    "features_trn,mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,wav2_input_shape = get_features_3lb_all(train_folder, patient_files_trn[:20], **params_feature,use_mel = True, use_cqt = False, use_stft = False,use_raw=False,use_interval=True,use_wav2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64fd08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e0958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847c786e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87418ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6935438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da1487a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00529ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c680b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbff874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf39e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eafe2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0f1679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd542d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
