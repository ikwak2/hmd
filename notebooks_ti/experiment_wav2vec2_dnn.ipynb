{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c585d668",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting transformers==4.11.3\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (1.20.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (768 kB)\n",
      "\u001b[K     |████████████████████████████████| 768 kB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (0.8.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (3.6.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[K     |████████████████████████████████| 880 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers==4.11.3) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.11.3) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers==4.11.3) (1.26.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.11.3) (1.16.0)\n",
      "Collecting click\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers==4.11.3) (1.0.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=f43bc280a4e6c5944a942a669a8e5124dfcd7932a983dd5285005fe556b6c97b\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, click, tokenizers, sacremoses, transformers\n",
      "Successfully installed click-8.1.3 regex-2022.7.25 sacremoses-0.0.53 tokenizers-0.10.3 transformers-4.11.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.8/site-packages (0.8.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.20.3)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.2.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: soundfile>=0.9.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: pooch>=1.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.3.0)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.0.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (5.0.9)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.6.3)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (0.36.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from numba>=0.43.0->librosa) (58.0.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (2.25.1)\n",
      "Requirement already satisfied: appdirs in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from pooch>=1.0->librosa) (20.9)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.8/site-packages (from resampy>=0.2.2->librosa) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.8/site-packages (from soundfile>=0.9.0->librosa) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->pooch>=1.0->librosa) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->pooch>=1.0->librosa) (1.26.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n",
      "Collecting python-Levenshtein==0.12.2\n",
      "  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from python-Levenshtein==0.12.2->jiwer) (58.0.4)\n",
      "Building wheels for collected packages: python-Levenshtein\n",
      "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp38-cp38-linux_x86_64.whl size=172291 sha256=4d2b007267be89a90cd30d461486c1870513524e6e8fa649d31e2f5aee24a20e\n",
      "  Stored in directory: /root/.cache/pip/wheels/d7/0c/76/042b46eb0df65c3ccd0338f791210c55ab79d209bcc269e2c7\n",
      "Successfully built python-Levenshtein\n",
      "Installing collected packages: python-Levenshtein, jiwer\n",
      "Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets>=1.18.3\n",
    "!pip install transformers==4.11.3\n",
    "!pip install librosa\n",
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f95722f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==0.8.1\n",
      "  Using cached torchaudio-0.8.1-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "Collecting torch==1.8.1\n",
      "  Using cached torch-1.8.1-cp38-cp38-manylinux1_x86_64.whl (804.1 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from torch==1.8.1->torchaudio==0.8.1) (1.20.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch==1.8.1->torchaudio==0.8.1) (3.10.0.0)\n",
      "Installing collected packages: torch, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0\n",
      "    Uninstalling torch-1.12.0:\n",
      "      Successfully uninstalled torch-1.12.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.12.0\n",
      "    Uninstalling torchaudio-0.12.0:\n",
      "      Successfully uninstalled torchaudio-0.12.0\n",
      "Successfully installed torch-1.8.1 torchaudio-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio==0.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b6697d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from jiwer import wer\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "\n",
    "# load model and tokenizer\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965c19d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureExtractor(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (2): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (3): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (4): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (5): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (6): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Linear(in_features=768, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8882f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "model.lm_head = nn.Sequential(\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(249*768,1024),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(1024,1),\n",
    "                nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0079eae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureExtractor(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2GroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (2): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (3): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (4): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (5): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "        (6): Wav2Vec2NoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2Encoder(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): Wav2Vec2EncoderLayer(\n",
       "          (attention): Wav2Vec2Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (lm_head): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=191232, out_features=1024, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
       "    (4): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99835470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from helper_code import *\n",
    "from tqdm import tqdm\n",
    "import pywt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle as pk\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from tools.utils import  get_class_distribution,get_class_distribution2,get_logger,  murmur_score,compute_weighted_accuracy\n",
    "sys.path.append(\"..\")\n",
    "from reader.data_reader_physionet import myDataLoader, myDataset\n",
    "import gc\n",
    "#from torch.utils.tensorboard import SummaryWriter\n",
    "from helper_code import *\n",
    "import numpy as np, scipy as sp, scipy.stats, os, sys, joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from models import *\n",
    "from get_feature import feature_extract_raw, get_feature_one, feature_extract_wavelet_raw\n",
    "import pickle as pk\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np, os, sys\n",
    "from helper_code import *\n",
    "from team_code import load_challenge_model, save_challenge_model\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a6f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f299938",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Data1/physionet/data_split/murmur/train'\n",
    "dev_folder = '/Data1/physionet/data_split/murmur/test'\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f2f4175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_folder, patient_files_trn, raw = True,rand = False) :\n",
    "    features = dict()\n",
    "\n",
    "    features['pw_raw'] = []\n",
    "    features['raw'] = []\n",
    "    features['mel1'] = []\n",
    "    murmurs = np.empty((0,2))#3))\n",
    "    labels = {}\n",
    "    \n",
    "    murmur_classes = ['Present', 'Absent'] # ,'Unknown'\n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in tqdm(range(num_patient_files)):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        if get_murmur(current_patient_data) != 'Present' :\n",
    "            murmur_location_information = 'nan'\n",
    "        else :\n",
    "            murmur_location_information = current_patient_data.split('\\n')[-15].split()[2].split('+')\n",
    "        \n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "            filename_location = recording_file.split('_')[1].split('.')[0]\n",
    "            \n",
    "            if raw :\n",
    "                raw1, n_samp = feature_extract_raw(filename,samp_sec=20)\n",
    "#                raw2, n_samp = feature_extract_wavelet_raw(filename,samp_sec=20)\n",
    "                features['raw'].extend(raw1)\n",
    "#                features['pw_raw'].extend(raw2)\n",
    "            # Extract melspec\n",
    "            else :\n",
    "                mel1 = feature_extract_raw_melspec(filename,rand)  # np > shape (n_samp,n_mels,time)(n,64,201)\n",
    "                \n",
    "                \n",
    "                n_samp = len(mel1)\n",
    "                features['mel1'].extend(mel1)\n",
    "\n",
    "\n",
    "            # Extract labels and use one-hot encoding.\n",
    "            \n",
    "            # 클래스 일단 3개지만 학습 데이터에선 loc 아니면 absent로 봄\n",
    "            \n",
    "            current_murmur = np.zeros((1,num_murmur_classes), dtype=int)  \n",
    "#            if (filename_location in murmur_location_information)  :\n",
    "#                murmur = get_murmur(current_patient_data)\n",
    "#            else :\n",
    "#                murmur = 'Absent'\n",
    "            murmur = get_murmur(current_patient_data)\n",
    "            if murmur in murmur_classes:\n",
    "                j = murmur_classes.index(murmur)\n",
    "                current_murmur[0][j] = 1\n",
    "            elif murmur == 'Unknown' :\n",
    "                current_murmur[0][0] = 0\n",
    "                current_murmur[0][1] = 1\n",
    "            current_murmur = np.repeat(current_murmur,n_samp,0)\n",
    "            murmurs = np.concatenate((murmurs,current_murmur),axis=0)\n",
    "            \n",
    "    \n",
    "    labels['murmur'] = murmurs\n",
    "    labels['outcome'] = []\n",
    "#    features['pw_raw'] = np.array(features['pw_raw'])\n",
    "    features['raw'] = np.array(features['raw'])\n",
    "    \n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed0a8aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "a = [1,0]\n",
    "b = [0.5,0.5]\n",
    "print(b.index(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200b460",
   "metadata": {},
   "source": [
    "# wav2vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "598f00cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features and labels from the Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 751/751 [00:02<00:00, 366.61it/s]\n",
      "100%|████████████████████████████████████████| 191/191 [00:00<00:00, 422.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# Find the patient data files.\n",
    "patient_files = find_patient_files(data_folder)\n",
    "dev_patient_files = find_patient_files(dev_folder)\n",
    "\n",
    "num_patient_files = len(patient_files)\n",
    "dev_num_patient_files = len(dev_patient_files)\n",
    "\n",
    "if num_patient_files==0:\n",
    "    raise Exception('No data was provided.')\n",
    "\n",
    "\n",
    "murmur_classes = ['Present', 'Absent'] # ,'Unknown'\n",
    "num_murmur_classes = len(murmur_classes)\n",
    "\n",
    "\n",
    "# Extract the features and labels.\n",
    "if verbose >= 1:\n",
    "    print('Extracting features and labels from the Challenge data...')\n",
    "\n",
    "features, labels = get_features(data_folder, patient_files)\n",
    "features_dev, labels_dev = get_features(dev_folder, dev_patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe59dc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2545"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['raw'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7277dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2545, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['murmur'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87721789",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7fe217a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 2545 training samples\n",
      "- 80 training batches\n",
      "- 639 testing samples\n",
      "- 20 testing batches\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [01:25<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:16 [MainProcess, 97247] [INFO ]  Iteration:0, loss = 0.433976, mur_f1 = 0.900, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:16 [MainProcess, 97247] [INFO ]  Iteration:0, valid_loss = 0.386338, valid_mur_f1 = 0.921, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:17 [MainProcess, 97247] [INFO ]  Iteration:1, loss = 0.290488, mur_f1 = 0.941, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:17 [MainProcess, 97247] [INFO ]  Iteration:1, valid_loss = 0.355470, valid_mur_f1 = 0.917, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:27<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:19 [MainProcess, 97247] [INFO ]  Iteration:2, loss = 0.278613, mur_f1 = 0.946, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:19 [MainProcess, 97247] [INFO ]  Iteration:2, valid_loss = 0.299618, valid_mur_f1 = 0.937, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:20 [MainProcess, 97247] [INFO ]  Iteration:3, loss = 0.236524, mur_f1 = 0.950, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:20 [MainProcess, 97247] [INFO ]  Iteration:3, valid_loss = 0.331172, valid_mur_f1 = 0.930, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:28<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:22 [MainProcess, 97247] [INFO ]  Iteration:4, loss = 0.224599, mur_f1 = 0.951, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:22 [MainProcess, 97247] [INFO ]  Iteration:4, valid_loss = 0.376456, valid_mur_f1 = 0.927, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:23 [MainProcess, 97247] [INFO ]  Iteration:5, loss = 0.210820, mur_f1 = 0.955, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:23 [MainProcess, 97247] [INFO ]  Iteration:5, valid_loss = 0.287896, valid_mur_f1 = 0.940, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:27<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:25 [MainProcess, 97247] [INFO ]  Iteration:6, loss = 0.188727, mur_f1 = 0.958, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:25 [MainProcess, 97247] [INFO ]  Iteration:6, valid_loss = 0.316140, valid_mur_f1 = 0.940, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:26 [MainProcess, 97247] [INFO ]  Iteration:7, loss = 0.177690, mur_f1 = 0.960, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:27 [MainProcess, 97247] [INFO ]  Iteration:7, valid_loss = 0.337919, valid_mur_f1 = 0.925, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:28 [MainProcess, 97247] [INFO ]  Iteration:8, loss = 0.179946, mur_f1 = 0.961, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:28 [MainProcess, 97247] [INFO ]  Iteration:8, valid_loss = 0.301318, valid_mur_f1 = 0.948, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:30 [MainProcess, 97247] [INFO ]  Iteration:9, loss = 0.144883, mur_f1 = 0.967, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:30 [MainProcess, 97247] [INFO ]  Iteration:9, valid_loss = 0.362733, valid_mur_f1 = 0.941, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:31 [MainProcess, 97247] [INFO ]  Iteration:10, loss = 0.146074, mur_f1 = 0.968, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:31 [MainProcess, 97247] [INFO ]  Iteration:10, valid_loss = 0.331184, valid_mur_f1 = 0.941, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:33 [MainProcess, 97247] [INFO ]  Iteration:11, loss = 0.132038, mur_f1 = 0.972, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:33 [MainProcess, 97247] [INFO ]  Iteration:11, valid_loss = 0.359303, valid_mur_f1 = 0.936, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:34 [MainProcess, 97247] [INFO ]  Iteration:12, loss = 0.123584, mur_f1 = 0.974, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:34 [MainProcess, 97247] [INFO ]  Iteration:12, valid_loss = 0.347909, valid_mur_f1 = 0.940, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:27<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:36 [MainProcess, 97247] [INFO ]  Iteration:13, loss = 0.114689, mur_f1 = 0.975, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:36 [MainProcess, 97247] [INFO ]  Iteration:13, valid_loss = 0.388715, valid_mur_f1 = 0.933, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:37 [MainProcess, 97247] [INFO ]  Iteration:14, loss = 0.095970, mur_f1 = 0.978, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:37 [MainProcess, 97247] [INFO ]  Iteration:14, valid_loss = 0.333813, valid_mur_f1 = 0.936, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:27<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:39 [MainProcess, 97247] [INFO ]  Iteration:15, loss = 0.076792, mur_f1 = 0.983, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:39 [MainProcess, 97247] [INFO ]  Iteration:15, valid_loss = 0.431105, valid_mur_f1 = 0.937, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:27<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:40 [MainProcess, 97247] [INFO ]  Iteration:16, loss = 0.069543, mur_f1 = 0.983, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:40 [MainProcess, 97247] [INFO ]  Iteration:16, valid_loss = 0.403745, valid_mur_f1 = 0.928, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:42 [MainProcess, 97247] [INFO ]  Iteration:17, loss = 0.076407, mur_f1 = 0.981, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:42 [MainProcess, 97247] [INFO ]  Iteration:17, valid_loss = 0.442599, valid_mur_f1 = 0.911, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:43 [MainProcess, 97247] [INFO ]  Iteration:18, loss = 0.071636, mur_f1 = 0.984, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:43 [MainProcess, 97247] [INFO ]  Iteration:18, valid_loss = 0.415529, valid_mur_f1 = 0.938, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [01:26<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:45 [MainProcess, 97247] [INFO ]  Iteration:19, loss = 0.055087, mur_f1 = 0.988, mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 20/20 [00:05<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-06 03:45 [MainProcess, 97247] [INFO ]  Iteration:19, valid_loss = 0.549353, valid_mur_f1 = 0.939, valid_mur_score = 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "log_dir = './log/'\n",
    "project = 'toy0'\n",
    "logger = get_logger(log_dir + '/' + project)\n",
    "\n",
    "#train\n",
    "label_mur = np.empty(len(labels['murmur']))\n",
    "for i,l in enumerate(labels['murmur']) :\n",
    "    try :\n",
    "        label_mur[i] = int(list(l).index(1))\n",
    "    except :\n",
    "        label_mur[i] = 0.5\n",
    "label_out = np.empty(len(labels['outcome']))\n",
    "for i,l in enumerate(labels['outcome']) :\n",
    "    label_out[i] = int(list(l).index(1))\n",
    "label = {'murmur':label_mur, 'outcome':label_out}\n",
    "\n",
    "#dev\n",
    "label_mur_dev = np.empty(len(labels_dev['murmur']))\n",
    "for i,l in enumerate(labels_dev['murmur']) :\n",
    "    try :\n",
    "        label_mur_dev[i] = int(list(l).index(1))\n",
    "    except :\n",
    "        label_mur_dev[i] = 0.5\n",
    "label_out_dev = np.empty(len(labels_dev['outcome']))\n",
    "for i,l in enumerate(labels_dev['outcome']) :\n",
    "    label_out_dev[i] = int(list(l).index(1))\n",
    "label_dev = {'murmur':label_mur_dev, 'outcome':label_out_dev}\n",
    "\n",
    "#    class_count = [i for i in get_class_distribution(label_mur).values()]\n",
    "#    class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
    "\n",
    "class_weights = torch.tensor([5/9,4/9],dtype=torch.float)\n",
    "\n",
    "dataset_train = myDataset(features, label,mode ='murmur')\n",
    "dataloader_train = myDataLoader(dataset=dataset_train,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)\n",
    "all_file_train = len(dataloader_train)\n",
    "if verbose >= 1:\n",
    "    print(\"- {} training samples\".format(len(dataset_train)))\n",
    "    print(\"- {} training batches\".format(len(dataloader_train)))\n",
    "dataset_dev = myDataset(features_dev, label_dev,mode ='murmur')\n",
    "dataloader_dev = myDataLoader(dataset=dataset_dev,\n",
    "                                batch_size=32,\n",
    "                                shuffle=True,\n",
    "                                num_workers=0)\n",
    "all_file_dev = len(dataloader_dev)\n",
    "if verbose >= 1:\n",
    "    print(\"- {} testing samples\".format(len(dataset_dev)))\n",
    "    print(\"- {} testing batches\".format(len(dataloader_dev)))\n",
    "\n",
    "\n",
    "#nnet = LCNN(mode = 'murmur')\n",
    "#nnet = nnet.cuda()\n",
    "nnet = model.cuda()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "sig = nn.Sigmoid()\n",
    "\n",
    "optimizer = optim.Adam(nnet.parameters(), lr=1e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.97)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Train the model.\n",
    "if verbose >= 1:\n",
    "    print('Training model...')\n",
    "\n",
    "\n",
    "for iter_ in range(20):  # args.end_iter\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    train_epoch_mur_f1 = 0.0\n",
    "\n",
    "    nnet.train()\n",
    "\n",
    "    pre_train = []\n",
    "    label_train = []\n",
    "\n",
    "    for audio_feature, data_label_torch in tqdm(dataloader_train): \n",
    "\n",
    "#            alpha =np.random.randint(4,10)/10\n",
    "#            lam = np.random.beta(alpha,alpha)\n",
    "#            audio_feature =  torch.cat([audio_feature,lam*audio_feature + (1.0-lam)*audio_feature2], dim=1)\n",
    "#            data_label_torch_mur = torch.cat([data_label_torch_mur,lam*data_label_torch_mur + (1.0-lam)*data_label_torch_mur2], dim=0)\n",
    "#        print(audio_feature.shape)\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        audio_feature = audio_feature.permute(1,0)\n",
    "#        audio_feature = audio_feature.unsqueeze(1)\n",
    "        audio_feature[audio_feature != audio_feature] = 0\n",
    "        audio_feature= torch.nan_to_num(audio_feature,nan=1e-6)+1e-6\n",
    "\n",
    "        audio_feature = audio_feature.float().cuda()\n",
    "\n",
    "        data_label_torch = data_label_torch.cuda()\n",
    "        data_label_torch = data_label_torch.long()\n",
    "\n",
    "#        print(audio_feature.shape)\n",
    "        outputs = nnet(audio_feature).logits\n",
    "\n",
    "#        print(type(outputs))\n",
    "#        print(outputs)\n",
    "        loss = criterion(outputs.float().squeeze(1), data_label_torch.float().squeeze(1))\n",
    "#        print(outputs)\n",
    "#        print(loss)\n",
    "        \n",
    "#        y_pred_softmax = softmax(outputs.float())\n",
    "#        y_pred_softmax = F.log_softmax(outputs.float(), dim = 1)\n",
    "#        _, output_tags = torch.max(outputs.float(), dim = 1)\n",
    "#        _, output_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "#        print(outputs)\n",
    "        output_tags = torch.ceil(outputs-0.5)\n",
    "#        print(output_tags)\n",
    "        output_tags = output_tags.detach().cpu().numpy()#.data.cpu().numpy()\n",
    "        data_label_torch = data_label_torch.data.cpu().numpy()\n",
    "        result = np.append(output_tags,data_label_torch,axis=1)\n",
    "#        print('result : ',result)\n",
    "        train_mur_f1 = f1_score(data_label_torch, output_tags)#, average='macro')\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        train_epoch_mur_f1 += train_mur_f1.item()\n",
    "\n",
    "        pre_train.extend(list(output_tags))\n",
    "        label_train.extend(list(data_label_torch))\n",
    "    pre_train[-1] = 0\n",
    "    pre_train[-2] = 1\n",
    "    label_train[-1] = np.array([0])\n",
    "    label_train[-2] = np.array([1])\n",
    "#    score_train = compute_weighted_accuracy(np.array(pre_train),np.array(label_train),'murmur')\n",
    "    score_train =0\n",
    "    logger.info(\"Iteration:{0}, loss = {1:.6f}, mur_f1 = {2:.3f}, mur_score = {3:.3f}\".format(iter_, running_loss/all_file_train, train_epoch_mur_f1/all_file_train, score_train))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        running_loss_dev = 0.0\n",
    "        dev_epoch_f1 = 0.0\n",
    "\n",
    "\n",
    "        pre_list = []\n",
    "        label_list = []\n",
    "        for audio_feature_dev, data_label_torch_dev  in tqdm(dataloader_dev) : \n",
    "            \n",
    "            audio_feature_dev = audio_feature_dev.permute(1,0)\n",
    "#            audio_feature_dev = audio_feature_dev.unsqueeze(1)\n",
    "            audio_feature_dev[audio_feature_dev != audio_feature_dev] = 0\n",
    "            audio_feature_dev = torch.nan_to_num(audio_feature_dev,nan=1e-6)+1e-6\n",
    "            audio_feature_dev = audio_feature_dev.float().cuda()           \n",
    "            label_dev = data_label_torch_dev\n",
    "\n",
    "            label_dev = label_dev.cuda()\n",
    "            label_dev = label_dev.long()\n",
    "\n",
    "            outputs_dev = nnet(audio_feature_dev).logits\n",
    "#            print(outputs_dev[0])\n",
    "\n",
    "            loss_dev = criterion(outputs_dev.float().squeeze(1), label_dev.float().squeeze(1))\n",
    "#            y_pred_softmax = softmax(outputs_dev.float())\n",
    "#            y_pred_softmax = F.log_softmax(outputs_dev.float(), dim = 1)\n",
    "#            _, output_tags = torch.max(outputs_dev.float(), dim = 1)\n",
    "#            _, output_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "            output_tags = torch.ceil(outputs_dev-0.5)\n",
    "            output_tags = output_tags.detach().cpu().numpy()#.data.cpu().numpy()\n",
    "            label_dev = label_dev.data.cpu().numpy()\n",
    "\n",
    "            dev_f1 = f1_score(label_dev, output_tags)#, average='macro')\n",
    "\n",
    "            running_loss_dev += loss_dev.item()\n",
    "            dev_epoch_f1 += dev_f1.item()\n",
    "            pre_list.extend(list(output_tags))\n",
    "            label_list.extend(list(label_dev))\n",
    "        pre_list[-1] = 0\n",
    "        pre_list[-2] = 1\n",
    "#        pre_list[-3] = 2\n",
    "        label_list[-1] = np.array([0])\n",
    "        label_list[-2] = np.array([1])\n",
    "#        label_list[-3] = np.array([2])\n",
    "     \n",
    "#        score_dev = compute_weighted_accuracy(np.array(pre_list),np.array(label_list),'murmur')\n",
    "        score_dev = 0\n",
    "        logger.info(\"Iteration:{0}, valid_loss = {1:.6f}, valid_mur_f1 = {2:.3f}, valid_mur_score = {3:.3f}\".format(iter_, running_loss_dev/all_file_dev, dev_epoch_f1/all_file_dev, score_dev))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796ad968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e541d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7b28a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37cb1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'w2v2_model_dnn'\n",
    "outcome_classes = ['Abnormal','Normal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97057712",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_challenge_model(model_folder, nnet,nnet, murmur_classes, outcome_classes, m_name = 'toy_ti', mel_shape = (100,313) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3b0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_models(model, data, recordings, verbose,thres):\n",
    "    torch.cuda.empty_cache()\n",
    "#    if model['model'] == 'toy_ti' :\n",
    "#        model1 = get_toy(model['mel_shape'])\n",
    "#    model1.load_weights(model['model_fnm'])\n",
    "    GPU_NUM = 0 # 원하는 GPU 번호 입력\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "#    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "\n",
    "#    if model['model'] == 'toy_ti' :\n",
    "#        trained_model =  torch.load(model['mur_model_fnm'])\n",
    "#        trained_model2 =  torch.load(model['out_model_fnm'])\n",
    "#        print(trained_model)\n",
    "#        nnet = LCNN(mode = 'murmur')\n",
    "#        nnet.load_state_dict(trained_model)\n",
    "#        nnet = nnet.cuda()\n",
    "#        nnet2 = LCNN(mode = 'murmur')\n",
    "#        nnet2.load_state_dict(trained_model2)\n",
    "#        nnet2 = nnet2.cuda()\n",
    "        #print('*')\n",
    "    nnet = model\n",
    "    nnet2 = model\n",
    "    nnet = nnet.cuda()\n",
    "    nnet2 = nnet2.cuda()\n",
    "    nnet.eval()\n",
    "    nnet2.eval()\n",
    "#    print(nnet)\n",
    "        \n",
    "#    murmur_classes = model['murmur_classes']\n",
    "#    outcome_classes = model['outcome_classes']\n",
    "    murmur_classes = ['Present','Unknown', 'Absent'] # \n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    num_outcome_classes = len(outcome_classes)\n",
    "\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "    probab1 = np.empty((0,2))\n",
    "    probab2 = np.empty((0,2))\n",
    "    for i in range(len(recordings)) :\n",
    "#        print(recordings[i])\n",
    "        audio_feature,_ = feature_extract_raw(recordings[i]/ 32768,samp_sec=20)\n",
    "#        print(type(audio_feature))\n",
    "        audio_feature = torch.from_numpy(np.array(audio_feature))\n",
    "        audio_feature[audio_feature != audio_feature] = 0\n",
    "        audio_feature = torch.nan_to_num(audio_feature,nan=1e-6) +1e-6\n",
    "        audio_feature = audio_feature.float().cuda()\n",
    "#        audio_feature = audio_feature.unsqueeze(1)\n",
    "#        audio_feature = audio_feature.permute(1,0,2)\n",
    "        \n",
    "#64, 1, 1, 157\n",
    "        outputs = nnet(audio_feature).logits\n",
    "        outputs2 = nnet2(audio_feature).logits\n",
    "#        print(outputs)\n",
    "#        print('outputs2 : ',outputs2)\n",
    "#        softmax = nn.Softmax(dim = 1)\n",
    "#        outputs_murmur = F.log_softmax(outputs.float(), dim = 1)\n",
    "#        outputs_outcome = F.log_softmax(outputs2.float(), dim = 1)#\n",
    "#        outputs_murmur = softmax(outputs)\n",
    "#        outputs_outcome = softmax(outputs2)\n",
    "        outputs_murmur = outputs\n",
    "        outputs_outcome = outputs2\n",
    "        outputs_murmur = torch.cat((1-outputs_murmur,outputs_murmur),dim = 1)\n",
    "        outputs_outcome = torch.cat((1-outputs_outcome,outputs_outcome),dim = 1)\n",
    "#        print('outputs_murmur : ',outputs_murmur)\n",
    "        prob1 = outputs_murmur.mean(axis = 0).reshape(1,2) \n",
    "        prob1 = prob1.data.cpu().numpy()\n",
    "        probab1 = np.concatenate((probab1,prob1),axis=0)\n",
    "\n",
    "        prob2 = outputs_outcome.mean(axis = 0).reshape(1,2) \n",
    "        prob2 = prob2.data.cpu().numpy()\n",
    "        probab2 = np.concatenate((probab2,prob2),axis=0)\n",
    "        \n",
    "    p1 = probab1.max(axis=0)\n",
    "    p2 = probab2.max(axis=0)\n",
    "    \n",
    "        \n",
    "    \n",
    "#    print('p1 :',p1)\n",
    "#    print('p2 :',p2)\n",
    "        \n",
    "        \n",
    "    # Get classifier probabilities.\n",
    "#    idx = np.argmax(p1)\n",
    "    if p1[0]>thres:\n",
    "        idx = 0\n",
    "    else :\n",
    "        idx = 2\n",
    "#    idx2 = np.argmax(p2)\n",
    "    if p2[0]>0.25 :\n",
    "        idx2 = 0\n",
    "    else :\n",
    "        idx2 = 1\n",
    "\n",
    "    n_p1 = np.zeros(len(murmur_classes))\n",
    "    n_p1[0] = p1[0]\n",
    "    n_p1[1] = 0\n",
    "    n_p1[2] = p1[1]\n",
    "    # Choose label with higher probability.\n",
    "    labels_murmur = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "    labels_murmur[idx] = 1\n",
    "    labels_outcome = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "    labels_outcome[idx2] = 1\n",
    "    \n",
    "    classes = murmur_classes + outcome_classes\n",
    "    labels = np.concatenate((labels_murmur, labels_outcome))\n",
    "    probabilities = np.concatenate((n_p1, p2))\n",
    "\n",
    "    return classes, labels, probabilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e57e0fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "# Do *not* edit this script. Changes will be discarded so that we can process the models consistently.\n",
    "\n",
    "# This file contains functions for running models for the 2022 Challenge. You can run it as follows:\n",
    "#\n",
    "#   python run_model.py model data outputs\n",
    "#\n",
    "# where 'model' is a folder containing the your trained model, 'data' is a folder containing the Challenge data, and 'outputs' is a\n",
    "# folder for saving your model's outputs.\n",
    "\n",
    "import numpy as np, os, sys\n",
    "from helper_code import *\n",
    "from team_code import load_challenge_model#, run_challenge_model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Run model.\n",
    "def run_models(model_folder, data_folder, output_folder, allow_failures, verbose,thres):\n",
    "    torch.cuda.empty_cache()\n",
    "    # Load models.\n",
    "    if verbose >= 1:\n",
    "        print('Loading Challenge model...')\n",
    "        \n",
    "    model = load_challenge_model(model_folder, verbose)\n",
    "    \n",
    "    # Find the patient data files.\n",
    "    patient_files = find_patient_files(data_folder)\n",
    "    num_patient_files = len(patient_files)\n",
    "\n",
    "    if num_patient_files==0:\n",
    "        raise Exception('No data was provided.')\n",
    "\n",
    "    # Create a folder for the Challenge outputs if it does not already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Run the team's model on the Challenge data.\n",
    "    if verbose >= 1:\n",
    "        print('Running model on Challenge data...')\n",
    "##########################\n",
    "    # Iterate over the patient files.\n",
    "    for i in tqdm(range(num_patient_files)):\n",
    "        if verbose >= 2:\n",
    "            print('    {}/{}...'.format(i+1, num_patient_files))\n",
    "\n",
    "        patient_data = load_patient_data(patient_files[i])\n",
    "        recordings = load_recordings(data_folder, patient_data)\n",
    "\n",
    "        # Allow or disallow the model to fail on parts of the data; helpful for debugging.\n",
    "        try:\n",
    "            classes, labels, probabilities = run_challenge_models(nnet, patient_data, recordings, verbose,thres) ### Teams: Implement this function!!!\n",
    "\n",
    "        except:\n",
    "            if allow_failures:\n",
    "                if verbose >= 2:\n",
    "                    print('... failed.')\n",
    "                classes, labels, probabilities = list(), list(), list()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Save Challenge outputs.\n",
    "        head, tail = os.path.split(patient_files[i])\n",
    "        root, extension = os.path.splitext(tail)\n",
    "        output_file = os.path.join(output_folder, root + '.csv')\n",
    "        patient_id = get_patient_id(patient_data)\n",
    "        save_challenge_outputs(output_file, patient_id, classes, labels, probabilities)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print('Done.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a089e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'w2v2_model_dnn'\n",
    "output_folder = 'w2v2_output_dnn'\n",
    "allow_failures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9db713e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:15<00:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_models(model_folder, dev_folder, output_folder, allow_failures, verbose,thres= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731765c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b102527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "250e5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python evaluate_model.py /Data1/physionet/data_split/murmur/test w2v2_output scores_w2v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a13c4cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\r\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\r\n",
      "0.783,0.636,0.483,0.733,0.765,14978.600\r\n",
      "\r\n",
      "#Outcome scores\r\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\r\n",
      "0.651,0.664,0.586,0.586,0.583,14216.054\r\n",
      "\r\n",
      "#Murmur scores (per class)\r\n",
      "Classes,Present,Unknown,Absent\r\n",
      "AUROC,0.957,0.500,0.893\r\n",
      "AUPRC,0.883,0.073,0.953\r\n",
      "F-measure,0.626,0.000,0.822\r\n",
      "Accuracy,0.947,0.000,0.748\r\n",
      "\r\n",
      "#Outcome scores (per class)\r\n",
      "Classes,Abnormal,Normal\r\n",
      "AUROC,0.633,0.668\r\n",
      "AUPRC,0.708,0.620\r\n",
      "F-measure,0.591,0.582\r\n",
      "Accuracy,0.582,0.591\r\n"
     ]
    }
   ],
   "source": [
    "!cat scores_w2v2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671d7a8",
   "metadata": {},
   "source": [
    "# wav2vec2 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf2cd7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:20<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.1\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.509,0.770,0.795,15762.962\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.679,0.000,0.849\n",
      "Accuracy,0.974,0.000,0.791\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:22<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.13\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.517,0.780,0.801,16167.544\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.692,0.000,0.858\n",
      "Accuracy,0.974,0.000,0.806\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:40<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.16\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.515,0.780,0.790,16364.265\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.686,0.000,0.859\n",
      "Accuracy,0.947,0.000,0.813\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:19<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.19\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.519,0.785,0.792,16358.465\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.692,0.000,0.864\n",
      "Accuracy,0.947,0.000,0.820\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:21<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.22\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.526,0.796,0.798,16766.748\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.706,0.000,0.872\n",
      "Accuracy,0.947,0.000,0.835\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:20<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.25\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.524,0.796,0.787,16966.900\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.700,0.000,0.873\n",
      "Accuracy,0.921,0.000,0.842\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:21<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.28\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.532,0.806,0.792,16958.817\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.714,0.000,0.881\n",
      "Accuracy,0.921,0.000,0.856\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:22<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.31\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.540,0.817,0.798,17161.248\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.729,0.000,0.890\n",
      "Accuracy,0.921,0.000,0.871\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:25<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.34\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.540,0.817,0.798,17161.248\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.729,0.000,0.890\n",
      "Accuracy,0.921,0.000,0.871\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:37<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.37\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.544,0.822,0.801,17158.131\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.737,0.000,0.894\n",
      "Accuracy,0.921,0.000,0.878\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:35<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.4\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.544,0.822,0.801,17158.131\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.737,0.000,0.894\n",
      "Accuracy,0.921,0.000,0.878\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:34<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.43\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.545,0.822,0.801,17155.250\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.745,0.000,0.891\n",
      "Accuracy,0.921,0.000,0.878\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:35<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.46\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.545,0.822,0.801,17155.250\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.745,0.000,0.891\n",
      "Accuracy,0.921,0.000,0.878\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:33<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.49\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.549,0.827,0.803,17362.018\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.753,0.000,0.895\n",
      "Accuracy,0.921,0.000,0.885\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:34<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.52\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.549,0.827,0.803,17362.018\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.753,0.000,0.895\n",
      "Accuracy,0.921,0.000,0.885\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:37<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.55\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.551,0.827,0.803,17569.000\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.761,0.000,0.891\n",
      "Accuracy,0.921,0.000,0.885\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:33<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.58\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.549,0.827,0.792,17774.138\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.756,0.000,0.892\n",
      "Accuracy,0.895,0.000,0.892\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:35<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.61\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.558,0.838,0.798,17770.578\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.773,0.000,0.900\n",
      "Accuracy,0.895,0.000,0.906\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:29<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.64\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.558,0.838,0.798,17770.578\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.773,0.000,0.900\n",
      "Accuracy,0.895,0.000,0.906\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:24<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.67\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.559,0.838,0.798,17978.467\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.782,0.000,0.897\n",
      "Accuracy,0.895,0.000,0.906\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.7\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.559,0.838,0.798,17978.467\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.782,0.000,0.897\n",
      "Accuracy,0.895,0.000,0.906\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.73\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.564,0.843,0.801,18186.507\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.791,0.000,0.901\n",
      "Accuracy,0.895,0.000,0.914\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:05<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.76\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.568,0.848,0.803,18185.263\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.800,0.000,0.905\n",
      "Accuracy,0.895,0.000,0.921\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = list(range(10,78,3))\n",
    "for t in a :\n",
    "    run_models(model_folder, dev_folder, output_folder, allow_failures, verbose,thres = t/100)\n",
    "    time.sleep(2)\n",
    "    print('threshold : ',t/100)\n",
    "    !python evaluate_model.py /Data1/physionet/data_split/murmur/test w2v2_output_dnn scores_w2v2_dnn.csv\n",
    "    !cat scores_w2v2_dnn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c35b3894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.78\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.570,0.848,0.803,18393.574\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.810,0.000,0.901\n",
      "Accuracy,0.895,0.000,0.921\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.81\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.579,0.859,0.809,18601.128\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.829,0.000,0.909\n",
      "Accuracy,0.895,0.000,0.935\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:05<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.84\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.579,0.859,0.809,18601.128\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.829,0.000,0.909\n",
      "Accuracy,0.895,0.000,0.935\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:08<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.87\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.579,0.859,0.809,18601.128\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.829,0.000,0.909\n",
      "Accuracy,0.895,0.000,0.935\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.9\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.594,0.874,0.817,18808.496\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.861,0.000,0.920\n",
      "Accuracy,0.895,0.000,0.957\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:05<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.93\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.582,0.864,0.790,19226.374\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.831,0.000,0.914\n",
      "Accuracy,0.842,0.000,0.957\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:06<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.96\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.582,0.864,0.790,19226.374\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.831,0.000,0.914\n",
      "Accuracy,0.842,0.000,0.957\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n",
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 191/191 [05:09<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "threshold :  0.99\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.764,0.625,0.571,0.859,0.744,20062.190\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.648,0.651,0.591,0.602,0.485,16966.900\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.961,0.500,0.830\n",
      "AUPRC,0.904,0.073,0.899\n",
      "F-measure,0.800,0.000,0.913\n",
      "Accuracy,0.737,0.000,0.978\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.650,0.647\n",
      "AUPRC,0.724,0.579\n",
      "F-measure,0.525,0.658\n",
      "Accuracy,0.429,0.785\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "a = list(range(78,100,3))\n",
    "for t in a :\n",
    "    run_models(model_folder, dev_folder, output_folder, allow_failures, verbose,thres = t/100)\n",
    "    time.sleep(2)\n",
    "    print('threshold : ',t/100)\n",
    "    !python evaluate_model.py /Data1/physionet/data_split/murmur/test w2v2_output_dnn scores_w2v2_dnn.csv\n",
    "    !cat scores_w2v2_dnn.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986866c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96e1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c53974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
