{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c017699",
   "metadata": {},
   "source": [
    "python evaluate_model.py labels outputs scores.csv class_scores.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b0af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, os.path, sys, numpy as np\n",
    "from helper_code import load_patient_data, get_label, load_challenge_outputs, compare_strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fce69",
   "metadata": {},
   "source": [
    "classes, auroc, auprc, auroc_classes, auprc_classes, accuracy, f_measure, f_measure_classes, challenge_score  = evaluate_model(labels, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de77606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder = '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data'\n",
    "output_folder = '/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f77a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "def evaluate_model(label_folder, output_folder):\n",
    "    # Define classes.\n",
    "    classes = ['Present', 'Unknown', 'Absent']\n",
    "\n",
    "    # Load the label and output files and reorder them, if needed, for consistency.\n",
    "    label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "    labels = load_labels(label_files, classes)\n",
    "    binary_outputs, scalar_outputs = load_classifier_outputs(output_files, classes)\n",
    "\n",
    "    # For each patient, set the 'Unknown' class to positive if no class is positive or if multiple classes are positive.\n",
    "    labels = enforce_positives(labels, classes, 'Unknown')\n",
    "    binary_outputs = enforce_positives(binary_outputs, classes, 'Unknown')\n",
    "\n",
    "    # Evaluate the model by comparing the labels and outputs.\n",
    "    auroc, auprc, auroc_classes, auprc_classes = compute_auc(labels, scalar_outputs)\n",
    "    accuracy = compute_accuracy(labels, binary_outputs)\n",
    "    f_measure, f_measure_classes = compute_f_measure(labels, binary_outputs)\n",
    "    challenge_score = compute_challenge_score(labels, binary_outputs, classes)\n",
    "\n",
    "    # Return the results.\n",
    "    return classes, auroc, auprc, auroc_classes, auprc_classes, accuracy, f_measure, f_measure_classes, challenge_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87148bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find Challenge files.\n",
    "def find_challenge_files(label_folder, output_folder):\n",
    "    label_files = list()\n",
    "    output_files = list()\n",
    "    for label_file in sorted(os.listdir(label_folder)):\n",
    "        label_file_path = os.path.join(label_folder, label_file) # Full path for label file\n",
    "        if os.path.isfile(label_file_path) and label_file.lower().endswith('.txt') and not label_file.lower().startswith('.'):\n",
    "            root, ext = os.path.splitext(label_file)\n",
    "            output_file = root + '.csv'\n",
    "            output_file_path = os.path.join(output_folder, output_file) # Full path for corresponding output file\n",
    "            if os.path.isfile(output_file_path):\n",
    "                label_files.append(label_file_path)\n",
    "                output_files.append(output_file_path)\n",
    "            else:\n",
    "                raise IOError('Output file {} not found for label file {}.'.format(output_file, label_file))\n",
    "\n",
    "    if label_files and output_files:\n",
    "        return label_files, output_files\n",
    "    else:\n",
    "        raise IOError('No label or output files found.')\n",
    "        \n",
    "# Load labels from header/label files.\n",
    "def load_labels(label_files, classes):\n",
    "    num_patients = len(label_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the labels.\n",
    "    labels = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        data = load_patient_data(label_files[i])\n",
    "        label = get_label(data)\n",
    "        for j, x in enumerate(classes):\n",
    "            if compare_strings(label, x):\n",
    "                labels[i, j] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Load outputs from output files.\n",
    "def load_classifier_outputs(output_files, classes):\n",
    "    # The outputs should have the following form:\n",
    "    #\n",
    "    # #Record ID\n",
    "    # class_1, class_2, class_3\n",
    "    #       0,       1,       1\n",
    "    #    0.12,    0.34,    0.56\n",
    "    #\n",
    "    num_patients = len(output_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the outputs.\n",
    "    binary_outputs = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "    scalar_outputs = np.zeros((num_patients, num_classes), dtype=np.float64)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        patient_id, patient_classes, patient_binary_outputs, patient_scalar_outputs = load_challenge_outputs(output_files[i])\n",
    "\n",
    "        # Allow for unordered or reordered classes.\n",
    "        for j, x in enumerate(classes):\n",
    "            for k, y in enumerate(patient_classes):\n",
    "                if compare_strings(x, y):\n",
    "                    binary_outputs[i, j] = patient_binary_outputs[k]\n",
    "                    scalar_outputs[i, j] = patient_scalar_outputs[k]\n",
    "\n",
    "    return binary_outputs, scalar_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3351ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "    classes = ['Present', 'Unknown', 'Absent']\n",
    "\n",
    "    # Load the label and output files and reorder them, if needed, for consistency.\n",
    "    label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "    labels = load_labels(label_files, classes)\n",
    "    binary_outputs, scalar_outputs = load_classifier_outputs(output_files, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f664f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/13918.txt',\n",
       " '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/14241.txt',\n",
       " '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/14998.txt',\n",
       " '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/23625.txt',\n",
       " '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/24160.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ab986b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1/13918.csv',\n",
       " '/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1/14241.csv',\n",
       " '/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1/14998.csv',\n",
       " '/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1/23625.csv',\n",
       " '/home/ubuntu/hmd/notebooks/our_classifier/tmp_out1/24160.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317c083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab834f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_outputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "113a68a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7154979 , 0.01438679, 0.27011532],\n",
       "       [0.69156986, 0.09864295, 0.20978718],\n",
       "       [0.04368902, 0.00971327, 0.9465977 ],\n",
       "       [0.31963044, 0.00296787, 0.67740166],\n",
       "       [0.05136017, 0.01008513, 0.9385547 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar_outputs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7c8948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each patient, set a specific class to positive if no class is positive or multiple classes are positive.\n",
    "def enforce_positives(outputs, classes, positive_class):\n",
    "    num_patients, num_classes = np.shape(outputs)\n",
    "    j = classes.index(positive_class)\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        if np.sum(outputs[i, :]) != 1:\n",
    "            outputs[i, :] = 0\n",
    "            outputs[i, j] = 1\n",
    "    return outputs\n",
    "\n",
    "# Compute a binary confusion matrix, where the columns are expert labels and rows are classifier labels.\n",
    "def compute_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels)==np.shape(outputs))\n",
    "    assert(all(value in (0, 1) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = np.zeros((num_classes, num_classes))\n",
    "    for k in range(num_patients):\n",
    "        i = np.argmax(outputs[k, :])\n",
    "        j = np.argmax(labels[k, :])\n",
    "        A[i, j] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute binary one-vs-rest confusion matrices, where the columns are expert labels and rows are classifier labels.\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels)==np.shape(outputs))\n",
    "    assert(all(value in (0, 1) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_patients):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j]==1 and outputs[i, j]==1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j]==0 and outputs[i, j]==1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j]==1 and outputs[i, j]==0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j]==0 and outputs[i, j]==0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro AUROC and macro AUPRC.\n",
    "def compute_auc(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    # Compute and summarize the confusion matrices for each class across at distinct output values.\n",
    "    auroc = np.zeros(num_classes)\n",
    "    auprc = np.zeros(num_classes)\n",
    "\n",
    "    for k in range(num_classes):\n",
    "        # We only need to compute TPs, FPs, FNs, and TNs at distinct output values.\n",
    "        thresholds = np.unique(outputs[:, k])\n",
    "        thresholds = np.append(thresholds, thresholds[-1]+1)\n",
    "        thresholds = thresholds[::-1]\n",
    "        num_thresholds = len(thresholds)\n",
    "\n",
    "        # Initialize the TPs, FPs, FNs, and TNs.\n",
    "        tp = np.zeros(num_thresholds)\n",
    "        fp = np.zeros(num_thresholds)\n",
    "        fn = np.zeros(num_thresholds)\n",
    "        tn = np.zeros(num_thresholds)\n",
    "        fn[0] = np.sum(labels[:, k]==1)\n",
    "        tn[0] = np.sum(labels[:, k]==0)\n",
    "\n",
    "        # Find the indices that result in sorted output values.\n",
    "        idx = np.argsort(outputs[:, k])[::-1]\n",
    "\n",
    "        # Compute the TPs, FPs, FNs, and TNs for class k across thresholds.\n",
    "        i = 0\n",
    "        for j in range(1, num_thresholds):\n",
    "            # Initialize TPs, FPs, FNs, and TNs using values at previous threshold.\n",
    "            tp[j] = tp[j-1]\n",
    "            fp[j] = fp[j-1]\n",
    "            fn[j] = fn[j-1]\n",
    "            tn[j] = tn[j-1]\n",
    "\n",
    "            # Update the TPs, FPs, FNs, and TNs at i-th output value.\n",
    "            while i < num_patients and outputs[idx[i], k] >= thresholds[j]:\n",
    "                if labels[idx[i], k]:\n",
    "                    tp[j] += 1\n",
    "                    fn[j] -= 1\n",
    "                else:\n",
    "                    fp[j] += 1\n",
    "                    tn[j] -= 1\n",
    "                i += 1\n",
    "\n",
    "        # Summarize the TPs, FPs, FNs, and TNs for class k.\n",
    "        tpr = np.zeros(num_thresholds)\n",
    "        tnr = np.zeros(num_thresholds)\n",
    "        ppv = np.zeros(num_thresholds)\n",
    "        for j in range(num_thresholds):\n",
    "            if tp[j] + fn[j]:\n",
    "                tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n",
    "            else:\n",
    "                tpr[j] = float('nan')\n",
    "            if fp[j] + tn[j]:\n",
    "                tnr[j] = float(tn[j]) / float(fp[j] + tn[j])\n",
    "            else:\n",
    "                tnr[j] = float('nan')\n",
    "            if tp[j] + fp[j]:\n",
    "                ppv[j] = float(tp[j]) / float(tp[j] + fp[j])\n",
    "            else:\n",
    "                ppv[j] = float('nan')\n",
    "\n",
    "        # Compute AUROC as the area under a piecewise linear function with TPR/\n",
    "        # sensitivity (x-axis) and TNR/specificity (y-axis) and AUPRC as the area\n",
    "        # under a piecewise constant with TPR/recall (x-axis) and PPV/precision\n",
    "        # (y-axis) for class k.\n",
    "        for j in range(num_thresholds-1):\n",
    "            auroc[k] += 0.5 * (tpr[j+1] - tpr[j]) * (tnr[j+1] + tnr[j])\n",
    "            auprc[k] += (tpr[j+1] - tpr[j]) * ppv[j+1]\n",
    "\n",
    "    # Compute macro AUROC and macro AUPRC across classes.\n",
    "    if np.any(np.isfinite(auroc)):\n",
    "        macro_auroc = np.nanmean(auroc)\n",
    "    else:\n",
    "        macro_auroc = float('nan')\n",
    "    if np.any(np.isfinite(auprc)):\n",
    "        macro_auprc = np.nanmean(auprc)\n",
    "    else:\n",
    "        macro_auprc = float('nan')\n",
    "\n",
    "    return macro_auroc, macro_auprc, auroc, auprc\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_accuracy(labels, outputs):\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    if np.sum(A) > 0:\n",
    "        accuracy = np.sum(np.diag(A)) / np.sum(A)\n",
    "    else:\n",
    "        accuracy = float('nan')\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels, outputs)\n",
    "\n",
    "    f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(f_measure)):\n",
    "        macro_f_measure = np.nanmean(f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, f_measure\n",
    "\n",
    "# Compute Challenge score.\n",
    "def compute_challenge_score(labels, outputs, classes):\n",
    "    # Define costs. Better to load these costs from an external file instead of defining them here.\n",
    "    c_algorithm  =     1 # Cost for algorithmic prescreening.\n",
    "    c_gp         =   250 # Cost for screening from a general practitioner (GP).\n",
    "    c_specialist =   500 # Cost for screening from a specialist.\n",
    "    c_treatment  =  1000 # Cost for treatment.\n",
    "    c_error      = 10000 # Cost for diagnostic error.\n",
    "    alpha        =   0.5 # Fraction of murmur unknown cases that are positive.\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    idx_positive = classes.index('Present')\n",
    "    idx_unknown  = classes.index('Unknown')\n",
    "    idx_negative = classes.index('Absent')\n",
    "\n",
    "    n_pp = A[idx_positive, idx_positive]\n",
    "    n_pu = A[idx_positive, idx_unknown ]\n",
    "    n_pn = A[idx_positive, idx_negative]\n",
    "    n_up = A[idx_unknown , idx_positive]\n",
    "    n_uu = A[idx_unknown , idx_unknown ]\n",
    "    n_un = A[idx_unknown , idx_negative]\n",
    "    n_np = A[idx_negative, idx_positive]\n",
    "    n_nu = A[idx_negative, idx_unknown ]\n",
    "    n_nn = A[idx_negative, idx_negative]\n",
    "\n",
    "    n_total = n_pp + n_pu + n_pn \\\n",
    "        + n_up + n_uu + n_un \\\n",
    "        + n_np + n_nu + n_nn\n",
    "\n",
    "    total_score = c_algorithm * n_total \\\n",
    "        + c_gp * (n_pp + n_pu + n_pn) \\\n",
    "        + c_specialist * (n_pu + n_up + n_uu + n_un) \\\n",
    "        + c_treatment * (n_pp + alpha * n_pu + n_up + alpha * n_uu) \\\n",
    "        + c_error * (n_np + alpha * n_nu)\n",
    "    if n_total > 0:\n",
    "        mean_score = total_score / n_total\n",
    "    else:\n",
    "        mean_score = float('nan')\n",
    "\n",
    "    return mean_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90eea640",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # For each patient, set the 'Unknown' class to positive if no class is positive or if multiple classes are positive.\n",
    "    labels = enforce_positives(labels, classes, 'Unknown')\n",
    "    binary_outputs = enforce_positives(binary_outputs, classes, 'Unknown')\n",
    "\n",
    "    # Evaluate the model by comparing the labels and outputs.\n",
    "    auroc, auprc, auroc_classes, auprc_classes = compute_auc(labels, scalar_outputs)\n",
    "    accuracy = compute_accuracy(labels, binary_outputs)\n",
    "    f_measure, f_measure_classes = compute_f_measure(labels, binary_outputs)\n",
    "    challenge_score = compute_challenge_score(labels, binary_outputs, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc73a6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "911.2972399150743"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "challenge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a74ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
