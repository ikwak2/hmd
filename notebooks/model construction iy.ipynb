{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39571107",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_code'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-60abba9b737c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhelper_code\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_code'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cdf120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/ubuntu/hmd/notebooks')\n",
    "sys.path.insert(0,'/home/ubuntu/hmd/iy_classifier')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21f4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "from utils.get_feature import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c38658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1'\n",
    "training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e4d34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 23 16:19:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   32C    P0    37W / 300W |      3MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   56C    P0   184W / 300W |  31098MiB / 32510MiB |     80%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     38952      C   ...sorflow2.4_p37/bin/python    31095MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63795321",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcf97e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>Murmur locations</th>\n",
       "      <th>Most audible location</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic murmur grading</th>\n",
       "      <th>Systolic murmur pitch</th>\n",
       "      <th>Systolic murmur quality</th>\n",
       "      <th>Diastolic murmur timing</th>\n",
       "      <th>Diastolic murmur shape</th>\n",
       "      <th>Diastolic murmur grading</th>\n",
       "      <th>Diastolic murmur pitch</th>\n",
       "      <th>Diastolic murmur quality</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Additional ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>III/VI</td>\n",
       "      <td>High</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9983</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>115.0</td>\n",
       "      <td>19.10</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13918</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>I/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14241</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.20</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>PV</td>\n",
       "      <td>...</td>\n",
       "      <td>II/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14998</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23625</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>50379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24160</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>17.66</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29045</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>II/VI</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29378</td>\n",
       "      <td>AV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.70</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID    Locations    Age     Sex  Height  Weight  Pregnancy status  \\\n",
       "0        2530  AV+PV+TV+MV  Child  Female    98.0   15.90             False   \n",
       "1        9979  AV+PV+TV+MV  Child  Female   103.0   13.10             False   \n",
       "2        9983  AV+PV+TV+MV  Child    Male   115.0   19.10             False   \n",
       "3       13918  AV+PV+TV+MV  Child    Male    98.0   15.90             False   \n",
       "4       14241  AV+PV+TV+MV  Child    Male    87.0   11.20             False   \n",
       "5       14998  AV+PV+TV+MV  Child    Male     NaN     NaN             False   \n",
       "6       23625  AV+PV+TV+MV  Child  Female    92.0   14.00             False   \n",
       "7       24160  AV+PV+TV+MV  Child  Female    98.0   17.66             False   \n",
       "8       29045  AV+PV+TV+MV  Child  Female    88.0   12.50             False   \n",
       "9       29378        AV+MV  Child  Female    82.0   10.70             False   \n",
       "\n",
       "    Murmur Murmur locations Most audible location  ...  \\\n",
       "0   Absent              NaN                   NaN  ...   \n",
       "1  Present      AV+MV+PV+TV                    TV  ...   \n",
       "2  Unknown              NaN                   NaN  ...   \n",
       "3  Present               TV                    TV  ...   \n",
       "4  Present      AV+MV+PV+TV                    PV  ...   \n",
       "5   Absent              NaN                   NaN  ...   \n",
       "6   Absent              NaN                   NaN  ...   \n",
       "7   Absent              NaN                   NaN  ...   \n",
       "8  Present      AV+MV+PV+TV                    TV  ...   \n",
       "9  Unknown              NaN                   NaN  ...   \n",
       "\n",
       "  Systolic murmur grading Systolic murmur pitch Systolic murmur quality  \\\n",
       "0                     NaN                   NaN                     NaN   \n",
       "1                  III/VI                  High                   Harsh   \n",
       "2                     NaN                   NaN                     NaN   \n",
       "3                    I/VI                   Low                 Blowing   \n",
       "4                   II/VI                   Low                   Harsh   \n",
       "5                     NaN                   NaN                     NaN   \n",
       "6                     NaN                   NaN                     NaN   \n",
       "7                     NaN                   NaN                     NaN   \n",
       "8                   II/VI                   Low                 Blowing   \n",
       "9                     NaN                   NaN                     NaN   \n",
       "\n",
       "  Diastolic murmur timing Diastolic murmur shape Diastolic murmur grading  \\\n",
       "0                     NaN                    NaN                      NaN   \n",
       "1                     NaN                    NaN                      NaN   \n",
       "2                     NaN                    NaN                      NaN   \n",
       "3                     NaN                    NaN                      NaN   \n",
       "4                     NaN                    NaN                      NaN   \n",
       "5                     NaN                    NaN                      NaN   \n",
       "6                     NaN                    NaN                      NaN   \n",
       "7                     NaN                    NaN                      NaN   \n",
       "8                     NaN                    NaN                      NaN   \n",
       "9                     NaN                    NaN                      NaN   \n",
       "\n",
       "  Diastolic murmur pitch Diastolic murmur quality Campaign Additional ID  \n",
       "0                    NaN                      NaN   CC2015           NaN  \n",
       "1                    NaN                      NaN   CC2015           NaN  \n",
       "2                    NaN                      NaN   CC2015           NaN  \n",
       "3                    NaN                      NaN   CC2015           NaN  \n",
       "4                    NaN                      NaN   CC2015           NaN  \n",
       "5                    NaN                      NaN   CC2015           NaN  \n",
       "6                    NaN                      NaN   CC2015       50379.0  \n",
       "7                    NaN                      NaN   CC2015           NaN  \n",
       "8                    NaN                      NaN   CC2015           NaN  \n",
       "9                    NaN                      NaN   CC2015           NaN  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(training_data_file)\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7860c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =  '/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data'\n",
    "model_folder = 'tmp_model1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b92feebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f84559de",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(data_folder)\n",
    "num_patient_files = len(patient_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "525d9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "942"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc071664",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_idx = np.random.permutation(942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df6f4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = patient_files[:800]\n",
    "patient_files_test = patient_files[800:]\n",
    "num_patient_files = len(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34c65a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_folder, exist_ok=True)\n",
    "\n",
    "classes = ['Present', 'Unknown', 'Absent']\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "167999f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels and use one-hot encoding.\n",
    "            current_labels = np.zeros(num_classes, dtype=int)\n",
    "            label = get_label(current_patient_data)\n",
    "            if label in classes:\n",
    "                j = classes.index(label)\n",
    "                current_labels[j] = 1\n",
    "            labels.append(current_labels)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "3e543f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_wo_labels(patient_files_trn) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in range(num_patient_files):\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            mel1 = feature_extract_melspec(filename)[0]\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "        \n",
    "    M, N = features['mel1'][i].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7b237d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_trn = get_features(patient_files_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4aae45e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_test = get_features(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8661fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "current_patient_data = load_patient_data(patient_files_trn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1ef5c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recordings. wav data recording\n",
    "def load_recordings(data_folder, data, get_frequencies=False):\n",
    "    num_locations = get_num_locations(data)\n",
    "    recording_information = data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    recordings = list()\n",
    "    frequencies = list()\n",
    "    for i in range(num_locations):\n",
    "        entries = recording_information[i].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        recording, frequency = load_wav_file(filename)\n",
    "        recordings.append(recording)\n",
    "        frequencies.append(frequency)\n",
    "\n",
    "    if get_frequencies:\n",
    "        return recordings, frequencies\n",
    "    else:\n",
    "        return recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f5c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(current_patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24a0971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv', 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv', 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv', 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']\n"
     ]
    }
   ],
   "source": [
    "print(num_locations, recording_information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ce9cb38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV 2530_AV.hea 2530_AV.wav 2530_AV.tsv',\n",
       " 'PV 2530_PV.hea 2530_PV.wav 2530_PV.tsv',\n",
       " 'TV 2530_TV.hea 2530_TV.wav 2530_TV.tsv',\n",
       " 'MV 2530_MV.hea 2530_MV.wav 2530_MV.tsv']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e168bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AV', '2530_AV.hea', '2530_AV.wav', '2530_AV.tsv']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = recording_information[i].split(' ')\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "627cb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_file = entries[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec6e111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530_AV.wav'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recording_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9728c5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/hmd/notebooks/physionet.org/files/circor-heart-sound/1.0.1/training_data/2530_AV.wav'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.path.join(data_folder, recording_file)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2af87aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "36493f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fec2057c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f9f07f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id1 = recording_file.split('_')[0]\n",
    "features['id'].append(id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "17006839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1 = feature_extract_melspec(filename)[0]\n",
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "80234950",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['mel1'].append(mel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca75e8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e449b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "108e1489",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_age = ['Child']\n",
    "age_group = get_age(current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e270aaf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ee5dfc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = get_age(current_patient_data)\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "497bede7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Child'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c23d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "899829f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = 'ddd'\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "current_age_group = np.zeros(6, dtype=int)\n",
    "\n",
    "if age_group in age_classes:\n",
    "    j = age_classes.index(age_group)\n",
    "    current_age_group[j] = 1\n",
    "else :\n",
    "    current_age_group[5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d564b469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_age_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fbb49ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['age'].append(current_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b3289b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sex. Use one-hot encoding.\n",
    "sex = get_sex(current_patient_data)\n",
    "sex_features = np.zeros(2, dtype=int)\n",
    "if compare_strings(sex, 'Female'):\n",
    "    sex_features[0] = 1\n",
    "elif compare_strings(sex, 'Male'):\n",
    "    sex_features[1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f9f1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['sex'].append(sex_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "13d20e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract height and weight.\n",
    "height = get_height(current_patient_data)\n",
    "weight = get_weight(current_patient_data)\n",
    "features['hw'].append(np.array([height, weight]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b103562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "features['preg'].append(is_pregnant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7fce236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = entries[0]\n",
    "\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "num_recording_locations = len(recording_locations)\n",
    "loc_features = np.zeros(num_recording_locations)\n",
    "if locations in recording_locations:\n",
    "    j = recording_locations.index(locations)\n",
    "    loc_features[j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ae82407d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AV'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "7aa5d2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loc_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6a39a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9d63fa30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['2530'],\n",
       " 'age': [array([0, 0, 0, 0, 0, 1])],\n",
       " 'sex': [array([1, 0])],\n",
       " 'hw': [array([98. , 15.9])],\n",
       " 'preg': [False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.])],\n",
       " 'mel1': [array([[-14.24342  , -14.460995 , -12.48743  , ...,  -8.350793 ,\n",
       "           -9.550913 ,  -6.6099434],\n",
       "         [ -8.833427 , -11.78526  , -10.376642 , ..., -10.638776 ,\n",
       "          -14.766047 ,  -2.595482 ],\n",
       "         [ -7.201795 , -11.942595 , -14.396763 , ..., -13.780443 ,\n",
       "          -11.831632 , -10.3140745],\n",
       "         ...,\n",
       "         [-43.652073 , -60.107727 , -58.363945 , ..., -46.318718 ,\n",
       "          -47.93747  , -47.206367 ],\n",
       "         [-42.097    , -59.548874 , -57.106033 , ..., -45.140682 ,\n",
       "          -53.84076  , -53.963337 ],\n",
       "         [-42.240356 , -60.107727 , -60.107727 , ..., -51.811592 ,\n",
       "          -55.905552 , -57.170105 ]], dtype=float32)]}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1f4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0dc3097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    current_patient_data = load_patient_data(patient_files[i])\n",
    "    current_recordings = load_recordings(data_folder, current_patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ce67f78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2530 4 4000\\nAV 2530_AV.hea 2530_AV.wav 2530_AV.tsv\\nPV 2530_PV.hea 2530_PV.wav 2530_PV.tsv\\nTV 2530_TV.hea 2530_TV.wav 2530_TV.tsv\\nMV 2530_MV.hea 2530_MV.wav 2530_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 98.0\\n#Weight: 15.9\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6c04a872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_patient_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ce45e339",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['id'] = []\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "labels = []\n",
    "\n",
    "age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "for i in range(num_patient_files):\n",
    "\n",
    "    # Load the current patient data and recordings.\n",
    "    current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "    num_locations = get_num_locations(current_patient_data)\n",
    "    recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "        \n",
    "        # Extract id\n",
    "        id1 = recording_file.split('_')[0]\n",
    "        features['id'].append(id1)\n",
    "        \n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "        \n",
    "        # Extract age_group\n",
    "        age_group = get_age(current_patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "        \n",
    "        # Extract sex\n",
    "        sex = get_sex(current_patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "        \n",
    "        # Extract height and weight.\n",
    "        height = get_height(current_patient_data)\n",
    "        weight = get_weight(current_patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "        \n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "\n",
    "        # Extract labels and use one-hot encoding.\n",
    "        current_labels = np.zeros(num_classes, dtype=int)\n",
    "        label = get_label(current_patient_data)\n",
    "        if label in classes:\n",
    "            j = classes.index(label)\n",
    "            current_labels[j] = 1\n",
    "        labels.append(current_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3688a504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed19c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6f1c4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a2812f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(age_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c8e5e0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e2e8ed95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2675"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "badc4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features['mel1'])) :\n",
    "    features['mel1'][i] = features['mel1'][i].reshape(100,313,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34ff309d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 313, 1)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['mel1'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3cd07ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "loc = keras.Input(shape=(len(recording_locations),), name = 'loc')\n",
    "mel1 = keras.Input(shape=(features['mel1'][0].shape), name = 'mel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e1c3cf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c9427",
   "metadata": {},
   "source": [
    "## A toy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "193287fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## age embeddig\n",
    "age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "## sex embedding\n",
    "sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "## hw embedding\n",
    "hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "## loc embedding\n",
    "loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "## mel embedding\n",
    "mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "mel2 = layers.MaxPooling2D()(mel2)\n",
    "mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "4bc40eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "8d5e7bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel (InputLayer)                [(None, 100, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 98, 311, 16)  160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 49, 155, 16)  0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 45, 151, 32)  12832       max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling2D) (None, 22, 75, 32)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 20, 73, 32)   9248        max_pooling2d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 10, 36, 32)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 34, 64)    18496       max_pooling2d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "age_cat (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex_cat (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "height_weight (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loc (InputLayer)                [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 4, 17, 64)    0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 2)            14          age_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 1)            3           sex_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 1)            3           height_weight[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 3)            18          loc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 64)           0           max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "is_preg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 72)           0           dense_91[0][0]                   \n",
      "                                                                 dense_92[0][0]                   \n",
      "                                                                 dense_93[0][0]                   \n",
      "                                                                 dense_94[0][0]                   \n",
      "                                                                 global_average_pooling2d_13[0][0]\n",
      "                                                                 is_preg[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 10)           730         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 3)            33          dense_95[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 41,537\n",
      "Trainable params: 41,537\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "81d4e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat1 )\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "9a21f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", \n",
    "             loss = \"categorical_crossentropy\",\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "306dc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in features.keys() :\n",
    "    features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "295b1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(features['mel1'])) :\n",
    "    features['mel1'][i] = features['mel1'][i].reshape(100,313,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "3ac55419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2675, 6)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "features['age'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "d6390a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2675, 3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "7aa1027d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': array(['2530', '2530', '2530', ..., '85109', '85109', '85109'],\n",
       "        dtype='<U5'),\n",
       "  'age': array([[0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]]),\n",
       "  'sex': array([[1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         ...,\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [1, 0]]),\n",
       "  'hw': array([[ 98. ,  15.9],\n",
       "         [ 98. ,  15.9],\n",
       "         [ 98. ,  15.9],\n",
       "         ...,\n",
       "         [119. ,  19.8],\n",
       "         [119. ,  19.8],\n",
       "         [119. ,  19.8]]),\n",
       "  'preg': array([False, False, False, ..., False, False, False]),\n",
       "  'loc': array([[1., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 0., 0.]]),\n",
       "  'mel1': array([[[[-14.24341965],\n",
       "           [-14.46099472],\n",
       "           [-12.48742962],\n",
       "           ...,\n",
       "           [ -8.35079288],\n",
       "           [ -9.55091286],\n",
       "           [ -6.60994339]],\n",
       "  \n",
       "          [[ -8.83342743],\n",
       "           [-11.7852602 ],\n",
       "           [-10.37664223],\n",
       "           ...,\n",
       "           [-10.63877583],\n",
       "           [-14.76604652],\n",
       "           [ -2.59548211]],\n",
       "  \n",
       "          [[ -7.2017951 ],\n",
       "           [-11.94259453],\n",
       "           [-14.39676285],\n",
       "           ...,\n",
       "           [-13.78044319],\n",
       "           [-11.83163166],\n",
       "           [-10.31407452]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-43.65207291],\n",
       "           [-60.10772705],\n",
       "           [-58.36394501],\n",
       "           ...,\n",
       "           [-46.31871796],\n",
       "           [-47.93746948],\n",
       "           [-47.20636749]],\n",
       "  \n",
       "          [[-42.09700012],\n",
       "           [-59.5488739 ],\n",
       "           [-57.10603333],\n",
       "           ...,\n",
       "           [-45.14068222],\n",
       "           [-53.84075928],\n",
       "           [-53.96333694]],\n",
       "  \n",
       "          [[-42.24035645],\n",
       "           [-60.10772705],\n",
       "           [-60.10772705],\n",
       "           ...,\n",
       "           [-51.8115921 ],\n",
       "           [-55.90555191],\n",
       "           [-57.17010498]]],\n",
       "  \n",
       "  \n",
       "         [[[ -1.76278357],\n",
       "           [ -7.6956807 ],\n",
       "           [-10.0526564 ],\n",
       "           ...,\n",
       "           [ -9.17302901],\n",
       "           [-11.91416682],\n",
       "           [ -9.71304741]],\n",
       "  \n",
       "          [[ -4.10499682],\n",
       "           [ -3.04740592],\n",
       "           [ -7.99589744],\n",
       "           ...,\n",
       "           [  1.13296489],\n",
       "           [ -4.41494839],\n",
       "           [ -5.30026421]],\n",
       "  \n",
       "          [[  2.37289745],\n",
       "           [ -2.04059993],\n",
       "           [ -5.03795553],\n",
       "           ...,\n",
       "           [ -4.48770402],\n",
       "           [ -0.96008616],\n",
       "           [ -6.78836285]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-35.97599769],\n",
       "           [-63.03632912],\n",
       "           [-63.03632912],\n",
       "           ...,\n",
       "           [-61.79777171],\n",
       "           [-62.11518067],\n",
       "           [-47.37110115]],\n",
       "  \n",
       "          [[-35.88112619],\n",
       "           [-61.61461487],\n",
       "           [-61.01754104],\n",
       "           ...,\n",
       "           [-60.72189183],\n",
       "           [-63.03632912],\n",
       "           [-48.97085352]],\n",
       "  \n",
       "          [[-36.13571271],\n",
       "           [-63.03632912],\n",
       "           [-63.03632912],\n",
       "           ...,\n",
       "           [-60.77532796],\n",
       "           [-63.03632912],\n",
       "           [-47.86174188]]],\n",
       "  \n",
       "  \n",
       "         [[[ -1.03466398],\n",
       "           [ -8.96630308],\n",
       "           [-10.68383903],\n",
       "           ...,\n",
       "           [-13.37314596],\n",
       "           [-11.81852916],\n",
       "           [-16.05991496]],\n",
       "  \n",
       "          [[ -2.32761212],\n",
       "           [ -3.51949809],\n",
       "           [-10.45657004],\n",
       "           ...,\n",
       "           [ -6.13660347],\n",
       "           [ -2.97687093],\n",
       "           [-18.70165319]],\n",
       "  \n",
       "          [[ -3.02883141],\n",
       "           [ -1.46444536],\n",
       "           [-15.68688304],\n",
       "           ...,\n",
       "           [ -5.84809928],\n",
       "           [ -1.89190893],\n",
       "           [-26.27239075]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-37.4012157 ],\n",
       "           [-53.90407524],\n",
       "           [-55.07319624],\n",
       "           ...,\n",
       "           [-58.25991843],\n",
       "           [-59.27267758],\n",
       "           [-53.89146703]],\n",
       "  \n",
       "          [[-38.9598168 ],\n",
       "           [-53.52410412],\n",
       "           [-55.39447186],\n",
       "           ...,\n",
       "           [-62.85613365],\n",
       "           [-57.7839855 ],\n",
       "           [-59.56494451]],\n",
       "  \n",
       "          [[-38.40588162],\n",
       "           [-53.05287559],\n",
       "           [-58.10594211],\n",
       "           ...,\n",
       "           [-63.90387215],\n",
       "           [-58.75308598],\n",
       "           [-60.59706362]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[-14.92621994],\n",
       "           [-19.86256027],\n",
       "           [-22.74859428],\n",
       "           ...,\n",
       "           [-20.5056076 ],\n",
       "           [-14.81362343],\n",
       "           [-27.03481293]],\n",
       "  \n",
       "          [[-18.74547958],\n",
       "           [-20.04498482],\n",
       "           [-25.54829788],\n",
       "           ...,\n",
       "           [-16.84513855],\n",
       "           [ -8.0646553 ],\n",
       "           [-26.75851631]],\n",
       "  \n",
       "          [[-16.33693695],\n",
       "           [-17.72608185],\n",
       "           [-25.54093552],\n",
       "           ...,\n",
       "           [-15.97365284],\n",
       "           [ -4.81385326],\n",
       "           [-26.2185688 ]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-38.22233963],\n",
       "           [-64.6667099 ],\n",
       "           [-54.44486618],\n",
       "           ...,\n",
       "           [-51.23309326],\n",
       "           [-48.96747208],\n",
       "           [-55.56414032]],\n",
       "  \n",
       "          [[-38.30625916],\n",
       "           [-59.72706604],\n",
       "           [-57.03933334],\n",
       "           ...,\n",
       "           [-51.79555511],\n",
       "           [-51.86066055],\n",
       "           [-52.25008011]],\n",
       "  \n",
       "          [[-38.42652893],\n",
       "           [-60.15376282],\n",
       "           [-57.76937103],\n",
       "           ...,\n",
       "           [-57.31532669],\n",
       "           [-50.26405716],\n",
       "           [-55.23196793]]],\n",
       "  \n",
       "  \n",
       "         [[[  3.34179735],\n",
       "           [  3.21778989],\n",
       "           [  2.13009691],\n",
       "           ...,\n",
       "           [-15.91869831],\n",
       "           [-14.18813801],\n",
       "           [ -3.19268823]],\n",
       "  \n",
       "          [[  3.05514097],\n",
       "           [  3.66310692],\n",
       "           [  5.64057446],\n",
       "           ...,\n",
       "           [-16.11846352],\n",
       "           [-11.99881077],\n",
       "           [  1.57547641]],\n",
       "  \n",
       "          [[ -0.86661136],\n",
       "           [  1.8989954 ],\n",
       "           [  1.2141552 ],\n",
       "           ...,\n",
       "           [-13.45223427],\n",
       "           [ -8.75177193],\n",
       "           [ -0.84374607]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-53.91950226],\n",
       "           [-62.666996  ],\n",
       "           [-62.6552887 ],\n",
       "           ...,\n",
       "           [-45.87496948],\n",
       "           [-53.10728073],\n",
       "           [-42.53530121]],\n",
       "  \n",
       "          [[-50.24755096],\n",
       "           [-62.38815308],\n",
       "           [-62.666996  ],\n",
       "           ...,\n",
       "           [-42.53837204],\n",
       "           [-54.24041748],\n",
       "           [-42.13832092]],\n",
       "  \n",
       "          [[-52.80511856],\n",
       "           [-59.82988358],\n",
       "           [-62.666996  ],\n",
       "           ...,\n",
       "           [-43.00945663],\n",
       "           [-55.88153076],\n",
       "           [-42.07498932]]],\n",
       "  \n",
       "  \n",
       "         [[[-25.19329061],\n",
       "           [-19.82801636],\n",
       "           [-16.75144949],\n",
       "           ...,\n",
       "           [ -8.50657317],\n",
       "           [-17.72589406],\n",
       "           [-11.11035324]],\n",
       "  \n",
       "          [[-18.6681916 ],\n",
       "           [-18.00551893],\n",
       "           [-15.69518197],\n",
       "           ...,\n",
       "           [ -7.176368  ],\n",
       "           [-10.52188535],\n",
       "           [ -8.46615383]],\n",
       "  \n",
       "          [[-21.05481997],\n",
       "           [-18.84051664],\n",
       "           [-21.7199146 ],\n",
       "           ...,\n",
       "           [ -4.04120067],\n",
       "           [-14.00794269],\n",
       "           [-10.17546359]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[-50.41377908],\n",
       "           [-57.98619905],\n",
       "           [-64.1634817 ],\n",
       "           ...,\n",
       "           [-53.09211251],\n",
       "           [-33.8020701 ],\n",
       "           [-38.46221992]],\n",
       "  \n",
       "          [[-50.04809339],\n",
       "           [-55.16153623],\n",
       "           [-62.92739622],\n",
       "           ...,\n",
       "           [-51.26978766],\n",
       "           [-37.07837834],\n",
       "           [-39.50943521]],\n",
       "  \n",
       "          [[-49.10597156],\n",
       "           [-53.97642218],\n",
       "           [-62.03405057],\n",
       "           ...,\n",
       "           [-49.36605012],\n",
       "           [-39.88476369],\n",
       "           [-42.82798984]]]])},\n",
       " array([[0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1]]))"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_trn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "2a027ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c7b83e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "84/84 [==============================] - 2s 13ms/step - loss: 0.7532 - accuracy: 0.7042 - val_loss: 0.6023 - val_accuracy: 0.8094\n",
      "Epoch 2/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6522 - accuracy: 0.7505 - val_loss: 0.5663 - val_accuracy: 0.8299\n",
      "Epoch 3/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.6119 - accuracy: 0.7755 - val_loss: 0.4964 - val_accuracy: 0.8504\n",
      "Epoch 4/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.5462 - accuracy: 0.8102 - val_loss: 0.4865 - val_accuracy: 0.8545\n",
      "Epoch 5/30\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.5657 - accuracy: 0.8140 - val_loss: 0.4716 - val_accuracy: 0.8668\n",
      "Epoch 6/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4966 - accuracy: 0.8428 - val_loss: 0.4889 - val_accuracy: 0.8648\n",
      "Epoch 7/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4986 - accuracy: 0.8345 - val_loss: 0.4774 - val_accuracy: 0.8566\n",
      "Epoch 8/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4924 - accuracy: 0.8321 - val_loss: 0.4583 - val_accuracy: 0.8668\n",
      "Epoch 9/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4577 - accuracy: 0.8464 - val_loss: 0.4805 - val_accuracy: 0.8586\n",
      "Epoch 10/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4565 - accuracy: 0.8494 - val_loss: 0.4523 - val_accuracy: 0.8648\n",
      "Epoch 11/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4325 - accuracy: 0.8581 - val_loss: 0.4364 - val_accuracy: 0.8648\n",
      "Epoch 12/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4305 - accuracy: 0.8533 - val_loss: 0.4598 - val_accuracy: 0.8648\n",
      "Epoch 13/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4364 - accuracy: 0.8481 - val_loss: 0.5084 - val_accuracy: 0.8402\n",
      "Epoch 14/30\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.4004 - accuracy: 0.8645 - val_loss: 0.4302 - val_accuracy: 0.8627\n",
      "Epoch 15/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.4203 - accuracy: 0.8585 - val_loss: 0.4256 - val_accuracy: 0.8668\n",
      "Epoch 16/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3552 - accuracy: 0.8813 - val_loss: 0.4136 - val_accuracy: 0.8668\n",
      "Epoch 17/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3952 - accuracy: 0.8668 - val_loss: 0.4104 - val_accuracy: 0.8648\n",
      "Epoch 18/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3784 - accuracy: 0.8702 - val_loss: 0.4799 - val_accuracy: 0.8463\n",
      "Epoch 19/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3830 - accuracy: 0.8607 - val_loss: 0.4227 - val_accuracy: 0.8668\n",
      "Epoch 20/30\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.3582 - accuracy: 0.8758 - val_loss: 0.4137 - val_accuracy: 0.8648\n",
      "Epoch 21/30\n",
      "84/84 [==============================] - 1s 10ms/step - loss: 0.3617 - accuracy: 0.8709 - val_loss: 0.5226 - val_accuracy: 0.8217\n",
      "Epoch 22/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3603 - accuracy: 0.8787 - val_loss: 0.4250 - val_accuracy: 0.8607\n",
      "Epoch 23/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3526 - accuracy: 0.8711 - val_loss: 0.4088 - val_accuracy: 0.8689\n",
      "Epoch 24/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3527 - accuracy: 0.8709 - val_loss: 0.4036 - val_accuracy: 0.8648\n",
      "Epoch 25/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2894 - accuracy: 0.8932 - val_loss: 0.4678 - val_accuracy: 0.8525\n",
      "Epoch 26/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3180 - accuracy: 0.8916 - val_loss: 0.4202 - val_accuracy: 0.8730\n",
      "Epoch 27/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.3190 - accuracy: 0.8872 - val_loss: 0.5255 - val_accuracy: 0.8197\n",
      "Epoch 28/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2960 - accuracy: 0.8993 - val_loss: 0.4164 - val_accuracy: 0.8770\n",
      "Epoch 29/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2719 - accuracy: 0.9075 - val_loss: 0.4490 - val_accuracy: 0.8545\n",
      "Epoch 30/30\n",
      "84/84 [==============================] - 1s 9ms/step - loss: 0.2830 - accuracy: 0.9046 - val_loss: 0.4383 - val_accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d4c0ddd10>"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([features_trn[0]['age'],features_trn[0]['sex'], features_trn[0]['hw'], features_trn[0]['preg'], features_trn[0]['loc'], \n",
    "           features_trn[0]['mel1']], labels,\n",
    "          validation_data = ([features_test[0]['age'],features_test[0]['sex'], features_test[0]['hw'], \n",
    "                              features_test[0]['preg'], features_test[0]['loc'], features_test[0]['mel1']], \n",
    "                             features_test[1]), \n",
    "          epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "bcd0079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model2(model_folder, model, classes, m_name, mel_shape = (100, 313, 1)) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename = os.path.join(model_folder, m_name + '_model.hdf5')\n",
    "    model.save(filename)\n",
    "    d = {'model': m_name, 'classes': classes, 'mel_shape': mel_shape, 'model_fnm': filename}    \n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(d, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1259e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "96553195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model.\n",
    "save_challenge_model2(model_folder, model, classes, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "d99e1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    with open(info_fnm, 'rb') as f:\n",
    "        info_m = pk.load(f)\n",
    "#    if info_m['model'] == 'toy' :\n",
    "#        model = get_toy(info_m['mel_shape'])\n",
    "#    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "#    model.load_weights(filename)\n",
    "    return info_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "28813b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toy(mel_input_shape):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = 'relu')(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = 'relu')(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = 'relu')(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = 'relu')(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    mel2 = layers.Conv2D(16, (3,3), activation = 'relu')(mel1)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (5,5), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(32, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.Conv2D(64, (3,3), activation = 'relu')(mel2)\n",
    "    mel2 = layers.MaxPooling2D()(mel2)\n",
    "    mel2 = layers.GlobalAveragePooling2D()(mel2)\n",
    "\n",
    "    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, mel2, preg])\n",
    "    concat1 = layers.Dense(10, activation = 'relu')(concat1)\n",
    "    concat1 = layers.Dense(3, activation = \"softmax\")(concat1)\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1] , outputs = concat1 )\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4c5720e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_challenge_model2(model_folder, classes, m_name = 'toy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "2d039bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_challenge_model(model_folder, verbose = 1) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d1b338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "e81ed73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[0])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "e4c1ceec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85110 4 4000\\nAV 85110_AV.hea 85110_AV.wav 85110_AV.tsv\\nPV 85110_PV.hea 85110_PV.wav 85110_PV.tsv\\nTV 85110_TV.hea 85110_TV.wav 85110_TV.tsv\\nMV 85110_MV.hea 85110_MV.wav 85110_MV.tsv\\n#Age: Child\\n#Sex: Male\\n#Height: 130.0\\n#Weight: 30.3\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: MV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Plateau\\n#Systolic murmur grading: II/VI\\n#Systolic murmur pitch: Low\\n#Systolic murmur quality: Blowing\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7c19244e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_challenge_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-393-54acaecfd6b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_challenge_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecordings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### Teams: Implement this function!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'run_challenge_model' is not defined"
     ]
    }
   ],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model1, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "4f0123fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "42bd22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(current_patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(current_patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(current_patient_data)\n",
    "    weight = get_weight(current_patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "360675cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "336085a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "838d3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8b93a267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "1ee9b8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2032033e-03, 2.9272465e-03, 9.9586958e-01],\n",
       "       [3.2206599e-02, 7.0056088e-02, 8.9773726e-01],\n",
       "       [1.4683392e-04, 7.0860866e-04, 9.9914455e-01],\n",
       "       [1.8912905e-03, 6.9301804e-03, 9.9117857e-01]], dtype=float32)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "a2684de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "75da3e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "d2d6a436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "464e0c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "8330cf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "b1354ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    classes = model['classes']\n",
    "    imputer = model['imputer']\n",
    "    classifier = model['classifier']\n",
    "\n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(info_m['mel_shape'])\n",
    "    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "    model.load_weights(filename)\n",
    "    \n",
    "    # Load features.\n",
    "    features = get_features(data, recordings)\n",
    "\n",
    "    # Impute missing data.\n",
    "    features = features.reshape(1, -1)\n",
    "    features = imputer.transform(features)\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    probabilities = classifier.predict_proba(features)\n",
    "    probabilities = np.asarray(probabilities, dtype=np.float32)[:, 0, 1]\n",
    "\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    idx = np.argmax(probabilities)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "42c6680c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1)}"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275a60b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed2322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "d52fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files_test[1])\n",
    "recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "5ef2d361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "f63b0dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85112 4 4000\\nAV 85112_AV.hea 85112_AV.wav 85112_AV.tsv\\nPV 85112_PV.hea 85112_PV.wav 85112_PV.tsv\\nTV 85112_TV.hea 85112_TV.wav 85112_TV.tsv\\nMV 85112_MV.hea 85112_MV.wav 85112_MV.tsv\\n#Age: Child\\n#Sex: Male\\n#Height: 136.0\\n#Weight: 26.3\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf26e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "2c26bebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "681bd312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85109 4 4000\\nAV 85109_AV.hea 85109_AV.wav 85109_AV.tsv\\nPV 85109_PV.hea 85109_PV.wav 85109_PV.tsv\\nTV 85109_TV.hea 85109_TV.wav 85109_TV.tsv\\nMV 85109_MV.hea 85109_MV.wav 85109_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 119.0\\n#Weight: 19.8\\n#Pregnancy status: False\\n#Murmur: Absent\\n#Murmur locations: nan\\n#Most audible location: nan\\n#Systolic murmur timing: nan\\n#Systolic murmur shape: nan\\n#Systolic murmur grading: nan\\n#Systolic murmur pitch: nan\\n#Systolic murmur quality: nan\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Campaign: CC2015\\n#Additional ID: nan'"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea9c05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "2ddd3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locations = get_num_locations(patient_data)\n",
    "recording_information = patient_data.split('\\n')[1:num_locations+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "f37e8d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = dict()\n",
    "features['age'] = []\n",
    "features['sex'] = []\n",
    "features['hw'] = []\n",
    "features['preg'] = []\n",
    "features['loc'] = []\n",
    "features['mel1'] = []\n",
    "for j in range(num_locations) :\n",
    "    entries = recording_information[j].split(' ')\n",
    "    recording_file = entries[2]\n",
    "    filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "    # Extract id\n",
    "#    id1 = recording_file.split('_')[0]\n",
    "#    features['id'].append(id1)\n",
    "\n",
    "    # Extract melspec\n",
    "    mel1 = feature_extract_melspec(filename)[0]\n",
    "    features['mel1'].append(mel1)\n",
    "\n",
    "    # Extract age_group\n",
    "    age_group = get_age(patient_data)\n",
    "    current_age_group = np.zeros(6, dtype=int)\n",
    "    if age_group in age_classes:\n",
    "        j = age_classes.index(age_group)\n",
    "        current_age_group[j] = 1\n",
    "    else :\n",
    "        current_age_group[5] = 1\n",
    "    features['age'].append(current_age_group)\n",
    "\n",
    "    # Extract sex\n",
    "    sex = get_sex(patient_data)\n",
    "    sex_features = np.zeros(2, dtype=int)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_features[0] = 1\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_features[1] = 1\n",
    "    features['sex'].append(sex_features)\n",
    "\n",
    "    # Extract height and weight.\n",
    "    height = get_height(patient_data)\n",
    "    weight = get_weight(patient_data)\n",
    "    features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "    # Extract pregnancy\n",
    "    is_pregnant = get_pregnancy_status(patient_data)\n",
    "    features['preg'].append(is_pregnant)\n",
    "\n",
    "    # Extract location\n",
    "    locations = entries[0]\n",
    "    num_recording_locations = len(recording_locations)\n",
    "    loc_features = np.zeros(num_recording_locations)\n",
    "    if locations in recording_locations:\n",
    "        j = recording_locations.index(locations)\n",
    "        loc_features[j] = 1\n",
    "    features['loc'].append(loc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "844bbca7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': [array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0]),\n",
       "  array([0, 0, 1, 0, 0, 0])],\n",
       " 'sex': [array([0, 1]), array([0, 1]), array([0, 1]), array([0, 1])],\n",
       " 'hw': [array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3]),\n",
       "  array([136. ,  26.3])],\n",
       " 'preg': [False, False, False, False],\n",
       " 'loc': [array([1., 0., 0., 0., 0.]),\n",
       "  array([0., 0., 1., 0., 0.]),\n",
       "  array([0., 0., 0., 1., 0.]),\n",
       "  array([0., 1., 0., 0., 0.])],\n",
       " 'mel1': [array([[  5.5544219 ,   5.25430448,   5.85624965, ...,  -4.01180172,\n",
       "           -2.62854908,  -2.5042349 ],\n",
       "         [ 10.42099442,   9.87717865,  14.38695231, ...,  -2.46004349,\n",
       "            1.79924639,  -4.51349842],\n",
       "         [ 11.33310424,  13.78394537,  13.1335616 , ...,   1.08339154,\n",
       "           -1.01365032,  -7.04751297],\n",
       "         ...,\n",
       "         [-18.90015848, -54.90594607, -58.1136186 , ..., -59.42052707,\n",
       "          -56.90998361, -48.85066669],\n",
       "         [-15.42566047, -52.71301415, -60.73131942, ..., -58.35870146,\n",
       "          -54.73361041, -52.19404219],\n",
       "         [-11.15672201, -51.57177258, -58.63095591, ..., -58.79083737,\n",
       "          -54.01102379, -52.62385897]]),\n",
       "  array([[ -5.34669814,   0.67031571,  -3.17846399, ..., -12.92143893,\n",
       "          -14.6734528 , -14.4765515 ],\n",
       "         [ -3.95126843,   6.31637984,  -4.64244314, ..., -10.39461407,\n",
       "          -10.63099409, -11.15637501],\n",
       "         [ -7.16954755,   2.46297333,  -0.85409502, ..., -10.59649951,\n",
       "          -12.49328981,   0.34125863],\n",
       "         ...,\n",
       "         [-34.42811144, -45.71171169, -59.00138537, ..., -50.40057535,\n",
       "          -56.65142888, -48.37946025],\n",
       "         [-36.29212611, -45.72542494, -61.35395916, ..., -49.05170214,\n",
       "          -58.97230698, -49.21394806],\n",
       "         [-34.86969307, -47.60865986, -61.69973905, ..., -51.1567752 ,\n",
       "          -61.31127645, -49.37548589]]),\n",
       "  array([[  1.68180672,  -3.96855903,  -9.31777817, ...,   0.59115272,\n",
       "          -13.3020849 , -12.12625751],\n",
       "         [  1.26698714,  -2.99167064, -12.70066591, ...,   6.97196192,\n",
       "          -11.43713667,  -3.81615562],\n",
       "         [  3.43579033,  -9.09430088, -10.03208319, ...,   6.05637143,\n",
       "          -11.2431155 ,  -4.3648029 ],\n",
       "         ...,\n",
       "         [-43.69433129, -54.66976803, -52.25798263, ..., -53.96021268,\n",
       "          -50.90066326, -48.80887587],\n",
       "         [-48.28895934, -55.59192024, -55.07810207, ..., -55.17842987,\n",
       "          -54.19418911, -49.81082227],\n",
       "         [-46.75922137, -56.52883698, -58.63612156, ..., -59.24551201,\n",
       "          -54.76376578, -48.53233825]]),\n",
       "  array([[-1.05357382e+01, -1.01090303e+01, -8.64615922e+00, ...,\n",
       "          -1.89183902e+01, -1.21077508e+01, -5.23639113e+00],\n",
       "         [-1.00548815e+01, -7.11764236e+00,  5.00336436e-02, ...,\n",
       "          -1.23953922e+01, -5.09774962e+00, -1.88250036e+00],\n",
       "         [-1.14629545e+01, -4.32136781e+00, -9.34656013e-02, ...,\n",
       "          -8.60415821e+00, -4.33791884e+00, -7.56818893e-01],\n",
       "         ...,\n",
       "         [-4.77923995e+01, -5.19989387e+01, -4.48201872e+01, ...,\n",
       "          -6.13758177e+01, -6.03041781e+01, -5.60282865e+01],\n",
       "         [-4.92251434e+01, -5.02118889e+01, -4.98856292e+01, ...,\n",
       "          -6.18184748e+01, -6.27257506e+01, -5.94607551e+01],\n",
       "         [-4.99104228e+01, -5.20431292e+01, -5.46581665e+01, ...,\n",
       "          -6.14256151e+01, -6.38957486e+01, -6.03423585e+01]])]}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc0fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "5b2f7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "c4cf010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_one(patient_data, verbose = 0) :\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    recording_information = patient_data.split('\\n')[1:num_locations+1]\n",
    "\n",
    "    features = dict()\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    for j in range(num_locations) :\n",
    "        entries = recording_information[j].split(' ')\n",
    "        recording_file = entries[2]\n",
    "        filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "        # Extract id\n",
    "    #    id1 = recording_file.split('_')[0]\n",
    "    #    features['id'].append(id1)\n",
    "\n",
    "        # Extract melspec\n",
    "        mel1 = feature_extract_melspec(filename)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "\n",
    "        # Extract age_group\n",
    "        age_group = get_age(patient_data)\n",
    "        current_age_group = np.zeros(6, dtype=int)\n",
    "        if age_group in age_classes:\n",
    "            j = age_classes.index(age_group)\n",
    "            current_age_group[j] = 1\n",
    "        else :\n",
    "            current_age_group[5] = 1\n",
    "        features['age'].append(current_age_group)\n",
    "\n",
    "        # Extract sex\n",
    "        sex = get_sex(patient_data)\n",
    "        sex_features = np.zeros(2, dtype=int)\n",
    "        if compare_strings(sex, 'Female'):\n",
    "            sex_features[0] = 1\n",
    "        elif compare_strings(sex, 'Male'):\n",
    "            sex_features[1] = 1\n",
    "        features['sex'].append(sex_features)\n",
    "\n",
    "        # Extract height and weight.\n",
    "        height = get_height(patient_data)\n",
    "        weight = get_weight(patient_data)\n",
    "        features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "        # Extract pregnancy\n",
    "        is_pregnant = get_pregnancy_status(patient_data)\n",
    "        features['preg'].append(is_pregnant)\n",
    "\n",
    "        # Extract location\n",
    "        locations = entries[0]\n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_features = np.zeros(num_recording_locations)\n",
    "        if locations in recording_locations:\n",
    "            j = recording_locations.index(locations)\n",
    "            loc_features[j] = 1\n",
    "        features['loc'].append(loc_features)\n",
    "        \n",
    "        \n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "        \n",
    "    if verbose :\n",
    "        label = get_label(patient_data)\n",
    "        print(label)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "e30cf101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['age', 'sex', 'hw', 'preg', 'loc', 'mel1'])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "daad20c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = model.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "faffaf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "9a66112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = res1.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "645e90cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "probargmax = prob1.argmax()\n",
    "labels = np.zeros((3,))\n",
    "labels[probargmax] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "f2f2df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "f50354ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent']"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "ae9c1e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'toy',\n",
       " 'classes': ['Present', 'Unknown', 'Absent'],\n",
       " 'mel_shape': (100, 313, 1),\n",
       " 'model_fnm': 'tmp_model1/toy_model.hdf5'}"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc043bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e64bd42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    \n",
    "    if model['model'] == 'toy' :\n",
    "        model1 = get_toy(info_m['mel_shape'])\n",
    "    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "    model1.load_weights(filename)\n",
    "    \n",
    "    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose)\n",
    "\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1']])\n",
    "    \n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    prob1 = res1.mean(axis = 0) ## simple rule for now\n",
    "    idx = np.argmax(prob1)\n",
    "    # Choose label with higher probability.\n",
    "    labels = np.zeros(len(classes), dtype=np.int_)\n",
    "    labels[idx] = 1\n",
    "\n",
    "    return classes, labels, prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "4a1edffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patient_files_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "3b40a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cb04504d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([1, 0, 0]),\n",
       " array([0.5782928 , 0.01442778, 0.40727937], dtype=float32))"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[0]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "d9a13238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca84eb320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.20622307, 0.06618129, 0.7275956 ], dtype=float32))"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[1]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "20da9eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca85f8cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.19515257, 0.00889223, 0.79595524], dtype=float32))"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[2]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "593d5aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cb04e8050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.02850191, 0.00479541, 0.96670264], dtype=float32))"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[3]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "579644c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cb04dcd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.05119427, 0.00629793, 0.9425078 ], dtype=float32))"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[4]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2291e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "0c88b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ones1 = []\n",
    "for i in range(100) :\n",
    "    patient_data = load_patient_data(patient_files_test[i])\n",
    "    num_locations = get_num_locations(patient_data)\n",
    "    if(num_locations == 1) :\n",
    "        ones1.append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "b306c970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 32, 80, 94, 98]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "81da7528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Present\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cb04b0440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([0.00782203, 0.03803323, 0.9541448 ], dtype=float32))"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[24]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "a5dc081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1ca85e4440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([2.2983432e-08, 4.3144092e-02, 9.5685589e-01], dtype=float32))"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[32]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8fc891b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absent\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f1cb04dcf80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent'],\n",
       " array([0, 0, 1]),\n",
       " array([2.701654e-04, 6.606587e-02, 9.336640e-01], dtype=float32))"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model1, data = load_patient_data(patient_files_test[80]), recordings = 0, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1b45cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe42c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba39b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d8a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965af64f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbdbce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdf5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd40f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c204ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
