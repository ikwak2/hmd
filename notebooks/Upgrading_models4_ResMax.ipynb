{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a6057f",
   "metadata": {},
   "source": [
    "## BC_ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a45589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math\n",
    "import sys\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/notebooks')\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/iy_classifier')\n",
    "sys.path.insert(0,'utils')\n",
    "from helper_code import *\n",
    "from get_feature import *\n",
    "from models import *\n",
    "from Generator0 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3bbd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'physionet.org/files/circor-heart-sound/1.0.3'\n",
    "training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52a9d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 11 14:00:24 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:05.0 Off |                  Off |\n",
      "| N/A   41C    P0    65W / 300W |  31097MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:06.0 Off |                  Off |\n",
      "| N/A   34C    P0    37W / 300W |      2MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     35636      C   ...sorflow2.4_p37/bin/python    31095MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb1c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25b6c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =  'physionet.org/files/circor-heart-sound/1.0.3/training_data'\n",
    "train_folder =  '/home/ubuntu/data/hmd/murmur/train'\n",
    "test_folder = '/home/ubuntu/data/hmd/murmur/test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6cf859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'resmax1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f7665",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cdbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3438eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "    if e < start:\n",
    "        return lr_start\n",
    "    elif e > end:\n",
    "        return lr_end\n",
    "\n",
    "    middle = (start + end) / 2\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ac699",
   "metadata": {},
   "source": [
    "### get feature 함수확장: 음성피쳐 옵션들과, 추가 음성들 고려한 피쳐추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c63a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = find_patient_files(train_folder)\n",
    "patient_files_test = find_patient_files(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98be9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature = {'samp_sec': 20,\n",
    "                  #### melspec, stft 피쳐 옵션들  \n",
    "                  'pre_emphasis': 0,\n",
    "                  'hop_length': 256,\n",
    "                  'win_length':512,\n",
    "                  'n_mels': 100,\n",
    "                  #### cqt 피쳐 옵션들  \n",
    "                  'filter_scale': 1,\n",
    "                  'n_bins': 80,\n",
    "                  'fmin': 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05434c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melspec:  100 313\n",
      "cqt:  80 157\n",
      "stft:  257 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utils/get_feature.py:599: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features[k1] = np.array(features[k1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melspec:  100 313\n",
      "cqt:  80 157\n",
      "stft:  257 313\n"
     ]
    }
   ],
   "source": [
    "features_trn, mm_lbs_trn, out_lbs_trn, mel_input_shape, cqt_input_shape, stft_input_shape = get_features_3lb_all(train_folder, patient_files_trn, **params_feature)\n",
    "features_test, mm_lbs_test, out_lbs_test, _, _, _ = get_features_3lb_all(test_folder, patient_files_test, **params_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d6039a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "227096b2",
   "metadata": {},
   "source": [
    "### BC-ResNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62554565",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, maximum, DepthwiseConv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, SpatialDropout2D\n",
    "from tensorflow.keras.layers import Convolution2D, GlobalAveragePooling2D, MaxPool2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import add,concatenate\n",
    "from tensorflow.keras.activations import relu, softmax, swish\n",
    "\n",
    "def SubSpectralNorm(S, A = True, eps=1e-5):\n",
    "    # S : number of sub-bands\n",
    "    # A : 'Sub' Transform type if True, \n",
    "    #     'All' Transform type if False.          <- cannot be implemented yet.\n",
    "    # Can be applied only for image inputs.\n",
    "    \n",
    "    \n",
    "    def f(x):\n",
    "        if S == 1:\n",
    "            y = BatchNormalization()(x)\n",
    "            \n",
    "        else:\n",
    "            F = x.shape[1]             # number of frequencies of the input.\n",
    "            if F % S == 0:\n",
    "                Q = F // S             # length of each sub-band.\n",
    "                subs = []\n",
    "                for i in range(S):     \n",
    "                    subs.append(x[:, i*Q:(i+1)*Q, :,:])\n",
    "                    \n",
    "                for i in range(S):\n",
    "                    subs[i] = BatchNormalization()(subs[i])\n",
    "                    \n",
    "            else:\n",
    "                Q = F // S\n",
    "                subs = []\n",
    "                for i in range(S-1):\n",
    "                    subs.append(x[:,i*Q:(i+1)*Q,:,:])\n",
    "                    \n",
    "                subs.append(x[:,(S-1)*Q:,:,:])      # the shape of x and y must be the same.\n",
    "                \n",
    "                for i in range(S):\n",
    "                    subs[i] = BatchNormalization()(subs[i])\n",
    "                    \n",
    "            \n",
    "            y = tf.concat(subs, axis=1)\n",
    "            \n",
    "        return y\n",
    "    \n",
    "    return f\n",
    "\n",
    "\n",
    "def TF_ResMax_seq(out_channels = False, strides=(1,1), dilation_rate=(1,1),\n",
    "                  freq_kernel_size=(3,1), temporal_kernel_size=(1,3), dropout_rate=0.3):\n",
    "    \n",
    "    def f(x):\n",
    "        if out_channels:\n",
    "            y = Conv2D(filters=out_channels, kernel_size=(1,1), strides=strides,\n",
    "                       activation=None, kernel_initializer='he_uniform')(x)\n",
    "            y = BatchNormalization()(y)\n",
    "            y = relu(y)\n",
    "            \n",
    "            z = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "                                activation=None, kernel_initializer='he_uniform')(y)\n",
    "            z = SubSpectralNorm(S=2)(z)\n",
    "            \n",
    "        else :\n",
    "            z = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "                                activation=None, kernel_initializer='he_uniform')(x)\n",
    "            z = SubSpectralNorm(S=2)(z)\n",
    "            \n",
    "        z = relu(z)\n",
    "        z = DepthwiseConv2D(kernel_size=temporal_kernel_size, strides=(1,1), padding='same',\n",
    "                                activation=None, kernel_initializer='he_uniform')(z)\n",
    "        z = SubSpectralNorm(S=2)(z)\n",
    "            #        y = relu(y)\n",
    "        z = swish(z)\n",
    "            \n",
    "        if out_channels:\n",
    "            z = Conv2D(filters=y.shape[3], kernel_size=(1,1), strides=(1,1),\n",
    "                    activation='relu', kernel_initializer='he_uniform')(z)\n",
    "        else :\n",
    "            z = Conv2D(filters=x.shape[3], kernel_size=(1,1), strides=(1,1),\n",
    "                       activation='relu', kernel_initializer='he_uniform')(z)\n",
    "                \n",
    "        z = SpatialDropout2D(dropout_rate)(z)\n",
    "        ############################\n",
    "            \n",
    "        if out_channels:\n",
    "            return add([y, z])\n",
    "        else:\n",
    "            return add([x, z])\n",
    "            \n",
    "    return f\n",
    "\n",
    "\n",
    "    \n",
    "def BC_ResMax(out_channels = False, strides=(1,1), dilation_rate=(1,1), \n",
    "              freq_kernel_size=(3,1), temporal_kernel_size=(1,3), dropout_rate=0.1):\n",
    "\n",
    "    def f(x):\n",
    "        if out_channels:\n",
    "            y = Conv2D(filters=out_channels, kernel_size=(1,1), strides=strides, \n",
    "                       activation=None, kernel_initializer='he_uniform')(x)\n",
    "            y = BatchNormalization()(y)\n",
    "            y = relu(y)\n",
    "            \n",
    "            y = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "                                 activation=None, kernel_initializer='he_uniform')(y)\n",
    "#            y2 = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "#                                 activation=None, kernel_initializer='he_uniform')(y)\n",
    "#            y = tf.keras.layers.maximum([y1, y2])\n",
    "\n",
    "        else :\n",
    "            y = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "                                 activation=None, kernel_initializer='he_uniform')(x)\n",
    "#            y2 = DepthwiseConv2D(kernel_size=freq_kernel_size, strides=(1,1), padding='same',\n",
    "#                                 activation=None, kernel_initializer='he_uniform')(x)\n",
    "#            y = tf.keras.layers.maximum([y1, y2])\n",
    "            \n",
    "        y = SubSpectralNorm(S=2)(y)                   # Should be changed to SSN\n",
    "        y = relu(y)\n",
    "        ############################\n",
    "        \n",
    "        z = AveragePooling2D(pool_size=(y.shape[1],1))(y)\n",
    "        \n",
    "        ########### f1 #############\n",
    "        z = DepthwiseConv2D(kernel_size=temporal_kernel_size, strides=(1,1), dilation_rate=dilation_rate,\n",
    "                            padding='same', activation=None, kernel_initializer='he_uniform')(z)\n",
    "        z = BatchNormalization()(z)\n",
    "        z = swish(z)\n",
    "\n",
    "        z = Conv2D(filters=y.shape[3], kernel_size=(1,1), strides=(1,1),\n",
    "                   activation='relu', kernel_initializer='he_uniform')(z)\n",
    "        z = SpatialDropout2D(dropout_rate)(z)                  \n",
    "        ############################\n",
    "        \n",
    "        \n",
    "        ########### BC #############\n",
    "        z = UpSampling2D(size=(y.shape[1],1), interpolation='nearest')(z)\n",
    "        ############################\n",
    "        \n",
    "        if out_channels:\n",
    "            return add([y, z])\n",
    "        else: \n",
    "            return add([x, y, z])\n",
    "        \n",
    "    return f\n",
    "\n",
    "def ResMax(n_output, k, l, upscale=False):\n",
    "    def f(x):\n",
    "        conv1_1 = Conv2D(filters = n_output, kernel_size =k, strides=(1, 1), padding='same', activation=None)(x)\n",
    "        conv1_2 = Conv2D(filters = n_output, kernel_size =k, strides=(1, 1), padding='same', activation=None)(x)\n",
    "        h = maximum([conv1_1, conv1_2])\n",
    "        if l :\n",
    "            conv1_1 = Conv2D(filters = n_output, kernel_size =k, strides=(1, 1), padding='same', activation=None)(h)\n",
    "            conv1_2 = Conv2D(filters = n_output, kernel_size =k, strides=(1, 1), padding='same', activation=None)(h)\n",
    "            h = maximum([conv1_1, conv1_2])\n",
    "        if upscale:\n",
    "            f = Conv2D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\n",
    "        else:\n",
    "            f = x\n",
    "        return add([f, h])\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ResMax_1(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = True, use_stft = True):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "    cqt1 = keras.Input(shape=(cqt_input_shape), name = 'cqt')\n",
    "    stft1 = keras.Input(shape=(stft_input_shape), name = 'stft')\n",
    "        \n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = None)(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = None)(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = None)(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = None)(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(mel1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    mel2 = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    ## cqt embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(cqt1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    cqt2 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    ## stft embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(stft1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    stft2 = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "#    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, preg])\n",
    "#    d1 = layers.Dense(2, activation = 'relu')(concat1)\n",
    "    \n",
    "    if use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2, stft2])\n",
    "    if not use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([cqt2, stft2])\n",
    "    if use_mel and not use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, stft2])\n",
    "    if use_mel and use_cqt and not use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2])\n",
    "    if not use_mel and not use_cqt and use_stft :  ## stft 만\n",
    "        concat2 = stft2\n",
    "    if use_mel and not use_cqt and not use_stft :  ### mel만\n",
    "        concat2 = mel2\n",
    "    if not use_mel and use_cqt and not use_stft :  ### cqt만\n",
    "        concat2 = cqt2\n",
    "#    concat2 = layers.Dense(10, activation = 'relu')(concat2)\n",
    "    res1 = layers.Dense(3, activation = \"softmax\")(concat2)\n",
    "    res2 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1,cqt1,stft1] , outputs = res1 )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy','AUC'])\n",
    "    return(model)\n",
    "\n",
    "def get_ResMax_2(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = True, use_stft = True):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    mel1 = keras.Input(shape=(mel_input_shape), name = 'mel')\n",
    "    cqt1 = keras.Input(shape=(cqt_input_shape), name = 'cqt')\n",
    "    stft1 = keras.Input(shape=(stft_input_shape), name = 'stft')\n",
    "        \n",
    "        \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = None)(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = None)(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = None)(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = None)(loc)\n",
    "\n",
    "    ## mel embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(mel1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    mel2 = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    ## cqt embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(cqt1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    cqt2 = GlobalAveragePooling2D()(x)\n",
    "\n",
    "    ## stft embedding\n",
    "    x = ResMax(16,3,1, upscale = True)(stft1)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(16,5,1, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(24,3,1, upscale = True)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(32,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(32,3,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(48,3,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ResMax(48,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = True)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#    x = Dropout(dropout_rate)(x)\n",
    "    x = ResMax(64,1,0, upscale = False)(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    stft2 = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "#    concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, preg])\n",
    "#    d1 = layers.Dense(2, activation = 'relu')(concat1)\n",
    "    \n",
    "    if use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2, stft2])\n",
    "    if not use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([cqt2, stft2])\n",
    "    if use_mel and not use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, stft2])\n",
    "    if use_mel and use_cqt and not use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2])\n",
    "    if not use_mel and not use_cqt and use_stft :  ## stft 만\n",
    "        concat2 = stft2\n",
    "    if use_mel and not use_cqt and not use_stft :  ### mel만\n",
    "        concat2 = mel2\n",
    "    if not use_mel and use_cqt and not use_stft :  ### cqt만\n",
    "        concat2 = cqt2\n",
    "#    concat2 = layers.Dense(10, activation = 'relu')(concat2)\n",
    "    res1 = layers.Dense(3, activation = \"softmax\")(concat2)\n",
    "    res2 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,mel1,cqt1,stft1] , outputs = res2 )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy','AUC'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffc5531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1 = get_toy5_1(mel_input_shape, cqt_input_shape, stft_input_shape)\n",
    "#model2 = get_toy5_2(mel_input_shape, cqt_input_shape, stft_input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d247bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = get_ResMax_1(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = False, use_stft = False)\n",
    "model2 = get_ResMax_2(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = False, use_stft = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4802c7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_ResMax_2(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = False, use_stft = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f1abd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mel (InputLayer)                [(None, 100, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 100, 313, 16) 160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 100, 313, 16) 160         mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "maximum_35 (Maximum)            (None, 100, 313, 16) 0           conv2d_359[0][0]                 \n",
      "                                                                 conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 100, 313, 16) 2320        maximum_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 100, 313, 16) 2320        maximum_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 100, 313, 16) 32          mel[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "maximum_36 (Maximum)            (None, 100, 313, 16) 0           conv2d_361[0][0]                 \n",
      "                                                                 conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_206 (Add)                   (None, 100, 313, 16) 0           conv2d_363[0][0]                 \n",
      "                                                                 maximum_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_139 (MaxPooling2D (None, 50, 157, 16)  0           add_206[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_687 (BatchN (None, 50, 157, 16)  64          max_pooling2d_139[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 50, 157, 16)  6416        batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 50, 157, 16)  6416        batch_normalization_687[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_37 (Maximum)            (None, 50, 157, 16)  0           conv2d_364[0][0]                 \n",
      "                                                                 conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 50, 157, 16)  6416        maximum_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 50, 157, 16)  6416        maximum_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "maximum_38 (Maximum)            (None, 50, 157, 16)  0           conv2d_366[0][0]                 \n",
      "                                                                 conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_207 (Add)                   (None, 50, 157, 16)  0           batch_normalization_687[0][0]    \n",
      "                                                                 maximum_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_140 (MaxPooling2D (None, 25, 79, 16)   0           add_207[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_688 (BatchN (None, 25, 79, 16)   64          max_pooling2d_140[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 25, 79, 24)   3480        batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 25, 79, 24)   3480        batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_39 (Maximum)            (None, 25, 79, 24)   0           conv2d_368[0][0]                 \n",
      "                                                                 conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 25, 79, 24)   5208        maximum_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 25, 79, 24)   5208        maximum_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 25, 79, 24)   408         batch_normalization_688[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_40 (Maximum)            (None, 25, 79, 24)   0           conv2d_370[0][0]                 \n",
      "                                                                 conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_208 (Add)                   (None, 25, 79, 24)   0           conv2d_372[0][0]                 \n",
      "                                                                 maximum_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_141 (MaxPooling2D (None, 13, 40, 24)   0           add_208[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_689 (BatchN (None, 13, 40, 24)   96          max_pooling2d_141[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 13, 40, 32)   6944        batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 13, 40, 32)   6944        batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 13, 40, 32)   800         batch_normalization_689[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_41 (Maximum)            (None, 13, 40, 32)   0           conv2d_373[0][0]                 \n",
      "                                                                 conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_209 (Add)                   (None, 13, 40, 32)   0           conv2d_375[0][0]                 \n",
      "                                                                 maximum_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_690 (BatchN (None, 13, 40, 32)   128         add_209[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 13, 40, 32)   9248        batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 13, 40, 32)   9248        batch_normalization_690[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_42 (Maximum)            (None, 13, 40, 32)   0           conv2d_376[0][0]                 \n",
      "                                                                 conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_210 (Add)                   (None, 13, 40, 32)   0           batch_normalization_690[0][0]    \n",
      "                                                                 maximum_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_142 (MaxPooling2D (None, 7, 20, 32)    0           add_210[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_691 (BatchN (None, 7, 20, 32)    128         max_pooling2d_142[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 7, 20, 48)    13872       batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 7, 20, 48)    13872       batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 7, 20, 48)    1584        batch_normalization_691[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_43 (Maximum)            (None, 7, 20, 48)    0           conv2d_378[0][0]                 \n",
      "                                                                 conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_211 (Add)                   (None, 7, 20, 48)    0           conv2d_380[0][0]                 \n",
      "                                                                 maximum_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_692 (BatchN (None, 7, 20, 48)    192         add_211[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 7, 20, 48)    2352        batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 7, 20, 48)    2352        batch_normalization_692[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_44 (Maximum)            (None, 7, 20, 48)    0           conv2d_381[0][0]                 \n",
      "                                                                 conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_212 (Add)                   (None, 7, 20, 48)    0           batch_normalization_692[0][0]    \n",
      "                                                                 maximum_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_143 (MaxPooling2D (None, 4, 10, 48)    0           add_212[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_693 (BatchN (None, 4, 10, 48)    192         max_pooling2d_143[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 4, 10, 64)    3136        batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 4, 10, 64)    3136        batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, 4, 10, 64)    3136        batch_normalization_693[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_45 (Maximum)            (None, 4, 10, 64)    0           conv2d_383[0][0]                 \n",
      "                                                                 conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_213 (Add)                   (None, 4, 10, 64)    0           conv2d_385[0][0]                 \n",
      "                                                                 maximum_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_694 (BatchN (None, 4, 10, 64)    256         add_213[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, 4, 10, 64)    4160        batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, 4, 10, 64)    4160        batch_normalization_694[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "maximum_46 (Maximum)            (None, 4, 10, 64)    0           conv2d_386[0][0]                 \n",
      "                                                                 conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_214 (Add)                   (None, 4, 10, 64)    0           batch_normalization_694[0][0]    \n",
      "                                                                 maximum_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_144 (MaxPooling2D (None, 2, 5, 64)     0           add_214[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_695 (BatchN (None, 2, 5, 64)     256         max_pooling2d_144[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_24 (Gl (None, 64)           0           batch_normalization_695[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "age_cat (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sex_cat (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "height_weight (InputLayer)      [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "is_preg (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "loc (InputLayer)                [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cqt (InputLayer)                [(None, 80, 157, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stft (InputLayer)               [(None, 257, 313, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 3)            195         global_average_pooling2d_24[0][0]\n",
      "==================================================================================================\n",
      "Total params: 134,955\n",
      "Trainable params: 134,267\n",
      "Non-trainable params: 688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe327878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 10s 193ms/step - loss: 1.0851 - accuracy: 0.4959 - auc: 0.6092 - val_loss: 22.0364 - val_accuracy: 0.0000e+00 - val_auc: 0.2858\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.8438 - accuracy: 0.7308 - auc: 0.8195 - val_loss: 4.3298 - val_accuracy: 0.0000e+00 - val_auc: 0.4152\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.6672 - accuracy: 0.7647 - auc: 0.8702 - val_loss: 1.7374 - val_accuracy: 0.2456 - val_auc: 0.3062\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.6014 - accuracy: 0.7784 - auc: 0.8805 - val_loss: 0.6352 - val_accuracy: 0.7956 - val_auc: 0.8885\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.5961 - accuracy: 0.7492 - auc: 0.8836 - val_loss: 0.5584 - val_accuracy: 0.7544 - val_auc: 0.8864\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.5510 - accuracy: 0.7834 - auc: 0.8918 - val_loss: 0.5770 - val_accuracy: 0.7702 - val_auc: 0.9002\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5506 - accuracy: 0.7860 - auc: 0.8878 - val_loss: 0.4925 - val_accuracy: 0.8051 - val_auc: 0.9035\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.5535 - accuracy: 0.7809 - auc: 0.8938 - val_loss: 0.4931 - val_accuracy: 0.8304 - val_auc: 0.9007\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5349 - accuracy: 0.7828 - auc: 0.8922 - val_loss: 0.4961 - val_accuracy: 0.8431 - val_auc: 0.9049\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.5245 - accuracy: 0.7839 - auc: 0.8958 - val_loss: 0.4717 - val_accuracy: 0.8209 - val_auc: 0.9069\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 6s 161ms/step - loss: 0.5455 - accuracy: 0.7839 - auc: 0.8928 - val_loss: 0.4576 - val_accuracy: 0.8431 - val_auc: 0.9104\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5270 - accuracy: 0.7893 - auc: 0.8958 - val_loss: 0.4822 - val_accuracy: 0.7924 - val_auc: 0.9007\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.5534 - accuracy: 0.7635 - auc: 0.8894 - val_loss: 0.4796 - val_accuracy: 0.7861 - val_auc: 0.9108\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.5336 - accuracy: 0.7841 - auc: 0.8979 - val_loss: 0.5213 - val_accuracy: 0.7528 - val_auc: 0.9045\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.5315 - accuracy: 0.8029 - auc: 0.8900 - val_loss: 0.4986 - val_accuracy: 0.7639 - val_auc: 0.9055\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5319 - accuracy: 0.7803 - auc: 0.8950 - val_loss: 0.4562 - val_accuracy: 0.8146 - val_auc: 0.9153\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5308 - accuracy: 0.7832 - auc: 0.8949 - val_loss: 0.5094 - val_accuracy: 0.8320 - val_auc: 0.9093\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 6s 165ms/step - loss: 0.5489 - accuracy: 0.7614 - auc: 0.8996 - val_loss: 0.4818 - val_accuracy: 0.8177 - val_auc: 0.9088\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5373 - accuracy: 0.7783 - auc: 0.8920 - val_loss: 0.4417 - val_accuracy: 0.8463 - val_auc: 0.9163\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.5346 - accuracy: 0.7794 - auc: 0.8994 - val_loss: 0.4504 - val_accuracy: 0.8336 - val_auc: 0.9130\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5273 - accuracy: 0.7925 - auc: 0.8963 - val_loss: 0.4775 - val_accuracy: 0.7861 - val_auc: 0.9116\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 6s 165ms/step - loss: 0.5322 - accuracy: 0.7777 - auc: 0.8928 - val_loss: 0.4683 - val_accuracy: 0.7765 - val_auc: 0.9134\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.5178 - accuracy: 0.7791 - auc: 0.8981 - val_loss: 0.4448 - val_accuracy: 0.8479 - val_auc: 0.9250\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5109 - accuracy: 0.7853 - auc: 0.9021 - val_loss: 0.4802 - val_accuracy: 0.8399 - val_auc: 0.9137\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5356 - accuracy: 0.7873 - auc: 0.8965 - val_loss: 0.5334 - val_accuracy: 0.8399 - val_auc: 0.9144\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.5134 - accuracy: 0.7963 - auc: 0.9009 - val_loss: 0.4796 - val_accuracy: 0.7892 - val_auc: 0.9092\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5281 - accuracy: 0.7963 - auc: 0.8962 - val_loss: 0.4579 - val_accuracy: 0.8225 - val_auc: 0.9160\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.5348 - accuracy: 0.7729 - auc: 0.9022 - val_loss: 0.4583 - val_accuracy: 0.8304 - val_auc: 0.9142\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5254 - accuracy: 0.7872 - auc: 0.8990 - val_loss: 0.4559 - val_accuracy: 0.8225 - val_auc: 0.9122\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5363 - accuracy: 0.7760 - auc: 0.9005 - val_loss: 0.4637 - val_accuracy: 0.8494 - val_auc: 0.9144\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.5102 - accuracy: 0.7934 - auc: 0.9019 - val_loss: 0.4446 - val_accuracy: 0.8479 - val_auc: 0.9157\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 7s 176ms/step - loss: 0.5318 - accuracy: 0.7841 - auc: 0.9008 - val_loss: 0.4636 - val_accuracy: 0.8162 - val_auc: 0.9143\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5245 - accuracy: 0.7986 - auc: 0.9017 - val_loss: 0.4380 - val_accuracy: 0.8574 - val_auc: 0.9207\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.5020 - accuracy: 0.7999 - auc: 0.9012 - val_loss: 0.4719 - val_accuracy: 0.8384 - val_auc: 0.9138\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 7s 165ms/step - loss: 0.5194 - accuracy: 0.7873 - auc: 0.9036 - val_loss: 0.4652 - val_accuracy: 0.8162 - val_auc: 0.9124\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.5210 - accuracy: 0.7873 - auc: 0.8995 - val_loss: 0.4513 - val_accuracy: 0.8273 - val_auc: 0.9149\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5164 - accuracy: 0.7946 - auc: 0.8997 - val_loss: 0.4519 - val_accuracy: 0.8193 - val_auc: 0.9149\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5099 - accuracy: 0.7853 - auc: 0.9051 - val_loss: 0.4697 - val_accuracy: 0.7876 - val_auc: 0.9107\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.4956 - accuracy: 0.7993 - auc: 0.9056 - val_loss: 0.4556 - val_accuracy: 0.8146 - val_auc: 0.9141\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5239 - accuracy: 0.7856 - auc: 0.9055 - val_loss: 0.4765 - val_accuracy: 0.8193 - val_auc: 0.9150\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 7s 175ms/step - loss: 0.4931 - accuracy: 0.8044 - auc: 0.9048 - val_loss: 0.4972 - val_accuracy: 0.7591 - val_auc: 0.9058\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 6s 165ms/step - loss: 0.5292 - accuracy: 0.7809 - auc: 0.9033 - val_loss: 0.4930 - val_accuracy: 0.7559 - val_auc: 0.9081\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 7s 177ms/step - loss: 0.5194 - accuracy: 0.7874 - auc: 0.9023 - val_loss: 0.4488 - val_accuracy: 0.8526 - val_auc: 0.9179\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.5211 - accuracy: 0.7879 - auc: 0.8977 - val_loss: 0.4450 - val_accuracy: 0.8574 - val_auc: 0.9176\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5268 - accuracy: 0.7859 - auc: 0.9042 - val_loss: 0.4303 - val_accuracy: 0.8590 - val_auc: 0.9230\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 6s 162ms/step - loss: 0.5142 - accuracy: 0.7867 - auc: 0.9063 - val_loss: 0.4773 - val_accuracy: 0.8352 - val_auc: 0.9181\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 7s 174ms/step - loss: 0.5014 - accuracy: 0.8004 - auc: 0.9054 - val_loss: 0.4453 - val_accuracy: 0.8605 - val_auc: 0.9218\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5358 - accuracy: 0.7751 - auc: 0.8977 - val_loss: 0.4647 - val_accuracy: 0.8241 - val_auc: 0.9123\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 6s 165ms/step - loss: 0.4965 - accuracy: 0.7940 - auc: 0.9041 - val_loss: 0.4493 - val_accuracy: 0.8336 - val_auc: 0.9133\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5207 - accuracy: 0.7864 - auc: 0.9066 - val_loss: 0.4576 - val_accuracy: 0.8510 - val_auc: 0.9120\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.4943 - accuracy: 0.7988 - auc: 0.9087 - val_loss: 0.4526 - val_accuracy: 0.8352 - val_auc: 0.9146\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.5208 - accuracy: 0.7813 - auc: 0.9083 - val_loss: 0.4827 - val_accuracy: 0.7876 - val_auc: 0.9087\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.5051 - accuracy: 0.7950 - auc: 0.9063 - val_loss: 0.4614 - val_accuracy: 0.8574 - val_auc: 0.9167\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5207 - accuracy: 0.7820 - auc: 0.9058 - val_loss: 0.4507 - val_accuracy: 0.8320 - val_auc: 0.9149\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.5175 - accuracy: 0.7758 - auc: 0.9091 - val_loss: 0.4493 - val_accuracy: 0.8447 - val_auc: 0.9168\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.5185 - accuracy: 0.7886 - auc: 0.9088 - val_loss: 0.4455 - val_accuracy: 0.8494 - val_auc: 0.9175\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5149 - accuracy: 0.7883 - auc: 0.9074 - val_loss: 0.4565 - val_accuracy: 0.8336 - val_auc: 0.9137\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.4811 - accuracy: 0.7942 - auc: 0.9135 - val_loss: 0.4534 - val_accuracy: 0.8273 - val_auc: 0.9128\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.4730 - accuracy: 0.8011 - auc: 0.9150 - val_loss: 0.4452 - val_accuracy: 0.8574 - val_auc: 0.9128\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.5191 - accuracy: 0.7898 - auc: 0.9053 - val_loss: 0.4406 - val_accuracy: 0.8526 - val_auc: 0.9160\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.4994 - accuracy: 0.8083 - auc: 0.9134 - val_loss: 0.4439 - val_accuracy: 0.8590 - val_auc: 0.9179\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.5004 - accuracy: 0.8091 - auc: 0.9095 - val_loss: 0.4496 - val_accuracy: 0.8494 - val_auc: 0.9150\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.4796 - accuracy: 0.8150 - auc: 0.9121 - val_loss: 0.4564 - val_accuracy: 0.8288 - val_auc: 0.9130\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.4996 - accuracy: 0.7926 - auc: 0.9104 - val_loss: 0.4467 - val_accuracy: 0.8415 - val_auc: 0.9147\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.4816 - accuracy: 0.8115 - auc: 0.9097 - val_loss: 0.4500 - val_accuracy: 0.8542 - val_auc: 0.9163\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5251 - accuracy: 0.7822 - auc: 0.9093 - val_loss: 0.4434 - val_accuracy: 0.8479 - val_auc: 0.9152\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.5091 - accuracy: 0.7905 - auc: 0.9097 - val_loss: 0.4611 - val_accuracy: 0.8384 - val_auc: 0.9141\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5007 - accuracy: 0.7968 - auc: 0.9112 - val_loss: 0.4537 - val_accuracy: 0.8415 - val_auc: 0.9152\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.4987 - accuracy: 0.7907 - auc: 0.9140 - val_loss: 0.4484 - val_accuracy: 0.8399 - val_auc: 0.9163\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.4907 - accuracy: 0.8011 - auc: 0.9183 - val_loss: 0.4455 - val_accuracy: 0.8352 - val_auc: 0.9167\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.4864 - accuracy: 0.7881 - auc: 0.9152 - val_loss: 0.4440 - val_accuracy: 0.8368 - val_auc: 0.9166\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5029 - accuracy: 0.7991 - auc: 0.9087 - val_loss: 0.4470 - val_accuracy: 0.8415 - val_auc: 0.9153\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.5174 - accuracy: 0.7795 - auc: 0.9112 - val_loss: 0.4514 - val_accuracy: 0.8415 - val_auc: 0.9148\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.4800 - accuracy: 0.8061 - auc: 0.9160 - val_loss: 0.4534 - val_accuracy: 0.8384 - val_auc: 0.9144\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.4942 - accuracy: 0.7991 - auc: 0.9123 - val_loss: 0.4520 - val_accuracy: 0.8399 - val_auc: 0.9140\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.4735 - accuracy: 0.8171 - auc: 0.9141 - val_loss: 0.4523 - val_accuracy: 0.8415 - val_auc: 0.9119\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.4918 - accuracy: 0.7967 - auc: 0.9162 - val_loss: 0.4481 - val_accuracy: 0.8447 - val_auc: 0.9137\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.5021 - accuracy: 0.7879 - auc: 0.9132 - val_loss: 0.4445 - val_accuracy: 0.8447 - val_auc: 0.9143\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.4862 - accuracy: 0.8046 - auc: 0.9149 - val_loss: 0.4474 - val_accuracy: 0.8463 - val_auc: 0.9145\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.4814 - accuracy: 0.8092 - auc: 0.9157 - val_loss: 0.4463 - val_accuracy: 0.8447 - val_auc: 0.9147\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.4998 - accuracy: 0.7897 - auc: 0.9175 - val_loss: 0.4489 - val_accuracy: 0.8431 - val_auc: 0.9143\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.4588 - accuracy: 0.8231 - auc: 0.9190 - val_loss: 0.4482 - val_accuracy: 0.8415 - val_auc: 0.9141\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.4790 - accuracy: 0.8046 - auc: 0.9173 - val_loss: 0.4482 - val_accuracy: 0.8415 - val_auc: 0.9139\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.4814 - accuracy: 0.7961 - auc: 0.9116 - val_loss: 0.4507 - val_accuracy: 0.8399 - val_auc: 0.9138\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5115 - accuracy: 0.7782 - auc: 0.9134 - val_loss: 0.4515 - val_accuracy: 0.8384 - val_auc: 0.9137\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.4758 - accuracy: 0.8122 - auc: 0.9135 - val_loss: 0.4501 - val_accuracy: 0.8384 - val_auc: 0.9141\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 6s 163ms/step - loss: 0.5141 - accuracy: 0.7861 - auc: 0.9154 - val_loss: 0.4514 - val_accuracy: 0.8384 - val_auc: 0.9132\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.4978 - accuracy: 0.7949 - auc: 0.9141 - val_loss: 0.4527 - val_accuracy: 0.8368 - val_auc: 0.9136\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 7s 166ms/step - loss: 0.5002 - accuracy: 0.7872 - auc: 0.9185 - val_loss: 0.4526 - val_accuracy: 0.8352 - val_auc: 0.9132\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5085 - accuracy: 0.7860 - auc: 0.9109 - val_loss: 0.4518 - val_accuracy: 0.8384 - val_auc: 0.9137\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.4697 - accuracy: 0.8127 - auc: 0.9170 - val_loss: 0.4535 - val_accuracy: 0.8399 - val_auc: 0.9136\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.4705 - accuracy: 0.8083 - auc: 0.9173 - val_loss: 0.4529 - val_accuracy: 0.8415 - val_auc: 0.9132\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.4884 - accuracy: 0.7943 - auc: 0.9155 - val_loss: 0.4512 - val_accuracy: 0.8447 - val_auc: 0.9137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "40/40 [==============================] - 7s 174ms/step - loss: 0.4920 - accuracy: 0.8097 - auc: 0.9131 - val_loss: 0.4519 - val_accuracy: 0.8431 - val_auc: 0.9138\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 7s 169ms/step - loss: 0.5047 - accuracy: 0.7882 - auc: 0.9191 - val_loss: 0.4519 - val_accuracy: 0.8431 - val_auc: 0.9133\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 6s 164ms/step - loss: 0.5009 - accuracy: 0.7960 - auc: 0.9133 - val_loss: 0.4530 - val_accuracy: 0.8399 - val_auc: 0.9132\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.5037 - accuracy: 0.7926 - auc: 0.9121 - val_loss: 0.4537 - val_accuracy: 0.8399 - val_auc: 0.9129\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 7s 172ms/step - loss: 0.4839 - accuracy: 0.7987 - auc: 0.9165 - val_loss: 0.4528 - val_accuracy: 0.8399 - val_auc: 0.9134\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.4987 - accuracy: 0.7968 - auc: 0.9100 - val_loss: 0.4516 - val_accuracy: 0.8431 - val_auc: 0.9135\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 7s 171ms/step - loss: 0.4811 - accuracy: 0.8095 - auc: 0.9155 - val_loss: 0.4506 - val_accuracy: 0.8447 - val_auc: 0.9137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7f586b9950>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "batch_size = 64\n",
    "params = {'batch_size': batch_size,\n",
    "#          'input_shape': (100, 313, 1),\n",
    "          'shuffle': True,\n",
    "          'beta_param': 0.7,\n",
    "          'mixup': True,\n",
    "#          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "#          'highpass': [.5, [78,79,80,81,82,83,84,85]]\n",
    "          'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "#           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "}\n",
    "\n",
    "params_no_shuffle = {'batch_size': batch_size,\n",
    "#          'input_shape': (100, 313, 1),\n",
    "          'shuffle': False,\n",
    "          'beta_param': 0.7,\n",
    "          'mixup': False\n",
    "          #'device': device\n",
    "}\n",
    "\n",
    "TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], features_trn['preg'], features_trn['loc'], \n",
    "           features_trn['mel1'],features_trn['cqt1'],features_trn['stft1']], \n",
    "                        mm_lbs_trn,  ## our Y\n",
    "                        **params)()\n",
    "\n",
    "#ValDGen_1 = Generator0([features_test[0]['age'],features_test[0]['sex'], features_test[0]['hw'], features_test[0]['preg'], features_test[0]['loc'], \n",
    "#           features_test[0]['mel1'],features_test[0]['cqt1'],features_test[0]['stft1']], \n",
    "#                        mm_lbs_test,  ## our Y\n",
    "#                        **params_no_shuffle)()\n",
    "\n",
    "    \n",
    "model1.fit(TrainDGen_1,\n",
    "          validation_data = ([features_test['age'],features_test['sex'], features_test['hw'], \n",
    "                              features_test['preg'], features_test['loc'], features_test['mel1'], \n",
    "                              features_test['cqt1'], features_test['stft1']], \n",
    "                             mm_lbs_test), \n",
    "                             callbacks=[lr],\n",
    "                              steps_per_epoch=np.ceil(len(mm_lbs_trn)/64),\n",
    "                             epochs = n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d23f4",
   "metadata": {},
   "source": [
    "트레이닝 accuracy 와 auc 가 validation accuracy, auc 와 거의 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1630e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 10s 199ms/step - loss: 0.7386 - accuracy: 0.5084 - auc: 0.5170 - val_loss: 86.4623 - val_accuracy: 0.5008 - val_auc: 0.5008\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.7102 - accuracy: 0.4956 - auc: 0.5135 - val_loss: 19.5566 - val_accuracy: 0.5008 - val_auc: 0.5008\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 7s 167ms/step - loss: 0.6964 - accuracy: 0.5340 - auc: 0.5626 - val_loss: 1.7648 - val_accuracy: 0.5040 - val_auc: 0.5543\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 7s 177ms/step - loss: 0.6944 - accuracy: 0.5336 - auc: 0.5590 - val_loss: 1.7856 - val_accuracy: 0.5008 - val_auc: 0.5767\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.6903 - accuracy: 0.5515 - auc: 0.5816 - val_loss: 1.2897 - val_accuracy: 0.5119 - val_auc: 0.5785\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 7s 173ms/step - loss: 0.6894 - accuracy: 0.5336 - auc: 0.5735 - val_loss: 0.7023 - val_accuracy: 0.5166 - val_auc: 0.5090\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 7s 179ms/step - loss: 0.6854 - accuracy: 0.5750 - auc: 0.5938 - val_loss: 0.9860 - val_accuracy: 0.5198 - val_auc: 0.5756\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 7s 170ms/step - loss: 0.6922 - accuracy: 0.5360 - auc: 0.5695 - val_loss: 0.7097 - val_accuracy: 0.5515 - val_auc: 0.5691\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 7s 168ms/step - loss: 0.6901 - accuracy: 0.5467 - auc: 0.5730 - val_loss: 0.6616 - val_accuracy: 0.6022 - val_auc: 0.6436\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 7s 180ms/step - loss: 0.6889 - accuracy: 0.5515 - auc: 0.5766 - val_loss: 0.6931 - val_accuracy: 0.5246 - val_auc: 0.5561\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 7s 181ms/step - loss: 0.6846 - accuracy: 0.5668 - auc: 0.6056 - val_loss: 0.6796 - val_accuracy: 0.5610 - val_auc: 0.5932\n",
      "Epoch 12/100\n",
      "29/40 [====================>.........] - ETA: 1s - loss: 0.6873 - accuracy: 0.5351 - auc: 0.5862"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "batch_size = 64\n",
    "params = {'batch_size': batch_size,\n",
    "#          'input_shape': (100, 313, 1),\n",
    "          'shuffle': True,\n",
    "          'beta_param': 0.7,\n",
    "          'mixup': True,\n",
    "#          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "          'highpass': [.5, [78,79,80,81,82,83,84,85]],\n",
    "          'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "#           'dropblock' : [30, 100]\n",
    "          #'device' : device\n",
    "}\n",
    "\n",
    "params_no_shuffle = {'batch_size': batch_size,\n",
    "#          'input_shape': (100, 313, 1),\n",
    "          'shuffle': False,\n",
    "          'beta_param': 0.7,\n",
    "          'mixup': False\n",
    "          #'device': device\n",
    "}\n",
    "\n",
    "TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], features_trn['preg'], features_trn['loc'], \n",
    "           features_trn['mel1'],features_trn['cqt1'],features_trn['stft1']], \n",
    "                        out_lbs_trn,  ## our Y\n",
    "                        **params)()\n",
    "\n",
    "#ValDGen_1 = Generator0([features_test[0]['age'],features_test[0]['sex'], features_test[0]['hw'], features_test[0]['preg'], features_test[0]['loc'], \n",
    "#           features_test[0]['mel1'],features_test[0]['cqt1'],features_test[0]['stft1']], \n",
    "#                        features_test[2],  ## our Y\n",
    "#                        **params_no_shuffle)()\n",
    "\n",
    "    \n",
    "model2.fit(TrainDGen_1,\n",
    "          validation_data = ([features_test['age'],features_test['sex'], features_test['hw'], \n",
    "                              features_test['preg'], features_test['loc'], features_test['mel1'], \n",
    "                              features_test['cqt1'], features_test['stft1']], \n",
    "                             out_lbs_test), \n",
    "                             callbacks=[lr],\n",
    "                              steps_per_epoch=np.ceil(len(out_lbs_trn)/64),\n",
    "                             epochs = n_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fa63b",
   "metadata": {},
   "source": [
    "### 팀코드 수정해야 할 함수들.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eacb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature['mel_shape'] = mel_input_shape\n",
    "params_feature['cqt_shape'] = cqt_input_shape\n",
    "params_feature['stft_shape'] = stft_input_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ba728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model(model_folder, model1, model2, m_name1, m_name2, param_feature) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename1 = os.path.join(model_folder, m_name1 + '_model1.hdf5')\n",
    "    filename2 = os.path.join(model_folder, m_name2 + '_model2.hdf5')\n",
    "    model1.save(filename1)\n",
    "    model2.save(filename2)\n",
    "    param_feature['model1'] = m_name1\n",
    "    param_feature['model2'] = m_name2\n",
    "    param_feature['model_fnm1'] = filename1\n",
    "    param_feature['model_fnm2'] = filename2\n",
    "\n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(param_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb83741",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_challenge_model(model_folder, model1, model2, m_name1 = 'resmax1', m_name2 = 'resmax2', param_feature = params_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    with open(info_fnm, 'rb') as f:\n",
    "        info_m = pk.load(f)\n",
    "#    if info_m['model'] == 'toy' :\n",
    "#        model = get_toy(info_m['mel_shape'])\n",
    "#    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "#    model.load_weights(filename)\n",
    "    return info_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    \n",
    "    if model['model1'] == 'toy1' :\n",
    "        model1 = get_toy5_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'] )\n",
    "    if model['model2'] == 'toy2' :\n",
    "        model2 = get_toy5_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'])\n",
    "    if model['model1'] == 'lcnn1' :\n",
    "        model1 = get_LCNN_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    if model['model2'] == 'lcnn2' :\n",
    "        model2 = get_LCNN_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    if model['model1'] == 'resmax1' :\n",
    "        model1 = get_ResMax_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    if model['model2'] == 'resmax2' :\n",
    "        model2 = get_ResMax_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    if model['model1'] == 'bcresmax1' :\n",
    "        model1 = get_BCResMax_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    if model['model2'] == 'bcresmax2' :\n",
    "        model2 = get_BCResMax_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = True, use_cqt = False, use_stft = False)\n",
    "    model1.load_weights(model['model_fnm1'])\n",
    "    model2.load_weights(model['model_fnm2'])\n",
    "    \n",
    "#    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "    samp_sec = model['samp_sec'] \n",
    "    pre_emphasis = model['pre_emphasis']\n",
    "    hop_length = model['hop_length']\n",
    "    win_length = model['win_length']\n",
    "    n_mels = model['n_mels']\n",
    "    filter_scale = model['filter_scale']\n",
    "    n_bins = model['n_bins']\n",
    "    fmin = model['fmin']\n",
    "    \n",
    "    features['mel1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_melspec(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                           win_length = win_length, n_mels = n_mels)[0]\n",
    "        features['mel1'].append(mel1)\n",
    "    M, N = features['mel1'][0].shape\n",
    "    for i in range(len(features['mel1'])) :\n",
    "        features['mel1'][i] = features['mel1'][i].reshape(M,N,1)   \n",
    "    features['mel1'] = np.array(features['mel1'])\n",
    "\n",
    "    features['cqt1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_cqt(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, filter_scale = filter_scale, \n",
    "                                        n_bins = n_bins, fmin = fmin)[0]\n",
    "        features['cqt1'].append(mel1)\n",
    "    M, N = features['cqt1'][0].shape\n",
    "    for i in range(len(features['cqt1'])) :\n",
    "        features['cqt1'][i] = features['cqt1'][i].reshape(M,N,1)   \n",
    "    features['cqt1'] = np.array(features['cqt1'])\n",
    "\n",
    "    features['stft1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        mel1 = feature_extract_stft(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                       win_length = win_length)[0]\n",
    "        features['stft1'].append(mel1)\n",
    "    M, N = features['stft1'][0].shape\n",
    "    for i in range(len(features['stft1'])) :\n",
    "        features['stft1'][i] = features['stft1'][i].reshape(M,N,1)           \n",
    "    features['stft1'] = np.array(features['stft1'])\n",
    "\n",
    "    #    print(features)\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1'], features['cqt1'], features['stft1']])\n",
    "    res2 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], features['mel1'], features['cqt1'], features['stft1']])\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    idx1 = res1.argmax(axis=0)[0]\n",
    "    murmur_probabilities = res1[idx1,]  ## mumur 확률 최대화 되는 애 뽑기\n",
    "    outcome_probabilities = res2.mean(axis = 0) ##  outcome 은 그냥 평균으로 뽑기\n",
    "#    idx = np.argmax(prob1)\n",
    "\n",
    "    ## 이부분도 생각 필요.. rule 을 cost를 maximize 하는 기준으로 threshold 탐색 필요할지도..\n",
    "    # Choose label with highest probability.\n",
    "    murmur_labels = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "    idx = np.argmax(murmur_probabilities)\n",
    "    murmur_labels[idx] = 1\n",
    "    outcome_labels = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "    idx = np.argmax(outcome_probabilities)\n",
    "    outcome_labels[idx] = 1\n",
    "    \n",
    "    # Concatenate classes, labels, and probabilities.\n",
    "    classes = murmur_classes + outcome_classes\n",
    "    labels = np.concatenate((murmur_labels, outcome_labels))\n",
    "    probabilities = np.concatenate((murmur_probabilities, outcome_probabilities))\n",
    "    \n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28b4c2",
   "metadata": {},
   "source": [
    "### 대회 평가용 run_model 함수 (수정 불필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769299d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model.\n",
    "def run_model(model_folder, data_folder, output_folder, allow_failures, verbose):\n",
    "    # Load models.\n",
    "    if verbose >= 1:\n",
    "        print('Loading Challenge model...')\n",
    "\n",
    "    model = load_challenge_model(model_folder, verbose) ### Teams: Implement this function!!!\n",
    "\n",
    "    # Find the patient data files.\n",
    "    patient_files = find_patient_files(data_folder)\n",
    "    num_patient_files = len(patient_files)\n",
    "\n",
    "    if num_patient_files==0:\n",
    "        raise Exception('No data was provided.')\n",
    "\n",
    "    # Create a folder for the Challenge outputs if it does not already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Run the team's model on the Challenge data.\n",
    "    if verbose >= 1:\n",
    "        print('Running model on Challenge data...')\n",
    "\n",
    "    # Iterate over the patient files.\n",
    "    for i in range(num_patient_files):\n",
    "        if verbose >= 2:\n",
    "            print('    {}/{}...'.format(i+1, num_patient_files))\n",
    "\n",
    "        patient_data = load_patient_data(patient_files[i])\n",
    "        recordings = load_recordings(data_folder, patient_data)\n",
    "\n",
    "        # Allow or disallow the model to fail on parts of the data; helpful for debugging.\n",
    "        try:\n",
    "            classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "        except:\n",
    "            if allow_failures:\n",
    "                if verbose >= 2:\n",
    "                    print('... failed.')\n",
    "                classes, labels, probabilities = list(), list(), list()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Save Challenge outputs.\n",
    "        head, tail = os.path.split(patient_files[i])\n",
    "        root, extension = os.path.splitext(tail)\n",
    "        output_file = os.path.join(output_folder, root + '.csv')\n",
    "        patient_id = get_patient_id(patient_data)\n",
    "        save_challenge_outputs(output_file, patient_id, classes, labels, probabilities)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba835b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 우리 모형 저장된 폴더이름\n",
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트 데이터 폴더\n",
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d52354",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 테스트 데이터에 모형 돌려서 스코어 저장할 폴더\n",
    "output_folder = '/home/ubuntu/hmd/notebooks/out_resmax1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e825de39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_model(model_folder, test_folder, output_folder, allow_failures = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11ec46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cat /home/ubuntu/hmd/notebooks/out_lcnn1/49628.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "murmur_scores, outcome_scores = evaluate_model(test_folder, output_folder)\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "    + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "\n",
    "if len(sys.argv) == 3:\n",
    "    print(output_string)\n",
    "elif len(sys.argv) == 4:\n",
    "    with open(sys.argv[3], 'w') as f:\n",
    "        f.write(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd3ae37",
   "metadata": {},
   "source": [
    "### Threshold 변경해가며 결과 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f7a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_folder = test_folder\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "# Load and parse label and model output files.\n",
    "label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "murmur_labels = load_murmurs(label_files, murmur_classes)\n",
    "murmur_binary_outputs, murmur_scalar_outputs = load_classifier_outputs(output_files, murmur_classes)\n",
    "outcome_labels = load_outcomes(label_files, outcome_classes)\n",
    "outcome_binary_outputs, outcome_scalar_outputs = load_classifier_outputs(output_files, outcome_classes)\n",
    "\n",
    "\n",
    "print(np.mean(murmur_scalar_outputs[:,0]))\n",
    "print(np.mean(murmur_scalar_outputs[:,2]))\n",
    "print(np.mean(outcome_scalar_outputs[:,0]))\n",
    "print(np.mean(outcome_scalar_outputs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b61ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## threshold 바꿔가면서 결과 출력\n",
    "\n",
    "for th1 in [0.01, 0.05, 0.1, 0.15,0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8] :\n",
    "    murmur_binary_outputs[:,0] = murmur_scalar_outputs[:,0] > th1\n",
    "    murmur_binary_outputs[:,2] = murmur_scalar_outputs[:,2] > 1 - th1\n",
    "    outcome_binary_outputs[:,0] = outcome_scalar_outputs[:,0] > th1\n",
    "    outcome_binary_outputs[:,1] = outcome_scalar_outputs[:,1] > 1 - th1\n",
    "    # For each patient, set the 'Present' or 'Abnormal' class to positive if no class is positive or if multiple classes are positive.\n",
    "    murmur_labels = enforce_positives(murmur_labels, murmur_classes, 'Present')\n",
    "    murmur_binary_outputs = enforce_positives(murmur_binary_outputs, murmur_classes, 'Present')\n",
    "    outcome_labels = enforce_positives(outcome_labels, outcome_classes, 'Abnormal')\n",
    "    outcome_binary_outputs = enforce_positives(outcome_binary_outputs, outcome_classes, 'Abnormal')\n",
    "    # Evaluate the murmur model by comparing the labels and model outputs.\n",
    "    murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes = compute_auc(murmur_labels, murmur_scalar_outputs)\n",
    "    murmur_f_measure, murmur_f_measure_classes = compute_f_measure(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_accuracy, murmur_accuracy_classes = compute_accuracy(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_weighted_accuracy = compute_weighted_accuracy(murmur_labels, murmur_binary_outputs, murmur_classes) # This is the murmur scoring metric.\n",
    "    murmur_cost = compute_cost(outcome_labels, murmur_binary_outputs, outcome_classes, murmur_classes) # Use *outcomes* to score *murmurs* for the Challenge cost metric, but this is not the actual murmur scoring metric.\n",
    "    murmur_scores = (murmur_classes, murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes, \\\n",
    "                 murmur_f_measure, murmur_f_measure_classes, murmur_accuracy, murmur_accuracy_classes, murmur_weighted_accuracy, murmur_cost)\n",
    "\n",
    "    # Evaluate the outcome model by comparing the labels and model outputs.\n",
    "    outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes = compute_auc(outcome_labels, outcome_scalar_outputs)\n",
    "    outcome_f_measure, outcome_f_measure_classes = compute_f_measure(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_accuracy, outcome_accuracy_classes = compute_accuracy(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_weighted_accuracy = compute_weighted_accuracy(outcome_labels, outcome_binary_outputs, outcome_classes)\n",
    "    outcome_cost = compute_cost(outcome_labels, outcome_binary_outputs, outcome_classes, outcome_classes) # This is the clinical outcomes scoring metric.\n",
    "    outcome_scores = (outcome_classes, outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes, \\\n",
    "                  outcome_f_measure, outcome_f_measure_classes, outcome_accuracy, outcome_accuracy_classes, outcome_weighted_accuracy, outcome_cost)\n",
    "\n",
    "\n",
    "\n",
    "    classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "    murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "    murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "    classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "    outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "    outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "    output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "                + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "    print(\"threshold: \", th1)\n",
    "    print(output_string)\n",
    "    print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a223bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2.4_p37)",
   "language": "python",
   "name": "conda_tensorflow2.4_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
