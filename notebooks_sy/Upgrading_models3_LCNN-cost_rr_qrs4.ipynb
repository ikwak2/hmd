{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6eda80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/912229180.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a6057f",
   "metadata": {},
   "source": [
    "## LCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74ed092a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Data2/hmd/hmd_sy/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a45589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math\n",
    "import sys\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/notebooks')\n",
    "#sys.path.insert(0,'/home/ikwak2/hmd/iy_classifier')\n",
    "sys.path.insert(0,'/Data2/hmd/hmd_sy/evaluation-2022')\n",
    "sys.path.insert(0,'utils')\n",
    "from helper_code import *\n",
    "from get_feature import *\n",
    "from models import *\n",
    "from Generator0 import *\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from evaluate_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3bbd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'physionet.org/files/circor-heart-sound/1.0.3'\n",
    "training_data_file = root_dir + '/' + 'training_data.csv'\n",
    "training_data_dir = root_dir + '/' + 'training_data'\n",
    "model_dir = root_dir + '/' + 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a9d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 31 13:51:59 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.39       Driver Version: 460.39       CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 8000     On   | 00000000:1A:00.0 Off |                  Off |\n",
      "| 33%   28C    P8    24W / 260W |    478MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro RTX 8000     On   | 00000000:3D:00.0 Off |                  Off |\n",
      "| 33%   28C    P8     6W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro RTX 8000     On   | 00000000:3E:00.0 Off |                  Off |\n",
      "| 46%   69C    P2   251W / 260W |  41282MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro RTX 8000     On   | 00000000:40:00.0 Off |                  Off |\n",
      "| 47%   70C    P2   251W / 260W |  42074MiB / 48601MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Quadro RTX 8000     On   | 00000000:41:00.0 Off |                  Off |\n",
      "| 33%   31C    P8    13W / 260W |      3MiB / 48601MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb1c20ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[4], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b6c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder =  '/Data2/hmd/physionet.org/files/circor-heart-sound/1.0.3/training_data'\n",
    "train_folder =  '/Data2/hmd/data_split/murmur/train'\n",
    "test_folder = '/Data2/hmd/data_split/murmur/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0afaa",
   "metadata": {},
   "source": [
    "## QRS_Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e0c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## detect QRS complex from ECG time series\n",
    "\n",
    "import numpy as np \n",
    "import math\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_ecg(file_name):\n",
    "\treturn genfromtxt(file_name, delimiter=',')\n",
    "\n",
    "def lgth_transform(ecg, ws):\n",
    "\tlgth=ecg.shape[0]\n",
    "\tsqr_diff=np.zeros(lgth)\n",
    "\tdiff=np.zeros(lgth)\n",
    "\tecg=np.pad(ecg, ws, 'edge')\n",
    "\tfor i in range(lgth):\n",
    "\t\ttemp=ecg[i:i+ws+ws+1]\n",
    "\t\tleft=temp[ws]-temp[0]\n",
    "\t\tright=temp[ws]-temp[-1]\n",
    "\t\tdiff[i]=min(left, right)\n",
    "\t\tdiff[diff<0]=0\n",
    "\t# sqr_diff=np.multiply(diff, diff)\n",
    "\t# diff=ecg[:-1]-ecg[1:]\n",
    "\t# sqr_diff[:-1]=np.multiply(diff, diff)\n",
    "\t# sqr_diff[-1]=sqr_diff[-2]\n",
    "\treturn np.multiply(diff, diff)\n",
    "\n",
    "def integrate(ecg, ws):\n",
    "\tlgth=ecg.shape[0]\n",
    "\tintegrate_ecg=np.zeros(lgth)\n",
    "\tecg=np.pad(ecg, math.ceil(ws/2), mode='symmetric')\n",
    "\tfor i in range(lgth):\n",
    "\t\tintegrate_ecg[i]=np.sum(ecg[i:i+ws])/ws\n",
    "\treturn integrate_ecg\n",
    "\n",
    "def find_peak(data, ws):\n",
    "\tlgth=data.shape[0]\n",
    "\ttrue_peaks=list()\n",
    "\tfor i in range(lgth-ws+1):\n",
    "\t\ttemp=data[i:i+ws]\n",
    "\t\tif np.var(temp)<5:\n",
    "\t\t\tcontinue\n",
    "\t\tindex=int((ws-1)/2)\n",
    "\t\tpeak=True\n",
    "\t\tfor j in range(index):\n",
    "\t\t\tif temp[index-j]<=temp[index-j-1] or temp[index+j]<=temp[index+j+1]:\n",
    "\t\t\t\tpeak=False\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\tif peak is True:\n",
    "\t\t\ttrue_peaks.append(int(i+(ws-1)/2))\n",
    "\treturn np.asarray(true_peaks)\n",
    "\n",
    "def find_R_peaks(ecg, peaks, ws):\n",
    "\tnum_peak=peaks.shape[0]\n",
    "\tR_peaks=list()\n",
    "\tfor index in range(num_peak):\n",
    "\t\ti=peaks[index]\n",
    "\t\tif i-2*ws>0 and i<ecg.shape[0]:\n",
    "\t\t\ttemp_ecg=ecg[i-2*ws:i]\n",
    "\t\t\tR_peaks.append(int(np.argmax(temp_ecg)+i-2*ws))\n",
    "\treturn np.asarray(R_peaks)\n",
    "\n",
    "def find_S_point(ecg, R_peaks):\n",
    "\tnum_peak=R_peaks.shape[0]\n",
    "\tS_point=list()\n",
    "\tfor index in range(num_peak):\n",
    "\t\ti=R_peaks[index]\n",
    "\t\tcnt=i\n",
    "\t\tif cnt+1>=ecg.shape[0]:\n",
    "\t\t\tbreak\n",
    "\t\twhile ecg[cnt]>ecg[cnt+1]:\n",
    "\t\t\tcnt+=1\n",
    "\t\t\tif cnt>=ecg.shape[0]:\n",
    "\t\t\t\tbreak\n",
    "\t\tS_point.append(cnt)\n",
    "\treturn np.asarray(S_point)\n",
    "\n",
    "\n",
    "def find_Q_point(ecg, R_peaks):\n",
    "\tnum_peak=R_peaks.shape[0]\n",
    "\tQ_point=list()\n",
    "\tfor index in range(num_peak):\n",
    "\t\ti=R_peaks[index]\n",
    "\t\tcnt=i\n",
    "\t\tif cnt-1<0:\n",
    "\t\t\tbreak\n",
    "\t\twhile ecg[cnt]>ecg[cnt-1]:\n",
    "\t\t\tcnt-=1\n",
    "\t\t\tif cnt<0:\n",
    "\t\t\t\tbreak\n",
    "\t\tQ_point.append(cnt)\n",
    "\treturn np.asarray(Q_point)\n",
    "\n",
    "# QRS 계산하는 함수\n",
    "def EKG_QRS_detect1(ecg, fs, QS, plot=False):\n",
    "\tsig_lgth=ecg.shape[0]\n",
    "\tecg=ecg-np.mean(ecg)\n",
    "\tecg_lgth_transform=lgth_transform(ecg, int(fs/222))\n",
    "\t# ecg_lgth_transform=lgth_transform(ecg_lgth_transform, int(fs/40))\n",
    "\n",
    "\tws=int(fs/89)\n",
    "\tecg_integrate=integrate(ecg_lgth_transform, ws)/ws\n",
    "\tws=int(fs/67)\n",
    "\tecg_integrate=integrate(ecg_integrate, ws)\n",
    "\tws=int(fs/400)\n",
    "\tecg_integrate=integrate(ecg_integrate, ws)\n",
    "\tws=int(fs/800)\n",
    "\tecg_integrate=integrate(ecg_integrate, ws)\n",
    "\n",
    "\tpeaks=find_peak(ecg_integrate, int(fs/111))\n",
    "\tR_peaks=find_R_peaks(ecg, peaks, int(fs/444))\n",
    "\tif QS:\n",
    "\t\tS_point=find_S_point(ecg, R_peaks)\n",
    "\t\tQ_point=find_Q_point(ecg, R_peaks)\n",
    "\telse:\n",
    "\t\tS_point=None\n",
    "\t\tQ_point=None\n",
    "\tif plot:\n",
    "\t\tindex=np.arange(sig_lgth)/fs\n",
    "\t\tfig, ax=plt.subplots()\n",
    "\t\tax.plot(index, ecg, 'b', label='EKG')\n",
    "\t\tax.plot(R_peaks/fs, ecg[R_peaks], 'ro', label='R peaks')\n",
    "\t\tif QS:\n",
    "\t\t\tax.plot(S_point/fs, ecg[S_point], 'go', label='S')\n",
    "\t\t\tax.plot(Q_point/fs, ecg[Q_point], 'yo', label='Q')\n",
    "\t\tax.set_xlim([0, sig_lgth/fs])\n",
    "\t\tax.set_xlabel('Time [sec]')\n",
    "\t\tax.legend()\n",
    "\t\t# ax[1].plot(ecg_integrate)\n",
    "\t\t# ax[1].set_xlim([0, ecg_integrate.shape[0]])\n",
    "\t\t# ax[2].plot(ecg_lgth_transform)\n",
    "\t\t# ax[2].set_xlim([0, ecg_lgth_transform.shape[0]])\n",
    "\t\tplt.figure(figsize=(20,45))\n",
    "\t\tplt.show()\n",
    "\treturn R_peaks, S_point, Q_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193f7665",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee244ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7cdbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3438eb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "    if e < start:\n",
    "        return lr_start\n",
    "    elif e > end:\n",
    "        return lr_end\n",
    "\n",
    "    middle = (start + end) / 2\n",
    "    s = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "    return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ac699",
   "metadata": {},
   "source": [
    "### get feature 함수확장: 음성피쳐 옵션들과, 추가 음성들 고려한 피쳐추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c63a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files_trn = find_patient_files(train_folder)\n",
    "patient_files_test = find_patient_files(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c65f40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Data2/hmd/hmd_sy/notebooks'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bfc11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = 'lcnn__rr_qrs4'\n",
    "output_folder = '/Data2/hmd/hmd_sy/notebooks/out_lcnn__rr_qrs4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "442df588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_3lb_all_ord_seqrr_seqqrs(data_folder, patient_files_trn, po = .3,\n",
    "                          samp_sec=20, pre_emphasis = 0, hop_length=256, win_length = 512, n_mels = 100,\n",
    "                             filter_scale = 1, n_bins = 80, fmin = 10, trim = 4000,\n",
    "                             use_mel = True, use_cqt = False, use_stft = False, use_raw = False,\n",
    "                             use_rr = False, use_qrs=False\n",
    "                         ) :\n",
    "    features = dict()\n",
    "    features['id'] = []\n",
    "    features['age'] = []\n",
    "    features['sex'] = []\n",
    "    features['hw'] = []\n",
    "    features['preg'] = []\n",
    "    features['loc'] = []\n",
    "    features['mel1'] = []\n",
    "    features['cqt1'] = []\n",
    "    features['stft1'] = []\n",
    "    features['raw1'] = []\n",
    "    features['rr1'] = []\n",
    "    features['qrs1'] = []\n",
    "    \n",
    "    mm_labels = []\n",
    "    out_labels = []\n",
    "\n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "\n",
    "    num_patient_files = len(patient_files_trn)\n",
    "\n",
    "    for i in tqdm.tqdm(range(num_patient_files)) :\n",
    "\n",
    "        # Load the current patient data and recordings.\n",
    "        current_patient_data = load_patient_data(patient_files_trn[i])\n",
    "        num_locations = get_num_locations(current_patient_data)\n",
    "        recording_information = current_patient_data.split('\\n')[1:num_locations+1]\n",
    "        for j in range(num_locations) :\n",
    "            entries = recording_information[j].split(' ')\n",
    "            recording_file = entries[2]\n",
    "            filename = os.path.join(data_folder, recording_file)\n",
    "\n",
    "            # Extract id\n",
    "            id1 = recording_file.split('_')[0]\n",
    "            features['id'].append(id1)\n",
    "\n",
    "            # Extract melspec\n",
    "            if use_mel :\n",
    "                mel1 = feature_extract_melspec(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                               win_length = win_length, n_mels = n_mels, trim = trim)[0]\n",
    "            else :\n",
    "                mel1 = np.zeros( (1,1,1) )\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "            if use_cqt :\n",
    "                mel2 = feature_extract_cqt(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, filter_scale = filter_scale, \n",
    "                                           n_bins = n_bins, fmin = fmin, trim = trim)[0]\n",
    "            else :\n",
    "                mel2 = np.zeros( (1,1,1) )\n",
    "            features['cqt1'].append(mel2)\n",
    "\n",
    "            if use_stft :\n",
    "                mel3 = feature_extract_stft(filename, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length, \n",
    "                                            win_length = win_length, trim = trim)[0]\n",
    "            else :\n",
    "                mel3 = np.zeros( (1,1,1) )\n",
    "            features['stft1'].append(mel3)\n",
    "\n",
    "            if use_raw :\n",
    "                frequency1, recording1 = sp.io.wavfile.read(filename)\n",
    "            else :\n",
    "                recording1 = np.zeros((1))\n",
    "            features['raw1'].append(recording1)\n",
    "            \n",
    "            \n",
    "            if use_rr :\n",
    "                try:\n",
    "                    ____, recording1 = sp.io.wavfile.read(filename)\n",
    "                    ____, info = nk.ecg_process(recording1, sampling_rate=4000)\n",
    "                    rr = (np.diff(info['ECG_R_Peaks'])/4000)\n",
    "                    current_rr = rr\n",
    "                except:\n",
    "                    print(filename)\n",
    "                    current_rr=np.zeros((1))\n",
    "            else :\n",
    "                current_rr = np.zeros((1))\n",
    "            features['rr1'].append(current_rr)        \n",
    "            \n",
    "            \n",
    "            if use_qrs :\n",
    "                ____, recording1 = sp.io.wavfile.read(filename)\n",
    "                R_peaks, S_point, Q_point=EKG_QRS_detect1(recording1, 4000, True, False)\n",
    "                qrs = (S_point-Q_point)/4000\n",
    "            else :\n",
    "                qrs = np.zeros((1))\n",
    "            features['qrs1'].append(qrs)   \n",
    "            \n",
    "            \n",
    "            # Extract age_group\n",
    "            age_group = get_age(current_patient_data)\n",
    "            current_age_group = np.zeros(6, dtype=int)\n",
    "            if age_group in age_classes:\n",
    "                j = age_classes.index(age_group)\n",
    "                current_age_group[j] = 1\n",
    "            else :\n",
    "                current_age_group[5] = 1\n",
    "            features['age'].append(current_age_group)\n",
    "\n",
    "            # Extract sex\n",
    "            sex = get_sex(current_patient_data)\n",
    "            sex_features = np.zeros(2, dtype=int)\n",
    "            if compare_strings(sex, 'Female'):\n",
    "                sex_features[0] = 1\n",
    "            elif compare_strings(sex, 'Male'):\n",
    "                sex_features[1] = 1\n",
    "            features['sex'].append(sex_features)\n",
    "\n",
    "            # Extract height and weight.\n",
    "            height = get_height(current_patient_data)\n",
    "            weight = get_weight(current_patient_data)\n",
    "            ## simple impute\n",
    "            if math.isnan(height) :\n",
    "                height = 110.846\n",
    "            if math.isnan(weight) :\n",
    "                weight = 23.767\n",
    "                \n",
    "            features['hw'].append(np.array([height, weight]))\n",
    "\n",
    "            # Extract pregnancy\n",
    "            is_pregnant = get_pregnancy_status(current_patient_data)\n",
    "            features['preg'].append(is_pregnant)\n",
    "\n",
    "            # Extract location\n",
    "            locations = entries[0]\n",
    "            num_recording_locations = len(recording_locations)\n",
    "            loc_features = np.zeros(num_recording_locations)\n",
    "            if locations in recording_locations:\n",
    "                j = recording_locations.index(locations)\n",
    "                loc_features[j] = 1\n",
    "            features['loc'].append(loc_features)\n",
    "\n",
    "            # Extract labels \n",
    "            mm_label = get_murmur(current_patient_data)\n",
    "            out_label = get_outcome(current_patient_data)\n",
    "            if mm_label == 'Absent' :\n",
    "                current_mm_labels = np.array([0, 1])\n",
    "            elif mm_label == 'Unknown' :\n",
    "                current_mm_labels = np.array([po, 1-po])\n",
    "            else :\n",
    "                mm_loc = get_murmur_loc(current_patient_data)\n",
    "                if mm_loc == 'nan' :\n",
    "                    current_mm_labels = np.array([0.9, 0.1])\n",
    "                else :\n",
    "                    mm_loc = mm_loc.split('+')\n",
    "                    if locations in mm_loc :\n",
    "                        current_mm_labels = np.array([1, 0])\n",
    "                    else :\n",
    "                        current_mm_labels = np.array([0.8, 0.2])\n",
    "\n",
    "            if out_label == 'Normal' :\n",
    "                current_out_labels = np.array([0, 1])\n",
    "            else :\n",
    "                current_out_labels = np.array([1, 0])\n",
    "#                if mm_label == 'Absent' :\n",
    "#                    current_out_labels = np.array([0.8, 0.2])\n",
    "#                elif mm_label == 'unknown' :\n",
    "#                    current_out_labels = np.array([0.85, 0.15])\n",
    "#                else :\n",
    "#                    current_out_labels = np.array([1, 0])\n",
    "                \n",
    "            mm_labels.append(current_mm_labels)\n",
    "            out_labels.append(current_out_labels)\n",
    "\n",
    "    if use_mel : \n",
    "        M, N = features['mel1'][i].shape\n",
    "        for i in range(len(features['mel1'])) :\n",
    "            features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "        print(\"melspec: \", M,N)\n",
    "    else :\n",
    "        M, N, _ = features['mel1'][i].shape\n",
    "    mel_input_shape = (M,N,1)\n",
    "        \n",
    "    if use_cqt :\n",
    "        M, N = features['cqt1'][i].shape\n",
    "        for i in range(len(features['cqt1'])) :\n",
    "            features['cqt1'][i] = features['cqt1'][i].reshape(M,N,1)\n",
    "        print(\"cqt: \", M,N)\n",
    "    else :\n",
    "        M, N, _ = features['cqt1'][i].shape\n",
    "    cqt_input_shape = (M,N,1)\n",
    "\n",
    "    \n",
    "    if use_stft :\n",
    "        M, N = features['stft1'][i].shape\n",
    "        for i in range(len(features['stft1'])) :\n",
    "            features['stft1'][i] = features['stft1'][i].reshape(M,N,1)\n",
    "        print(\"stft: \", M,N)\n",
    "    else :\n",
    "        M, N, _ = features['stft1'][i].shape\n",
    "    stft_input_shape = (M,N,1)\n",
    "        \n",
    "    for k1 in features.keys() :\n",
    "        features[k1] = np.array(features[k1])\n",
    "    \n",
    "    mm_labels = np.array(mm_labels)\n",
    "    out_labels = np.array(out_labels)\n",
    "    return features, mm_labels, out_labels, mel_input_shape, cqt_input_shape, stft_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98be9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim = 0\n",
    "use_mel = True\n",
    "use_cqt = True #np.random.choice([True,False])\n",
    "use_stft = True #np.random.choice([True,False])\n",
    "use_rr = True\n",
    "use_qrs = True\n",
    "\n",
    "params_feature = {'samp_sec': 20,\n",
    "                  #### melspec, stft 피쳐 옵션들\n",
    "                  'pre_emphasis': 0,\n",
    "                  'hop_length': 128,\n",
    "                  'win_length':256,\n",
    "                  'n_mels': 100,\n",
    "                  #### cqt 피쳐 옵션들\n",
    "                  'filter_scale': 1,\n",
    "                  'n_bins': 80,\n",
    "                  'fmin': 10,\n",
    "                  ### 사용할 피쳐 지정\n",
    "                      'trim' : trim, # 앞뒤 얼마나 자를지? 4000 이면 1초\n",
    "                      'use_mel' : use_mel,\n",
    "                      'use_cqt' : use_cqt,\n",
    "                      'use_stft' : use_stft,\n",
    "                      'use_rr': use_rr,\n",
    "                      'use_qrs': use_qrs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d334c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                        | 3/751 [01:33<6:35:23, 31.72s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  1%|▍                                        | 7/751 [03:42<6:56:17, 33.57s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  2%|▋                                       | 12/751 [05:31<4:54:45, 23.93s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  4%|█▍                                      | 27/751 [12:12<7:07:32, 35.43s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  5%|██▏                                     | 40/751 [21:27<8:18:20, 42.05s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  5%|██▏                                     | 41/751 [22:23<9:05:40, 46.11s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  6%|██▏                                     | 42/751 [22:51<8:00:56, 40.70s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  6%|██▌                                     | 48/751 [27:15<9:25:15, 48.24s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  7%|██▉                                     | 56/751 [33:40<7:47:33, 40.36s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  8%|███▎                                    | 63/751 [38:07<7:03:55, 36.97s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  9%|███▌                                    | 66/751 [40:20<8:01:10, 42.15s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  9%|███▌                                    | 67/751 [41:17<8:51:54, 46.66s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "  9%|███▌                                    | 68/751 [41:39<7:28:27, 39.40s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 11%|████▌                                   | 85/751 [48:54<3:38:33, 19.69s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 12%|████▋                                   | 87/751 [49:44<4:04:05, 22.06s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 12%|████▋                                   | 89/751 [51:40<7:20:51, 39.96s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 12%|████▊                                   | 90/751 [52:39<8:23:03, 45.66s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 13%|█████▏                                  | 98/751 [56:51<6:17:23, 34.68s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 14%|█████                                | 104/751 [1:00:43<6:25:37, 35.76s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█████▎                               | 109/751 [1:03:51<7:35:23, 42.56s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 15%|█████▌                               | 114/751 [1:07:41<8:03:35, 45.55s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 15%|█████▋                               | 115/751 [1:08:12<7:16:14, 41.16s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 15%|█████▋                               | 116/751 [1:09:08<8:01:43, 45.52s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 16%|█████▊                               | 117/751 [1:09:53<8:01:31, 45.57s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 17%|██████▍                              | 131/751 [1:19:33<7:48:50, 45.37s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 18%|██████▌                              | 134/751 [1:22:33<9:44:16, 56.82s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 19%|██████▉                              | 140/751 [1:26:05<6:14:08, 36.74s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 20%|███████▎                             | 148/751 [1:30:27<5:13:25, 31.19s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 20%|███████▍                             | 152/751 [1:32:19<4:39:47, 28.03s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 21%|███████▌                             | 154/751 [1:33:26<5:19:19, 32.09s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 21%|███████▋                             | 155/751 [1:34:16<6:13:08, 37.56s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 22%|████████▏                            | 166/751 [1:39:31<4:27:43, 27.46s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 22%|████████▏                            | 167/751 [1:40:24<5:41:35, 35.10s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 23%|████████▍                            | 171/751 [1:42:51<5:36:20, 34.79s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 24%|████████▊                            | 179/751 [1:48:49<6:53:33, 43.38s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 24%|████████▉                            | 181/751 [1:49:56<5:47:30, 36.58s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 24%|█████████                            | 183/751 [1:51:37<6:46:36, 42.95s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 25%|█████████▏                           | 186/751 [1:53:01<5:22:31, 34.25s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█████████▍                           | 191/751 [1:56:42<6:14:24, 40.12s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 26%|█████████▍                           | 192/751 [1:57:07<5:31:01, 35.53s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 26%|█████████▌                           | 193/751 [1:57:53<5:58:48, 38.58s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 26%|█████████▌                           | 194/751 [1:58:45<6:36:54, 42.76s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 26%|█████████▋                           | 197/751 [2:00:58<6:30:49, 42.33s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 27%|█████████▊                           | 200/751 [2:03:13<6:39:49, 43.54s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 27%|██████████                           | 203/751 [2:04:47<5:15:21, 34.53s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 28%|██████████▍                          | 211/751 [2:10:02<4:58:27, 33.16s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 28%|██████████▍                          | 213/751 [2:11:32<5:55:39, 39.66s/it]/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "features_trn, mm_lbs_trn, out_lbs_trn, mel_input_shape, cqt_input_shape, stft_input_shape = get_features_3lb_all_ord_seqrr_seqqrs(train_folder, patient_files_trn, **params_feature)\n",
    "features_test, mm_lbs_test, out_lbs_test, _, _, _ = get_features_3lb_all_ord_seqrr_seqqrs(test_folder, patient_files_test, **params_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bc07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features_trn_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(features_trn,f)\n",
    "    \n",
    "with open('mm_lbs_trn_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(mm_lbs_trn,f)\n",
    "    \n",
    "with open('out_lbs_trn_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(out_lbs_trn,f)\n",
    "    \n",
    "with open('mel_input_shape_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(mel_input_shape,f)\n",
    "\n",
    "with open('cqt_input_shape_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(cqt_input_shape,f)\n",
    "    \n",
    "with open('stft_input_shape_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(stft_input_shape,f)\n",
    "    \n",
    "with open('features_test_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(features_test,f)\n",
    "    \n",
    "with open('mm_lbs_test_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(mm_lbs_test,f)\n",
    "\n",
    "with open('out_lbs_test_rr_qrs3.pkl','wb') as f:\n",
    "    pickle.dump(out_lbs_test,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a148e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/Data2/hmd/hmd_sy/notebooks/features_trn_rr_qrs3.pkl','rb') as f:\n",
    "    features_trn = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/mm_lbs_trn_rr_qrs3.pkl','rb') as f:\n",
    "    mm_lbs_trn = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/out_lbs_trn_rr_qrs3.pkl','rb') as f:\n",
    "    out_lbs_trn = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/mel_input_shape_rr_qrs3.pkl','rb') as f:\n",
    "    mel_input_shape = pickle.load(f)\n",
    "\n",
    "with open('/Data2/hmd/hmd_sy/notebooks/cqt_input_shape_rr_qrs3.pkl','rb') as f:\n",
    "    cqt_input_shape = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/stft_input_shape_rr_qrs3.pkl','rb') as f:\n",
    "    stft_input_shape = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/features_test_rr_qrs3.pkl','rb') as f:\n",
    "    features_test = pickle.load(f)\n",
    "    \n",
    "with open('/Data2/hmd/hmd_sy/notebooks/mm_lbs_test_rr_qrs3.pkl','rb') as f:\n",
    "    mm_lbs_test = pickle.load(f)\n",
    "\n",
    "with open('/Data2/hmd/hmd_sy/notebooks/out_lbs_test_rr_qrs3.pkl','rb') as f:\n",
    "    out_lbs_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa5d2d",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b799b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LCNN_o_5_dr_qrs2_2_1(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = True, \n",
    "                        use_stft = True, ord1 = True, dp = .5, fc = False, ext = False):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    rr = keras.Input(shape=(1,), name = 'rr')\n",
    "    qrs = keras.Input(shape=(1,), name = 'qrs') \n",
    "    mel1 = keras.Input(shape=mel_input_shape, name = 'mel')\n",
    "    cqt1 = keras.Input(shape=cqt_input_shape, name = 'cqt')\n",
    "    stft1 = keras.Input(shape=stft_input_shape, name = 'stft')\n",
    "    \n",
    "    \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = None)(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = None)(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = None)(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = None)(loc)\n",
    "    \n",
    "    ## rr interval embedding\n",
    "    \n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "\n",
    "    ## qrs interval embedding    \n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "\n",
    "    ## mel embedding\n",
    "    if use_mel :\n",
    "        \n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(mel1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(mel1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "\n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "\n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "\n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "\n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "\n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "\n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(mfm27)\n",
    "        mel2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        mel2 = Dropout(dp)(mel2)\n",
    "\n",
    "    if use_cqt :\n",
    "        \n",
    "        ## cqt embedding\n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(cqt1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(cqt1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "\n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "\n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "        \n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "        \n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "\n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "\n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm27)\n",
    "        cqt2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        if dp :\n",
    "            cqt2 = Dropout(dp)(cqt2)\n",
    "            \n",
    "    if use_stft :\n",
    "        ## stft embedding\n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(stft1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(stft1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "        \n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "        \n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "        \n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "        \n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "        \n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "        \n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(mfm27)\n",
    "        stft2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        stft2 = Dropout(dp)(stft2)\n",
    "    \n",
    "    \n",
    "    if use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2, stft2])\n",
    "    if not use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([cqt2, stft2])\n",
    "    if use_mel and not use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, stft2])\n",
    "    if use_mel and use_cqt and not use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2])\n",
    "    if not use_mel and not use_cqt and use_stft :  ## stft 만\n",
    "        concat2 = stft2\n",
    "    if use_mel and not use_cqt and not use_stft :  ### mel만\n",
    "        concat2 = mel2\n",
    "    if not use_mel and use_cqt and not use_stft :  ### cqt만\n",
    "        concat2 = cqt2\n",
    "\n",
    "    if ext :\n",
    "        concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, preg,rr1,qrs1])\n",
    "        d1 = layers.Dense(5, activation = 'relu')(concat1)\n",
    "        concat2 = layers.Concatenate()([concat2, d1]) # rr1,qrs1 따로 concat\n",
    "        \n",
    "    if fc :\n",
    "        concat2 = layers.Dense(10, activation = \"relu\")(concat2)\n",
    "        concat2 = Dropout(dp)(concat2)\n",
    "        \n",
    "    if ord1 :\n",
    "        res1 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "    else :\n",
    "        res1 = layers.Dense(3, activation = \"softmax\")(concat2)\n",
    "\n",
    "        \n",
    "#     res2 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,rr,qrs, mel1,cqt1, stft1] , outputs = res1 )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy','AUC'])\n",
    "    return(model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_LCNN_o_5_dr_qrs2_2_2(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = True, use_cqt = True, \n",
    "                        use_stft = True, ord1 = True, dp = .5, fc = False, ext = False):\n",
    "        # Create a towy model.\n",
    "    age = keras.Input(shape=(6,), name = 'age_cat')\n",
    "    sex = keras.Input(shape=(2,), name = 'sex_cat')\n",
    "    hw = keras.Input(shape=(2,), name = 'height_weight')\n",
    "    preg = keras.Input(shape=(1,), name = 'is_preg')\n",
    "    loc = keras.Input(shape=(5,), name = 'loc')\n",
    "    rr = keras.Input(shape=(1,), name = 'rr')\n",
    "    qrs = keras.Input(shape=(1,), name = 'qrs') \n",
    "    mel1 = keras.Input(shape=mel_input_shape, name = 'mel')\n",
    "    cqt1 = keras.Input(shape=cqt_input_shape, name = 'cqt')\n",
    "    stft1 = keras.Input(shape=stft_input_shape, name = 'stft')\n",
    "    \n",
    "    \n",
    "    ## age embeddig\n",
    "    age1 = layers.Dense(2, activation = None)(age)\n",
    "\n",
    "    ## sex embedding\n",
    "    sex1 = layers.Dense(1, activation = None)(sex)\n",
    "\n",
    "    ## hw embedding\n",
    "    hw1 = layers.Dense(1, activation = None)(hw)\n",
    "\n",
    "    ## loc embedding\n",
    "    loc1 = layers.Dense(3, activation = None)(loc)\n",
    "    \n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "    rr1 = layers.Dense(20, activation = \"relu\")(rr1)\n",
    "    rr1 = BatchNormalization()(rr1)\n",
    "\n",
    "    ## qrs interval embedding    \n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "    qrs1 = layers.Dense(20, activation = \"relu\")(qrs1)\n",
    "    qrs1 = BatchNormalization()(qrs1)\n",
    "\n",
    "    ## mel embedding\n",
    "    if use_mel :\n",
    "        \n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(mel1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(mel1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "\n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "\n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "\n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "\n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "\n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "\n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(mfm27)\n",
    "        mel2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        mel2 = Dropout(dp)(mel2)\n",
    "\n",
    "    if use_cqt :\n",
    "        \n",
    "        ## cqt embedding\n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(cqt1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(cqt1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "\n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "\n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "        \n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "        \n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "\n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "\n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm27)\n",
    "        cqt2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        if dp :\n",
    "            cqt2 = Dropout(dp)(cqt2)\n",
    "            \n",
    "    if use_stft :\n",
    "        ## stft embedding\n",
    "        conv1_1 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(stft1)\n",
    "        conv1_2 = Conv2D(filters = 32, kernel_size =5, strides=(1, 1), padding='same', activation=None)(stft1)\n",
    "        mfm2 = tensorflow.keras.layers.maximum([conv1_1, conv1_2])\n",
    "        max3 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm2)\n",
    "        \n",
    "        conv4_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        conv4_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max3)\n",
    "        mfm5 = tensorflow.keras.layers.maximum([conv4_1, conv4_2])\n",
    "        batch6 = BatchNormalization(axis=3, scale=False)(mfm5)\n",
    "        \n",
    "        conv7_1 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        conv7_2 = Conv2D(filters = 48, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch6)\n",
    "        mfm8 = tensorflow.keras.layers.maximum([conv7_1, conv7_2])\n",
    "        \n",
    "        max9 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm8)\n",
    "        batch10 = BatchNormalization(axis=3, scale=False)(max9)\n",
    "        \n",
    "        conv11_1 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        conv11_2 = Conv2D(filters = 48, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch10)\n",
    "        mfm12 = tensorflow.keras.layers.maximum([conv11_1, conv11_2])\n",
    "        batch13 = BatchNormalization(axis=3, scale=False)(mfm12)\n",
    "\n",
    "        conv14_1 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        conv14_2 = Conv2D(filters = 64, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch13)\n",
    "        mfm15 = tensorflow.keras.layers.maximum([conv14_1, conv14_2])\n",
    "        \n",
    "        max16 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='same')(mfm15)\n",
    "\n",
    "        conv17_1 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        conv17_2 = Conv2D(filters = 64, kernel_size =1, strides=(1, 1), padding='same', activation=None)(max16)\n",
    "        mfm18 = tensorflow.keras.layers.maximum([conv17_1, conv17_2])\n",
    "        batch19 = BatchNormalization(axis=3, scale=False)(mfm18)\n",
    "\n",
    "        conv20_1 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        conv20_2 = Conv2D(filters = 32, kernel_size =3, strides=(1, 1), padding='same', activation=None)(batch19)\n",
    "        mfm21 = tensorflow.keras.layers.maximum([conv20_1, conv20_2])\n",
    "        batch22 = BatchNormalization(axis=3, scale=False)(mfm21)\n",
    "\n",
    "        conv23_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        conv23_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch22)\n",
    "        mfm24 = tensorflow.keras.layers.maximum([conv23_1, conv23_2])\n",
    "        batch25 = BatchNormalization(axis=3, scale=False)(mfm24)\n",
    "\n",
    "        conv26_1 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        conv26_2 = Conv2D(filters = 32, kernel_size =1, strides=(1, 1), padding='same', activation=None)(batch25)\n",
    "        mfm27 = tensorflow.keras.layers.maximum([conv26_1, conv26_2])\n",
    "        \n",
    "        max28 = MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(mfm27)\n",
    "        stft2 = layers.GlobalAveragePooling2D()(max28)\n",
    "        stft2 = Dropout(dp)(stft2)\n",
    "    \n",
    "    \n",
    "    if use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2, stft2])\n",
    "    if not use_mel and use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([cqt2, stft2])\n",
    "    if use_mel and not use_cqt and use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, stft2])\n",
    "    if use_mel and use_cqt and not use_stft :\n",
    "        concat2 = layers.Concatenate()([mel2, cqt2])\n",
    "    if not use_mel and not use_cqt and use_stft :  ## stft 만\n",
    "        concat2 = stft2\n",
    "    if use_mel and not use_cqt and not use_stft :  ### mel만\n",
    "        concat2 = mel2\n",
    "    if not use_mel and use_cqt and not use_stft :  ### cqt만\n",
    "        concat2 = cqt2\n",
    "\n",
    "    if ext :\n",
    "        concat1 = layers.Concatenate()([age1, sex1, hw1, loc1, preg])\n",
    "        d1 = layers.Dense(5, activation = 'relu')(concat1)\n",
    "        concat2 = layers.Concatenate()([concat2, d1,rr1,qrs1]) # rr1,qrs1 따로 concat\n",
    "        \n",
    "    if fc :\n",
    "        concat2 = layers.Dense(10, activation = \"relu\")(concat2)\n",
    "        concat2 = Dropout(dp)(concat2)\n",
    "        \n",
    "    if ord1 :\n",
    "        res2 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "    else :\n",
    "        res2 = layers.Dense(3, activation = \"softmax\")(concat2)\n",
    "\n",
    "        \n",
    "#     res2 = layers.Dense(2, activation = \"softmax\")(concat2)\n",
    "\n",
    "    model = keras.Model(inputs = [age,sex,hw,preg,loc,rr,qrs, mel1,cqt1, stft1] , outputs = res2 )\n",
    "    \n",
    "    model.compile(loss=['categorical_crossentropy'], optimizer='adam', metrics=['accuracy','AUC'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01d6039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 13:56:50.035037: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-31 13:56:50.716296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 47232 MB memory:  -> device: 4, name: Quadro RTX 8000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "use_mel = True\n",
    "use_cqt = True\n",
    "use_stft = True\n",
    "\n",
    "model1 = get_LCNN_o_5_dr_qrs2_2_1(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = use_mel, use_cqt = use_cqt, use_stft = use_stft)\n",
    "model2 = get_LCNN_o_5_dr_qrs2_2_2(mel_input_shape, cqt_input_shape, stft_input_shape, use_mel = use_mel, use_cqt = use_cqt, use_stft = use_stft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d637cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_feature['ord1'] = True \n",
    "params_feature['mm_mean'] = False\n",
    "params_feature['trim'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2e2a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 13:57:02.004336: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 13:57:06.239723: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 24s 379ms/step - loss: 1.2606 - accuracy: 0.6133 - auc: 0.6572 - val_loss: 6.2370 - val_accuracy: 0.2108 - val_auc: 0.1968\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 12s 308ms/step - loss: 0.9818 - accuracy: 0.6863 - auc: 0.7510 - val_loss: 0.8025 - val_accuracy: 0.2868 - val_auc: 0.2694\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 12s 310ms/step - loss: 0.8705 - accuracy: 0.7645 - auc: 0.8195 - val_loss: 0.6538 - val_accuracy: 0.6418 - val_auc: 0.6807\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.8705 - accuracy: 0.7785 - auc: 0.8266 - val_loss: 0.8710 - val_accuracy: 0.2235 - val_auc: 0.2778\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 12s 311ms/step - loss: 0.8474 - accuracy: 0.7961 - auc: 0.8334 - val_loss: 0.7070 - val_accuracy: 0.4754 - val_auc: 0.5322\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 13s 314ms/step - loss: 0.8018 - accuracy: 0.8336 - auc: 0.8539 - val_loss: 1.3785 - val_accuracy: 0.2520 - val_auc: 0.3096\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.7785 - accuracy: 0.8410 - auc: 0.8491 - val_loss: 0.4318 - val_accuracy: 0.8288 - val_auc: 0.8984\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 12s 311ms/step - loss: 0.7674 - accuracy: 0.8543 - auc: 0.8488 - val_loss: 0.6703 - val_accuracy: 0.6070 - val_auc: 0.6531\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.7377 - accuracy: 0.8633 - auc: 0.8639 - val_loss: 1.2582 - val_accuracy: 0.2425 - val_auc: 0.3230\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.7103 - accuracy: 0.8664 - auc: 0.8737 - val_loss: 0.4603 - val_accuracy: 0.8114 - val_auc: 0.8894\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.7338 - accuracy: 0.8687 - auc: 0.8698 - val_loss: 0.3638 - val_accuracy: 0.8732 - val_auc: 0.9272\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6995 - accuracy: 0.8719 - auc: 0.8697 - val_loss: 0.3528 - val_accuracy: 0.8764 - val_auc: 0.9190\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.6777 - accuracy: 0.8777 - auc: 0.8751 - val_loss: 0.3377 - val_accuracy: 0.8796 - val_auc: 0.9387\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 12s 308ms/step - loss: 0.6831 - accuracy: 0.8762 - auc: 0.8724 - val_loss: 0.3371 - val_accuracy: 0.9017 - val_auc: 0.9463\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6707 - accuracy: 0.8813 - auc: 0.8745 - val_loss: 0.4403 - val_accuracy: 0.8637 - val_auc: 0.9205\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6823 - accuracy: 0.8750 - auc: 0.8777 - val_loss: 0.3042 - val_accuracy: 0.8906 - val_auc: 0.9462\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6759 - accuracy: 0.8824 - auc: 0.8757 - val_loss: 0.6662 - val_accuracy: 0.6735 - val_auc: 0.7451\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6592 - accuracy: 0.8895 - auc: 0.8770 - val_loss: 0.3465 - val_accuracy: 0.8716 - val_auc: 0.9325\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6564 - accuracy: 0.8852 - auc: 0.8816 - val_loss: 0.3380 - val_accuracy: 0.8811 - val_auc: 0.9340\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6652 - accuracy: 0.8863 - auc: 0.8782 - val_loss: 0.3177 - val_accuracy: 0.8764 - val_auc: 0.9433\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6397 - accuracy: 0.8836 - auc: 0.8821 - val_loss: 0.3598 - val_accuracy: 0.8843 - val_auc: 0.9267\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6488 - accuracy: 0.8914 - auc: 0.8797 - val_loss: 0.3227 - val_accuracy: 0.8922 - val_auc: 0.9495\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6173 - accuracy: 0.8938 - auc: 0.8890 - val_loss: 0.3976 - val_accuracy: 0.8764 - val_auc: 0.9253\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6536 - accuracy: 0.8906 - auc: 0.8847 - val_loss: 0.3582 - val_accuracy: 0.9033 - val_auc: 0.9470\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6223 - accuracy: 0.8934 - auc: 0.8919 - val_loss: 0.4749 - val_accuracy: 0.8669 - val_auc: 0.9230\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 12s 308ms/step - loss: 0.6134 - accuracy: 0.9023 - auc: 0.8861 - val_loss: 0.2915 - val_accuracy: 0.8827 - val_auc: 0.9525\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 12s 307ms/step - loss: 0.6348 - accuracy: 0.8930 - auc: 0.8887 - val_loss: 1.1532 - val_accuracy: 0.7987 - val_auc: 0.8618\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 12s 312ms/step - loss: 0.6499 - accuracy: 0.8977 - auc: 0.8796 - val_loss: 2.0760 - val_accuracy: 0.3265 - val_auc: 0.3788\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 12s 307ms/step - loss: 0.6246 - accuracy: 0.9004 - auc: 0.8813 - val_loss: 0.8019 - val_accuracy: 0.7987 - val_auc: 0.9011\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6295 - accuracy: 0.8953 - auc: 0.8813 - val_loss: 0.4940 - val_accuracy: 0.8637 - val_auc: 0.9106\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6340 - accuracy: 0.8859 - auc: 0.8889 - val_loss: 0.2898 - val_accuracy: 0.9049 - val_auc: 0.9461\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5987 - accuracy: 0.8992 - auc: 0.8901 - val_loss: 0.3636 - val_accuracy: 0.8922 - val_auc: 0.9380\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5939 - accuracy: 0.9039 - auc: 0.8890 - val_loss: 0.3120 - val_accuracy: 0.8827 - val_auc: 0.9476\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6139 - accuracy: 0.9035 - auc: 0.8857 - val_loss: 0.3515 - val_accuracy: 0.8320 - val_auc: 0.9285\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5845 - accuracy: 0.9082 - auc: 0.8841 - val_loss: 0.3062 - val_accuracy: 0.8970 - val_auc: 0.9417\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5997 - accuracy: 0.9086 - auc: 0.8914 - val_loss: 0.3906 - val_accuracy: 0.8922 - val_auc: 0.9220\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5957 - accuracy: 0.9004 - auc: 0.8968 - val_loss: 0.3099 - val_accuracy: 0.8843 - val_auc: 0.9421\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 12s 297ms/step - loss: 0.5889 - accuracy: 0.9082 - auc: 0.8971 - val_loss: 0.7336 - val_accuracy: 0.8526 - val_auc: 0.9084\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6082 - accuracy: 0.8949 - auc: 0.8855 - val_loss: 0.9438 - val_accuracy: 0.4643 - val_auc: 0.5081\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6288 - accuracy: 0.8855 - auc: 0.8814 - val_loss: 0.3327 - val_accuracy: 0.8669 - val_auc: 0.9345\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 13s 318ms/step - loss: 0.5772 - accuracy: 0.9113 - auc: 0.8912 - val_loss: 0.3361 - val_accuracy: 0.8700 - val_auc: 0.9388\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 12s 312ms/step - loss: 0.5931 - accuracy: 0.9090 - auc: 0.8957 - val_loss: 0.3096 - val_accuracy: 0.8906 - val_auc: 0.9445\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5646 - accuracy: 0.9109 - auc: 0.8954 - val_loss: 0.2806 - val_accuracy: 0.9017 - val_auc: 0.9540\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.6013 - accuracy: 0.9059 - auc: 0.9021 - val_loss: 0.4634 - val_accuracy: 0.7876 - val_auc: 0.8644\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.5492 - accuracy: 0.9223 - auc: 0.8981 - val_loss: 0.3372 - val_accuracy: 0.8669 - val_auc: 0.9325\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 12s 310ms/step - loss: 0.5600 - accuracy: 0.9148 - auc: 0.8971 - val_loss: 0.5912 - val_accuracy: 0.8510 - val_auc: 0.9122\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 12s 309ms/step - loss: 0.5572 - accuracy: 0.9164 - auc: 0.8934 - val_loss: 0.3044 - val_accuracy: 0.9065 - val_auc: 0.9418\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.5628 - accuracy: 0.9121 - auc: 0.8978 - val_loss: 0.5043 - val_accuracy: 0.8700 - val_auc: 0.9226\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5675 - accuracy: 0.9137 - auc: 0.8974 - val_loss: 0.3023 - val_accuracy: 0.9017 - val_auc: 0.9446\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5497 - accuracy: 0.9242 - auc: 0.9009 - val_loss: 0.3238 - val_accuracy: 0.8796 - val_auc: 0.9377\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5298 - accuracy: 0.9270 - auc: 0.8999 - val_loss: 0.3305 - val_accuracy: 0.8906 - val_auc: 0.9374\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 12s 308ms/step - loss: 0.5357 - accuracy: 0.9246 - auc: 0.9035 - val_loss: 0.3322 - val_accuracy: 0.8653 - val_auc: 0.9348\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 13s 314ms/step - loss: 0.5558 - accuracy: 0.9156 - auc: 0.8929 - val_loss: 0.4320 - val_accuracy: 0.8225 - val_auc: 0.8942\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 12s 309ms/step - loss: 0.5145 - accuracy: 0.9336 - auc: 0.9028 - val_loss: 0.3763 - val_accuracy: 0.8827 - val_auc: 0.9323\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5123 - accuracy: 0.9187 - auc: 0.9022 - val_loss: 0.3718 - val_accuracy: 0.8732 - val_auc: 0.9340\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.5065 - accuracy: 0.9367 - auc: 0.9071 - val_loss: 0.3341 - val_accuracy: 0.8970 - val_auc: 0.9377\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5319 - accuracy: 0.9227 - auc: 0.9002 - val_loss: 0.3800 - val_accuracy: 0.8605 - val_auc: 0.9167\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5133 - accuracy: 0.9352 - auc: 0.9040 - val_loss: 0.3153 - val_accuracy: 0.8922 - val_auc: 0.9433\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 12s 307ms/step - loss: 0.5346 - accuracy: 0.9324 - auc: 0.9047 - val_loss: 0.3195 - val_accuracy: 0.9017 - val_auc: 0.9419\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.5042 - accuracy: 0.9383 - auc: 0.8993 - val_loss: 0.3570 - val_accuracy: 0.8811 - val_auc: 0.9345\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 12s 307ms/step - loss: 0.4808 - accuracy: 0.9410 - auc: 0.9059 - val_loss: 0.3815 - val_accuracy: 0.8843 - val_auc: 0.9387\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4961 - accuracy: 0.9332 - auc: 0.9078 - val_loss: 0.3710 - val_accuracy: 0.8906 - val_auc: 0.9403\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 12s 308ms/step - loss: 0.5009 - accuracy: 0.9395 - auc: 0.9020 - val_loss: 0.3364 - val_accuracy: 0.8685 - val_auc: 0.9338\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4912 - accuracy: 0.9359 - auc: 0.9045 - val_loss: 0.3280 - val_accuracy: 0.9002 - val_auc: 0.9412\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4750 - accuracy: 0.9445 - auc: 0.9073 - val_loss: 0.4096 - val_accuracy: 0.8827 - val_auc: 0.9364\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4821 - accuracy: 0.9449 - auc: 0.9018 - val_loss: 0.3669 - val_accuracy: 0.8954 - val_auc: 0.9405\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.4993 - accuracy: 0.9375 - auc: 0.9106 - val_loss: 0.3350 - val_accuracy: 0.8827 - val_auc: 0.9435\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.4937 - accuracy: 0.9426 - auc: 0.9028 - val_loss: 0.3698 - val_accuracy: 0.8922 - val_auc: 0.9371\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4735 - accuracy: 0.9332 - auc: 0.9105 - val_loss: 0.3978 - val_accuracy: 0.8875 - val_auc: 0.9360\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.4923 - accuracy: 0.9379 - auc: 0.9082 - val_loss: 0.3304 - val_accuracy: 0.8938 - val_auc: 0.9419\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.4813 - accuracy: 0.9496 - auc: 0.9059 - val_loss: 0.3463 - val_accuracy: 0.8922 - val_auc: 0.9426\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5022 - accuracy: 0.9395 - auc: 0.9054 - val_loss: 0.3443 - val_accuracy: 0.8986 - val_auc: 0.9426\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4706 - accuracy: 0.9500 - auc: 0.9106 - val_loss: 0.3428 - val_accuracy: 0.8859 - val_auc: 0.9434\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4793 - accuracy: 0.9469 - auc: 0.9079 - val_loss: 0.3249 - val_accuracy: 0.8875 - val_auc: 0.9429\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4801 - accuracy: 0.9473 - auc: 0.9031 - val_loss: 0.3764 - val_accuracy: 0.8922 - val_auc: 0.9375\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4658 - accuracy: 0.9453 - auc: 0.9083 - val_loss: 0.3592 - val_accuracy: 0.8875 - val_auc: 0.9388\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4713 - accuracy: 0.9449 - auc: 0.9111 - val_loss: 0.3783 - val_accuracy: 0.8859 - val_auc: 0.9358\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4798 - accuracy: 0.9465 - auc: 0.9084 - val_loss: 0.3360 - val_accuracy: 0.8922 - val_auc: 0.9424\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4788 - accuracy: 0.9488 - auc: 0.9073 - val_loss: 0.3299 - val_accuracy: 0.8875 - val_auc: 0.9414\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4797 - accuracy: 0.9457 - auc: 0.9114 - val_loss: 0.3487 - val_accuracy: 0.8954 - val_auc: 0.9397\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4704 - accuracy: 0.9539 - auc: 0.9098 - val_loss: 0.3301 - val_accuracy: 0.8986 - val_auc: 0.9438\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4817 - accuracy: 0.9504 - auc: 0.9082 - val_loss: 0.3250 - val_accuracy: 0.8827 - val_auc: 0.9423\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4675 - accuracy: 0.9531 - auc: 0.9085 - val_loss: 0.3323 - val_accuracy: 0.8986 - val_auc: 0.9440\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4680 - accuracy: 0.9469 - auc: 0.9105 - val_loss: 0.3590 - val_accuracy: 0.8938 - val_auc: 0.9388\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.4814 - accuracy: 0.9477 - auc: 0.9092 - val_loss: 0.3489 - val_accuracy: 0.8970 - val_auc: 0.9390\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4817 - accuracy: 0.9504 - auc: 0.9045 - val_loss: 0.3363 - val_accuracy: 0.8906 - val_auc: 0.9426\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4617 - accuracy: 0.9500 - auc: 0.9140 - val_loss: 0.3345 - val_accuracy: 0.8875 - val_auc: 0.9420\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4662 - accuracy: 0.9492 - auc: 0.9086 - val_loss: 0.3438 - val_accuracy: 0.8906 - val_auc: 0.9422\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.4642 - accuracy: 0.9504 - auc: 0.9086 - val_loss: 0.3530 - val_accuracy: 0.8954 - val_auc: 0.9420\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.4819 - accuracy: 0.9434 - auc: 0.9063 - val_loss: 0.3378 - val_accuracy: 0.8906 - val_auc: 0.9423\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.4736 - accuracy: 0.9504 - auc: 0.9104 - val_loss: 0.3491 - val_accuracy: 0.8922 - val_auc: 0.9418\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4922 - accuracy: 0.9484 - auc: 0.9097 - val_loss: 0.3443 - val_accuracy: 0.8891 - val_auc: 0.9417\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 12s 304ms/step - loss: 0.4666 - accuracy: 0.9547 - auc: 0.9097 - val_loss: 0.3409 - val_accuracy: 0.8891 - val_auc: 0.9410\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.4938 - accuracy: 0.9453 - auc: 0.9124 - val_loss: 0.3450 - val_accuracy: 0.8891 - val_auc: 0.9424\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.4756 - accuracy: 0.9465 - auc: 0.9113 - val_loss: 0.3356 - val_accuracy: 0.8922 - val_auc: 0.9427\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4892 - accuracy: 0.9449 - auc: 0.9165 - val_loss: 0.3451 - val_accuracy: 0.8938 - val_auc: 0.9427\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.4746 - accuracy: 0.9531 - auc: 0.9068 - val_loss: 0.3347 - val_accuracy: 0.8938 - val_auc: 0.9439\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.4733 - accuracy: 0.9531 - auc: 0.9086 - val_loss: 0.3325 - val_accuracy: 0.8891 - val_auc: 0.9438\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.4580 - accuracy: 0.9457 - auc: 0.9044 - val_loss: 0.3435 - val_accuracy: 0.8891 - val_auc: 0.9421\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.4879 - accuracy: 0.9391 - auc: 0.9103 - val_loss: 0.3382 - val_accuracy: 0.8922 - val_auc: 0.9421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f71c519fe20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    n_epoch = 100\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "    batch_size = 64\n",
    "    params = {'batch_size': batch_size,\n",
    "              #          'input_shape': (100, 313, 1),\n",
    "              'shuffle': True,\n",
    "              'beta_param': 0.7,\n",
    "              'mixup': True,\n",
    "              #          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "              #          'highpass': [.5, [78,79,80,81,82,83,84,85]]\n",
    "              'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "              #           'dropblock' : [30, 100]\n",
    "              #'device' : device\n",
    "    }\n",
    "\n",
    "    params_no_shuffle = {'batch_size': batch_size,\n",
    "                         #          'input_shape': (100, 313, 1),\n",
    "                         'shuffle': False,\n",
    "                         'beta_param': 0.7,\n",
    "                         'mixup': False\n",
    "                         #'device': device\n",
    "    }\n",
    "\n",
    "    TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], features_trn['preg'], features_trn['loc'],\n",
    "                              features_trn['rr1'],features_trn['qrs1'],\n",
    "                              features_trn['mel1'],features_trn['cqt1'],features_trn['stft1']],\n",
    "                             mm_lbs_trn,  ## our Y\n",
    "                             **params)()\n",
    "\n",
    "    class_weight = {0: 3, 1: 1.}\n",
    "\n",
    "    model1.fit(TrainDGen_1,\n",
    "          validation_data = ([features_test['age'],features_test['sex'], features_test['hw'],\n",
    "                              features_test['preg'], features_test['loc'], \n",
    "                              features_test['rr1'], features_test['qrs1'],\n",
    "                              features_test['mel1'],\n",
    "                              features_test['cqt1'], features_test['stft1']],\n",
    "                             mm_lbs_test),\n",
    "                             callbacks=[lr],\n",
    "                              steps_per_epoch=np.ceil(len(mm_lbs_trn)/64),\n",
    "                           class_weight=class_weight,\n",
    "                             epochs = n_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a0ae8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 16s 328ms/step - loss: 0.9793 - accuracy: 0.5094 - auc: 0.5144 - val_loss: 3.7732 - val_accuracy: 0.5008 - val_auc: 0.5048\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.7825 - accuracy: 0.5227 - auc: 0.5201 - val_loss: 1.7040 - val_accuracy: 0.5008 - val_auc: 0.5913\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.7300 - accuracy: 0.5207 - auc: 0.5402 - val_loss: 1.3394 - val_accuracy: 0.5071 - val_auc: 0.5900\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.7099 - accuracy: 0.5359 - auc: 0.5699 - val_loss: 1.3107 - val_accuracy: 0.5008 - val_auc: 0.5953\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.7122 - accuracy: 0.5270 - auc: 0.5398 - val_loss: 0.8536 - val_accuracy: 0.5119 - val_auc: 0.5937\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.6959 - accuracy: 0.5453 - auc: 0.5580 - val_loss: 0.8698 - val_accuracy: 0.5151 - val_auc: 0.5944\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6919 - accuracy: 0.5422 - auc: 0.5632 - val_loss: 0.6375 - val_accuracy: 0.6640 - val_auc: 0.7022\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 12s 305ms/step - loss: 0.6869 - accuracy: 0.5437 - auc: 0.5777 - val_loss: 0.6505 - val_accuracy: 0.6070 - val_auc: 0.6640\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6889 - accuracy: 0.5637 - auc: 0.5846 - val_loss: 0.7114 - val_accuracy: 0.5341 - val_auc: 0.6021\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6876 - accuracy: 0.5723 - auc: 0.5804 - val_loss: 0.6381 - val_accuracy: 0.6292 - val_auc: 0.6864\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6825 - accuracy: 0.5660 - auc: 0.5852 - val_loss: 0.6328 - val_accuracy: 0.6418 - val_auc: 0.6933\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6892 - accuracy: 0.5531 - auc: 0.5705 - val_loss: 0.6898 - val_accuracy: 0.5753 - val_auc: 0.6346\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6801 - accuracy: 0.5707 - auc: 0.5917 - val_loss: 0.8581 - val_accuracy: 0.5198 - val_auc: 0.5996\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6722 - accuracy: 0.5977 - auc: 0.6150 - val_loss: 0.6481 - val_accuracy: 0.6339 - val_auc: 0.6699\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6757 - accuracy: 0.5805 - auc: 0.5978 - val_loss: 0.6832 - val_accuracy: 0.5848 - val_auc: 0.6417\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6740 - accuracy: 0.5879 - auc: 0.6133 - val_loss: 0.6867 - val_accuracy: 0.5024 - val_auc: 0.5759\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.6629 - accuracy: 0.6117 - auc: 0.6234 - val_loss: 0.6620 - val_accuracy: 0.6212 - val_auc: 0.6671\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6660 - accuracy: 0.6055 - auc: 0.6280 - val_loss: 0.6846 - val_accuracy: 0.6117 - val_auc: 0.6767\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6590 - accuracy: 0.6238 - auc: 0.6368 - val_loss: 1.1134 - val_accuracy: 0.5325 - val_auc: 0.6093\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6624 - accuracy: 0.6090 - auc: 0.6292 - val_loss: 0.7183 - val_accuracy: 0.5832 - val_auc: 0.6251\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6607 - accuracy: 0.6152 - auc: 0.6307 - val_loss: 0.6810 - val_accuracy: 0.6323 - val_auc: 0.6909\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.6618 - accuracy: 0.6039 - auc: 0.6271 - val_loss: 0.6124 - val_accuracy: 0.6276 - val_auc: 0.6962\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6591 - accuracy: 0.6160 - auc: 0.6274 - val_loss: 0.8115 - val_accuracy: 0.5452 - val_auc: 0.6073\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6553 - accuracy: 0.6125 - auc: 0.6340 - val_loss: 0.6519 - val_accuracy: 0.5959 - val_auc: 0.6530\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6592 - accuracy: 0.6094 - auc: 0.6277 - val_loss: 0.7446 - val_accuracy: 0.6149 - val_auc: 0.6626\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.6533 - accuracy: 0.6113 - auc: 0.6402 - val_loss: 0.7683 - val_accuracy: 0.5071 - val_auc: 0.6129\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 12s 297ms/step - loss: 0.6515 - accuracy: 0.6375 - auc: 0.6514 - val_loss: 0.6504 - val_accuracy: 0.6212 - val_auc: 0.6604\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.6547 - accuracy: 0.6211 - auc: 0.6382 - val_loss: 0.8577 - val_accuracy: 0.5705 - val_auc: 0.6309\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6598 - accuracy: 0.6141 - auc: 0.6449 - val_loss: 0.6548 - val_accuracy: 0.5452 - val_auc: 0.6274\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6561 - accuracy: 0.6246 - auc: 0.6367 - val_loss: 0.6378 - val_accuracy: 0.6355 - val_auc: 0.6998\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6509 - accuracy: 0.6211 - auc: 0.6565 - val_loss: 0.6303 - val_accuracy: 0.6466 - val_auc: 0.7079\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6435 - accuracy: 0.6293 - auc: 0.6593 - val_loss: 0.6132 - val_accuracy: 0.6513 - val_auc: 0.7131\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6504 - accuracy: 0.6371 - auc: 0.6467 - val_loss: 0.7428 - val_accuracy: 0.5674 - val_auc: 0.6008\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6431 - accuracy: 0.6418 - auc: 0.6568 - val_loss: 0.6828 - val_accuracy: 0.5943 - val_auc: 0.5801\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.6438 - accuracy: 0.6266 - auc: 0.6524 - val_loss: 0.6495 - val_accuracy: 0.6434 - val_auc: 0.6796\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6404 - accuracy: 0.6543 - auc: 0.6666 - val_loss: 0.6583 - val_accuracy: 0.6355 - val_auc: 0.6603\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6401 - accuracy: 0.6465 - auc: 0.6652 - val_loss: 0.6160 - val_accuracy: 0.6450 - val_auc: 0.7032\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.6504 - accuracy: 0.6246 - auc: 0.6485 - val_loss: 0.6267 - val_accuracy: 0.6624 - val_auc: 0.6945\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6402 - accuracy: 0.6430 - auc: 0.6723 - val_loss: 0.6101 - val_accuracy: 0.6640 - val_auc: 0.7106\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6366 - accuracy: 0.6469 - auc: 0.6696 - val_loss: 0.6498 - val_accuracy: 0.6498 - val_auc: 0.6844\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6399 - accuracy: 0.6457 - auc: 0.6544 - val_loss: 0.6333 - val_accuracy: 0.6355 - val_auc: 0.7052\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6347 - accuracy: 0.6512 - auc: 0.6639 - val_loss: 0.6229 - val_accuracy: 0.6355 - val_auc: 0.6948\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6354 - accuracy: 0.6527 - auc: 0.6626 - val_loss: 0.6990 - val_accuracy: 0.6244 - val_auc: 0.6393\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6365 - accuracy: 0.6469 - auc: 0.6550 - val_loss: 0.6450 - val_accuracy: 0.6276 - val_auc: 0.6749\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6300 - accuracy: 0.6504 - auc: 0.6803 - val_loss: 0.6180 - val_accuracy: 0.6513 - val_auc: 0.7083\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6321 - accuracy: 0.6734 - auc: 0.6654 - val_loss: 0.6326 - val_accuracy: 0.6577 - val_auc: 0.7093\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6360 - accuracy: 0.6559 - auc: 0.6660 - val_loss: 1.7212 - val_accuracy: 0.5563 - val_auc: 0.6049\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6223 - accuracy: 0.6605 - auc: 0.6853 - val_loss: 0.7392 - val_accuracy: 0.6244 - val_auc: 0.6375\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6180 - accuracy: 0.6902 - auc: 0.6936 - val_loss: 0.6158 - val_accuracy: 0.6450 - val_auc: 0.7053\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.6143 - accuracy: 0.6727 - auc: 0.6980 - val_loss: 0.6841 - val_accuracy: 0.6403 - val_auc: 0.6691\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6178 - accuracy: 0.6715 - auc: 0.6924 - val_loss: 0.6882 - val_accuracy: 0.6387 - val_auc: 0.6653\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6168 - accuracy: 0.6660 - auc: 0.6909 - val_loss: 0.8876 - val_accuracy: 0.5198 - val_auc: 0.5927\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6132 - accuracy: 0.6750 - auc: 0.7030 - val_loss: 0.6969 - val_accuracy: 0.6260 - val_auc: 0.6748\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5941 - accuracy: 0.7086 - auc: 0.7269 - val_loss: 0.7707 - val_accuracy: 0.5483 - val_auc: 0.6196\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.6093 - accuracy: 0.6895 - auc: 0.7065 - val_loss: 0.7905 - val_accuracy: 0.6165 - val_auc: 0.6275\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.6105 - accuracy: 0.6828 - auc: 0.7035 - val_loss: 0.6883 - val_accuracy: 0.6434 - val_auc: 0.6772\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.6040 - accuracy: 0.6922 - auc: 0.7150 - val_loss: 0.6606 - val_accuracy: 0.5927 - val_auc: 0.6545\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.5901 - accuracy: 0.7102 - auc: 0.7245 - val_loss: 1.0744 - val_accuracy: 0.5658 - val_auc: 0.5675\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5909 - accuracy: 0.7059 - auc: 0.7199 - val_loss: 0.7544 - val_accuracy: 0.5674 - val_auc: 0.6193\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5905 - accuracy: 0.6969 - auc: 0.7199 - val_loss: 0.7114 - val_accuracy: 0.6212 - val_auc: 0.6596\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5780 - accuracy: 0.7246 - auc: 0.7313 - val_loss: 0.8768 - val_accuracy: 0.6117 - val_auc: 0.6156\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5783 - accuracy: 0.7199 - auc: 0.7249 - val_loss: 0.6601 - val_accuracy: 0.6181 - val_auc: 0.6826\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5771 - accuracy: 0.7102 - auc: 0.7294 - val_loss: 0.6736 - val_accuracy: 0.5943 - val_auc: 0.6587\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5734 - accuracy: 0.7316 - auc: 0.7340 - val_loss: 1.0416 - val_accuracy: 0.6038 - val_auc: 0.6226\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5695 - accuracy: 0.7309 - auc: 0.7423 - val_loss: 0.7080 - val_accuracy: 0.6006 - val_auc: 0.6575\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5590 - accuracy: 0.7574 - auc: 0.7440 - val_loss: 0.8494 - val_accuracy: 0.6307 - val_auc: 0.6573\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5620 - accuracy: 0.7473 - auc: 0.7425 - val_loss: 0.9724 - val_accuracy: 0.6101 - val_auc: 0.6082\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5545 - accuracy: 0.7570 - auc: 0.7495 - val_loss: 0.7212 - val_accuracy: 0.5848 - val_auc: 0.6395\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5591 - accuracy: 0.7516 - auc: 0.7562 - val_loss: 0.9640 - val_accuracy: 0.6070 - val_auc: 0.6049\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5537 - accuracy: 0.7547 - auc: 0.7562 - val_loss: 0.6952 - val_accuracy: 0.6244 - val_auc: 0.6859\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.5498 - accuracy: 0.7563 - auc: 0.7619 - val_loss: 0.8769 - val_accuracy: 0.6212 - val_auc: 0.6392\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5389 - accuracy: 0.7637 - auc: 0.7555 - val_loss: 0.9672 - val_accuracy: 0.6197 - val_auc: 0.6262\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.5509 - accuracy: 0.7496 - auc: 0.7526 - val_loss: 0.7606 - val_accuracy: 0.6418 - val_auc: 0.6811\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5404 - accuracy: 0.7625 - auc: 0.7638 - val_loss: 0.7314 - val_accuracy: 0.6181 - val_auc: 0.6752\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5327 - accuracy: 0.7680 - auc: 0.7671 - val_loss: 0.7438 - val_accuracy: 0.6292 - val_auc: 0.6755\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5384 - accuracy: 0.7707 - auc: 0.7605 - val_loss: 0.7974 - val_accuracy: 0.6418 - val_auc: 0.6757\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5397 - accuracy: 0.7668 - auc: 0.7648 - val_loss: 0.7368 - val_accuracy: 0.6022 - val_auc: 0.6551\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5268 - accuracy: 0.7758 - auc: 0.7734 - val_loss: 0.7588 - val_accuracy: 0.6006 - val_auc: 0.6546\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5401 - accuracy: 0.7621 - auc: 0.7507 - val_loss: 0.7696 - val_accuracy: 0.6276 - val_auc: 0.6742\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5287 - accuracy: 0.7812 - auc: 0.7689 - val_loss: 0.7450 - val_accuracy: 0.6307 - val_auc: 0.6845\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.5319 - accuracy: 0.7621 - auc: 0.7654 - val_loss: 0.7299 - val_accuracy: 0.6197 - val_auc: 0.6749\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.5317 - accuracy: 0.7875 - auc: 0.7647 - val_loss: 0.7563 - val_accuracy: 0.6197 - val_auc: 0.6652\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5210 - accuracy: 0.7773 - auc: 0.7832 - val_loss: 0.9801 - val_accuracy: 0.6276 - val_auc: 0.6408\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5245 - accuracy: 0.7727 - auc: 0.7690 - val_loss: 0.8527 - val_accuracy: 0.6307 - val_auc: 0.6699\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5342 - accuracy: 0.7645 - auc: 0.7632 - val_loss: 0.7601 - val_accuracy: 0.6276 - val_auc: 0.6702\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.5252 - accuracy: 0.7824 - auc: 0.7780 - val_loss: 0.7553 - val_accuracy: 0.6292 - val_auc: 0.6748\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 12s 298ms/step - loss: 0.5270 - accuracy: 0.7734 - auc: 0.7643 - val_loss: 0.8005 - val_accuracy: 0.6149 - val_auc: 0.6621\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 12s 304ms/step - loss: 0.5379 - accuracy: 0.7668 - auc: 0.7656 - val_loss: 0.8739 - val_accuracy: 0.6434 - val_auc: 0.6685\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5225 - accuracy: 0.7785 - auc: 0.7722 - val_loss: 0.7944 - val_accuracy: 0.6212 - val_auc: 0.6726\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 0.5245 - accuracy: 0.7762 - auc: 0.7765 - val_loss: 0.7679 - val_accuracy: 0.6323 - val_auc: 0.6842\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.5241 - accuracy: 0.7785 - auc: 0.7833 - val_loss: 0.9626 - val_accuracy: 0.6371 - val_auc: 0.6519\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.5207 - accuracy: 0.7898 - auc: 0.7737 - val_loss: 0.8022 - val_accuracy: 0.6276 - val_auc: 0.6821\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 12s 299ms/step - loss: 0.5150 - accuracy: 0.7828 - auc: 0.7754 - val_loss: 0.8635 - val_accuracy: 0.6418 - val_auc: 0.6616\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5182 - accuracy: 0.7898 - auc: 0.7798 - val_loss: 0.7686 - val_accuracy: 0.6181 - val_auc: 0.6716\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 12s 301ms/step - loss: 0.5171 - accuracy: 0.7844 - auc: 0.7769 - val_loss: 0.7690 - val_accuracy: 0.6165 - val_auc: 0.6752\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 12s 300ms/step - loss: 0.5135 - accuracy: 0.7977 - auc: 0.7802 - val_loss: 0.7668 - val_accuracy: 0.6181 - val_auc: 0.6672\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.5201 - accuracy: 0.7941 - auc: 0.7790 - val_loss: 0.7967 - val_accuracy: 0.6228 - val_auc: 0.6688\n",
      "Epoch 98/100\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.5120 - accuracy: 0.7977 - auc: 0.7884 - val_loss: 0.8181 - val_accuracy: 0.6292 - val_auc: 0.6796\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5280 - accuracy: 0.7762 - auc: 0.7623 - val_loss: 0.7878 - val_accuracy: 0.6197 - val_auc: 0.6764\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.5239 - accuracy: 0.7805 - auc: 0.7655 - val_loss: 0.8406 - val_accuracy: 0.6244 - val_auc: 0.6657\n"
     ]
    }
   ],
   "source": [
    "    n_epoch = 100\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "    batch_size = 64\n",
    "    params = {'batch_size': batch_size,\n",
    "              #          'input_shape': (100, 313, 1),\n",
    "              'shuffle': True,\n",
    "              'beta_param': 0.7,\n",
    "              'mixup': True,\n",
    "              #          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "            'highpass': [.5, [78,79,80,81,82,83,84,85]],\n",
    "              'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "            #           'dropblock' : [30, 100]\n",
    "              #'device' : device\n",
    "    }\n",
    "    params_no_shuffle = {'batch_size': batch_size,\n",
    "                         #          'input_shape': (100, 313, 1),\n",
    "                         'shuffle': False,\n",
    "                         'beta_param': 0.7,\n",
    "                         'mixup': False\n",
    "                         #'device': device\n",
    "    }\n",
    "\n",
    "    TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], features_trn['preg'], features_trn['loc'],\n",
    "                              features_trn['rr1'],features_trn['qrs1'],\n",
    "                              features_trn['mel1'],features_trn['cqt1'],features_trn['stft1']],\n",
    "                             out_lbs_trn,  ## our Y\n",
    "                             **params)()\n",
    "\n",
    "    class_weight = {0: 3, 1: 1.}\n",
    "\n",
    "    model2.fit(TrainDGen_1,\n",
    "          validation_data = ([features_test['age'],features_test['sex'], features_test['hw'],\n",
    "                              features_test['preg'], features_test['loc'], \n",
    "                              features_test['rr1'], features_test['qrs1'],\n",
    "                              features_test['mel1'],\n",
    "                              features_test['cqt1'], features_test['stft1']],\n",
    "                             out_lbs_test),\n",
    "                             callbacks=[lr],\n",
    "                              steps_per_epoch=np.ceil(len(out_lbs_trn)/64),\n",
    "                             epochs = n_epoch)\n",
    "\n",
    "\n",
    "    params_feature['mel_shape'] = mel_input_shape\n",
    "    params_feature['cqt_shape'] = cqt_input_shape\n",
    "    params_feature['stft_shape'] = stft_input_shape\n",
    "\n",
    "    params_feature['use_mel'] = use_mel\n",
    "    params_feature['use_cqt'] = use_cqt\n",
    "    params_feature['use_stft'] = use_stft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa43fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model(model_folder, model1, model2, m_name1, m_name2, param_feature) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename1 = os.path.join(model_folder, m_name1 + '_model1.hdf5')\n",
    "    filename2 = os.path.join(model_folder, m_name2 + '_model2.hdf5')\n",
    "    model1.save(filename1)\n",
    "    model2.save(filename2)\n",
    "    param_feature['model1'] = m_name1\n",
    "    param_feature['model2'] = m_name2\n",
    "    param_feature['model_fnm1'] = filename1\n",
    "    param_feature['model_fnm2'] = filename2\n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(param_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "\n",
    "def load_challenge_model(model_folder, verbose):\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    with open(info_fnm, 'rb') as f:\n",
    "        info_m = pk.load(f)\n",
    "#    if info_m['model'] == 'toy' :\n",
    "#        model = get_toy(info_m['mel_shape'])\n",
    "#    filename = os.path.join(model_folder, info_m['model'] + '_model.hdf5')\n",
    "#    model.load_weights(filename)\n",
    "    return info_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f26f41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model.\n",
    "def run_model(model_folder, data_folder, output_folder, allow_failures, verbose):\n",
    "    # Load models.\n",
    "    if verbose >= 1:\n",
    "        print('Loading Challenge model...')\n",
    "\n",
    "    model = load_challenge_model(model_folder, verbose) ### Teams: Implement this function!!!\n",
    "\n",
    "    # Find the patient data files.\n",
    "    patient_files = find_patient_files(data_folder)\n",
    "    num_patient_files = len(patient_files)\n",
    "\n",
    "    if num_patient_files==0:\n",
    "        raise Exception('No data was provided.')\n",
    "\n",
    "    # Create a folder for the Challenge outputs if it does not already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Run the team's model on the Challenge data.\n",
    "    if verbose >= 1:\n",
    "        print('Running model on Challenge data...')\n",
    "\n",
    "#    @tf.function\n",
    "    # Iterate over the patient files.\n",
    "    for i in range(num_patient_files):\n",
    "        if verbose >= 2:\n",
    "            print('    {}/{}...'.format(i+1, num_patient_files))\n",
    "\n",
    "        patient_data = load_patient_data(patient_files[i])\n",
    "        recordings = load_recordings(data_folder, patient_data)\n",
    "\n",
    "        # Allow or disallow the model to fail on parts of the data; helpful for debugging.\n",
    "        try:\n",
    "            classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "        except:\n",
    "            if allow_failures:\n",
    "                if verbose >= 2:\n",
    "                    print('... failed.')\n",
    "                classes, labels, probabilities = list(), list(), list()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Save Challenge outputs.\n",
    "        head, tail = os.path.split(patient_files[i])\n",
    "        root, extension = os.path.splitext(tail)\n",
    "        output_file = os.path.join(output_folder, root + '.csv')\n",
    "        patient_id = get_patient_id(patient_data)\n",
    "        save_challenge_outputs(output_file, patient_id, classes, labels, probabilities)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50591d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "\n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "    if model['model1'] == 'toy1' :\n",
    "        model1 = get_toy5_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'] )\n",
    "    if model['model2'] == 'toy2' :\n",
    "        model2 = get_toy5_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'])\n",
    "    if model['model1'] == 'lcnn1' :\n",
    "        model1 = get_LCNN_o_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model2'] == 'lcnn2' :\n",
    "        model2 = get_LCNN_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'])\n",
    "    if model['model1'] == 'resmax1' :\n",
    "        model1 = get_ResMax_o_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model2'] == 'resmax2' :\n",
    "        model2 = get_ResMax_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'])\n",
    "    if model['model1'] == 'lcnn1_dr' :\n",
    "        model1 = get_LCNN_o_1_dr(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'], dp = model['dp'], fc = model['fc'], ext = model['ext'])\n",
    "    if model['model2'] == 'lcnn2_dr' :\n",
    "        model2 = get_LCNN_2_dr(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], dp = model['dp'], fc = model['fc'], ext = model['ext'])\n",
    "    if model['model1'] == 'lcnn_rr_qrs1' :\n",
    "        model1 = get_LCNN_o_5_dr_qrs1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model2'] == 'lcnn_rr_qrs2' :\n",
    "        model2 = get_LCNN_o_5_dr_qrs1_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model1'] == 'lcnn_rr_qrs2_2_1' :\n",
    "        model1 = get_LCNN_o_5_dr_qrs2_2_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model2'] == 'lcnn_rr_qrs2_2_2' :\n",
    "        model2 = get_LCNN_o_5_dr_qrs2_2_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])    \n",
    "    if model['model1'] == 'lcnn_rr_qrs3_1' :\n",
    "        model1 = get_LCNN_o_5_dr_qrs3_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    if model['model2'] == 'lcnn_rr_qrs3_2' :\n",
    "        model2 = get_LCNN_o_5_dr_qrs3_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], use_mel = model['use_mel'], use_cqt = model['use_cqt'], use_stft = model['use_stft'], ord1 = model['ord1'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    model1.load_weights(model['model_fnm1'])\n",
    "    model2.load_weights(model['model_fnm2'])\n",
    "\n",
    "#    classes = model['classes']\n",
    "    # Load features.\n",
    "    features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "    samp_sec = model['samp_sec']\n",
    "    pre_emphasis = model['pre_emphasis']\n",
    "    hop_length = model['hop_length']\n",
    "    win_length = model['win_length']\n",
    "    n_mels = model['n_mels']\n",
    "    filter_scale = model['filter_scale']\n",
    "    n_bins = model['n_bins']\n",
    "    fmin = model['fmin']\n",
    "    use_mel = model['use_mel']\n",
    "    use_cqt = model['use_cqt']\n",
    "    use_stft = model['use_stft']\n",
    "\n",
    "    trim = model['trim']\n",
    "    \n",
    "    features['rr1'] = [] \n",
    "    for i in range(len(recordings)):\n",
    "        try:\n",
    "            ____, info = nk.ecg_process(recordings[i], sampling_rate=4000)\n",
    "            rr = np.diff(info['ECG_R_Peaks'])/4000\n",
    "            current_rr = rr\n",
    "        except:\n",
    "            current_rr=np.zeros(1)\n",
    "        features['rr1'].append(current_rr)  \n",
    "    features['rr1'] = np.array(features['rr1'])\n",
    "    \n",
    "    \n",
    "    features['qrs1'] = []\n",
    "    for i in range(len(recordings)):\n",
    "        try:\n",
    "            R_peaks, S_point, Q_point=EKG_QRS_detect1(recording1, 4000, True, False)\n",
    "            qrs = (S_point-Q_point)/4000\n",
    "            current_qrs = qrs\n",
    "        except:\n",
    "            current_qrs=np.zeros(1) \n",
    "        features['qrs1'].append(current_rr)  \n",
    "    features['qrs1'] = np.array(features['qrs1'])\n",
    "    \n",
    "\n",
    "    features['mel1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        if use_mel :\n",
    "            mel1 = feature_extract_melspec(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length,\n",
    "                                           win_length = win_length, n_mels = n_mels, trim = trim)[0]\n",
    "        else :\n",
    "            mel1 = np.zeros( (1,1) )\n",
    "        features['mel1'].append(mel1)\n",
    "    M, N = features['mel1'][0].shape\n",
    "\n",
    "    if use_mel :\n",
    "        for i in range(len(features['mel1'])) :\n",
    "            features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "    features['mel1'] = np.array(features['mel1'])\n",
    "\n",
    "    features['cqt1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        if use_cqt :\n",
    "            mel1 = feature_extract_cqt(recordings[i], samp_sec=samp_sec, pre_emphasis = pre_emphasis, filter_scale = filter_scale,\n",
    "                                        n_bins = n_bins, fmin = fmin, trim = trim)[0]\n",
    "        else :\n",
    "            mel1 = np.zeros( (1,1))\n",
    "        features['cqt1'].append(mel1)\n",
    "    M, N = features['cqt1'][0].shape\n",
    "    if use_cqt :\n",
    "        for i in range(len(features['cqt1'])) :\n",
    "            features['cqt1'][i] = features['cqt1'][i].reshape(M,N,1)\n",
    "    features['cqt1'] = np.array(features['cqt1'])\n",
    "\n",
    "    features['stft1'] = []\n",
    "    for i in range(len(recordings)) :\n",
    "        if use_stft :\n",
    "            mel1 = feature_extract_stft(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length,\n",
    "                                        win_length = win_length, trim = trim)[0]\n",
    "        else :\n",
    "            mel1 = np.zeros( (1,1) )\n",
    "        features['stft1'].append(mel1)\n",
    "    M, N = features['stft1'][0].shape\n",
    "    if use_stft :\n",
    "        for i in range(len(features['stft1'])) :\n",
    "            features['stft1'][i] = features['stft1'][i].reshape(M,N,1)\n",
    "    features['stft1'] = np.array(features['stft1'])\n",
    "\n",
    "    #    print(features)\n",
    "    # Impute missing data.\n",
    "    res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], \n",
    "                           features['rr1'], features['qrs1'], features['mel1'], features['cqt1'], features['stft1']])\n",
    "    res2 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'], features['loc'], \n",
    "                           features['rr1'], features['qrs1'], features['mel1'], features['cqt1'], features['stft1']])\n",
    "\n",
    "    # Get classifier probabilities.\n",
    "    if model['ord1'] :\n",
    "        idx1 = res1.argmax(axis=0)[0]\n",
    "        murmur_p = res1[idx1,]  ## mumur 확률 최대화 되는 애 뽑기\n",
    "        murmur_probabilities = np.zeros((3,))\n",
    "        murmur_probabilities[0] = murmur_p[0]\n",
    "        murmur_probabilities[1] = 0\n",
    "        murmur_probabilities[2] = murmur_p[1]\n",
    "        outcome_probabilities = res2.mean(axis = 0) ##  outcome 은 그냥 평균으로 뽑기\n",
    "    else :\n",
    "        if model['mm_mean'] :\n",
    "            murmur_probabilities = res1.mean(axis = 0)\n",
    "        else :\n",
    "            idx1 = res1.argmax(axis=0)[0]\n",
    "            murmur_probabilities = res1[idx1,]  ## mumur 확률 최대화 되는 애 뽑기\n",
    "        outcome_probabilities = res2.mean(axis = 0) ##  outcome 은 그냥 평균으로 뽑기\n",
    "\n",
    "        \n",
    "    ## 이부분도 생각 필요.. rule 을 cost를 maximize 하는 기준으로 threshold 탐색 필요할지도..\n",
    "    # Choose label with highest probability.\n",
    "    murmur_labels = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "    idx = np.argmax(murmur_probabilities)\n",
    "    murmur_labels[idx] = 1\n",
    "    outcome_labels = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "    idx = np.argmax(outcome_probabilities)\n",
    "    outcome_labels[idx] = 1\n",
    "\n",
    "    # Concatenate classes, labels, and probabilities.\n",
    "    classes = murmur_classes + outcome_classes\n",
    "    labels = np.concatenate((murmur_labels, outcome_labels))\n",
    "    probabilities = np.concatenate((murmur_probabilities, outcome_probabilities))\n",
    "\n",
    "    return classes, labels, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d1c4393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_challenge_model(model_folder, model1, model2, m_name1 = 'lcnn_rr_qrs2_2_1', m_name2 = 'lcnn_rr_qrs2_2_2', param_feature = params_feature)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73f66a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcnn__rr_qrs4'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "513b7bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Data2/hmd/data_split/murmur/test'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = test_folder\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ff610cb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Data2/hmd/hmd_sy/notebooks/out_lcnn__rr_qrs4'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed1bd147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 24).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 24).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 24).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 24).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 49).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 49).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 20).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 20).\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6d28052430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 20).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 20).\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f6cf85b4f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 57).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 57).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 57).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 57).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 51).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 43).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 51).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 51).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 37).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 43).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 43).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 25).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 25).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 25).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 25).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 47).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 47).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 47).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 47).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 22).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 22).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 40).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 40).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 37).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 37).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_42045/1123519003.py:67: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  features['rr1'] = np.array(features['rr1'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='rr'), name='rr', description=\"created by layer 'rr'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='qrs'), name='qrs', description=\"created by layer 'qrs'\"), but it was called on an input with incompatible shape (None, 38).\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run_model(model_folder, test_folder, output_folder, allow_failures = True, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23bcbb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.148,0.230,0.496,14101.853\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.379,0.508,0.798,14180.830\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.327,0.000,0.117\n",
      "Accuracy,0.921,0.000,0.065\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.662,0.096\n",
      "Accuracy,0.939,0.054\n",
      "\n"
     ]
    }
   ],
   "source": [
    "murmur_scores, outcome_scores = evaluate_model(test_folder, output_folder)\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "    + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "\n",
    "if len(sys.argv) == 3:\n",
    "    print(output_string)\n",
    "elif len(sys.argv) == 4:\n",
    "    with open(sys.argv[3], 'w') as f:\n",
    "        f.write(output_string)\n",
    "#Murmur scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4090c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030344201410640304\n",
      "0.069132238470447\n",
      "0.03898775832866518\n",
      "0.06048868206471049\n"
     ]
    }
   ],
   "source": [
    "label_folder = test_folder\n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "# Load and parse label and model output files.\n",
    "label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "murmur_labels = load_murmurs(label_files, murmur_classes)\n",
    "murmur_binary_outputs, murmur_scalar_outputs = load_classifier_outputs(output_files, murmur_classes)\n",
    "outcome_labels = load_outcomes(label_files, outcome_classes)\n",
    "outcome_binary_outputs, outcome_scalar_outputs = load_classifier_outputs(output_files, outcome_classes)\n",
    "\n",
    "\n",
    "print(np.mean(murmur_scalar_outputs[:,0]))\n",
    "print(np.mean(murmur_scalar_outputs[:,2]))\n",
    "print(np.mean(outcome_scalar_outputs[:,0]))\n",
    "print(np.mean(outcome_scalar_outputs[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c6dc6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.01\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.122,0.209,0.518,14915.104\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.337,0.508,0.832,15131.464\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.338,0.000,0.028\n",
      "Accuracy,1.000,0.000,0.014\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.674,0.000\n",
      "Accuracy,0.990,0.000\n",
      "\n",
      "-------------\n",
      "threshold:  0.05\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.132,0.220,0.523,14718.457\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.349,0.513,0.834,14916.196\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.341,0.000,0.055\n",
      "Accuracy,1.000,0.000,0.029\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.676,0.021\n",
      "Accuracy,0.990,0.011\n",
      "\n",
      "-------------\n",
      "threshold:  0.1\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.132,0.220,0.523,14718.457\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.352,0.503,0.810,14718.457\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.341,0.000,0.055\n",
      "Accuracy,1.000,0.000,0.029\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.664,0.040\n",
      "Accuracy,0.959,0.022\n",
      "\n",
      "-------------\n",
      "threshold:  0.15\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.132,0.220,0.523,14718.457\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.363,0.508,0.811,14520.528\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.341,0.000,0.055\n",
      "Accuracy,1.000,0.000,0.029\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.060\n",
      "Accuracy,0.959,0.032\n",
      "\n",
      "-------------\n",
      "threshold:  0.2\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.132,0.220,0.523,14718.457\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.363,0.508,0.811,14520.528\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.341,0.000,0.055\n",
      "Accuracy,1.000,0.000,0.029\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.060\n",
      "Accuracy,0.959,0.032\n",
      "\n",
      "-------------\n",
      "threshold:  0.25\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.144,0.230,0.518,14365.565\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.382,0.513,0.806,14156.141\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.338,0.000,0.094\n",
      "Accuracy,0.974,0.000,0.050\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.097\n",
      "Accuracy,0.949,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.3\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.144,0.230,0.518,14365.565\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.382,0.513,0.806,14156.141\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.338,0.000,0.094\n",
      "Accuracy,0.974,0.000,0.050\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.097\n",
      "Accuracy,0.949,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.35\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.149,0.236,0.520,14208.724\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.382,0.513,0.806,14156.141\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.341,0.000,0.106\n",
      "Accuracy,0.974,0.000,0.058\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.097\n",
      "Accuracy,0.949,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.4\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.151,0.236,0.509,14273.984\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.382,0.513,0.806,14156.141\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.335,0.000,0.118\n",
      "Accuracy,0.947,0.000,0.065\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.097\n",
      "Accuracy,0.949,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.45\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.148,0.230,0.496,14101.853\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.382,0.513,0.806,14156.141\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.327,0.000,0.117\n",
      "Accuracy,0.921,0.000,0.065\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.667,0.097\n",
      "Accuracy,0.949,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.5\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.148,0.230,0.496,14101.853\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.379,0.508,0.798,14180.830\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.327,0.000,0.117\n",
      "Accuracy,0.921,0.000,0.065\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.662,0.096\n",
      "Accuracy,0.939,0.054\n",
      "\n",
      "-------------\n",
      "threshold:  0.55\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13932.783\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.389,0.513,0.799,13999.300\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.329,0.000,0.129\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.664,0.114\n",
      "Accuracy,0.939,0.065\n",
      "\n",
      "-------------\n",
      "threshold:  0.6\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13932.783\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.386,0.508,0.791,14030.363\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.329,0.000,0.129\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.659,0.113\n",
      "Accuracy,0.929,0.065\n",
      "\n",
      "-------------\n",
      "threshold:  0.65\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13932.783\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.383,0.503,0.782,14064.560\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.329,0.000,0.129\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.655,0.112\n",
      "Accuracy,0.918,0.065\n",
      "\n",
      "-------------\n",
      "threshold:  0.7\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13976.162\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.380,0.497,0.774,14101.853\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.330,0.000,0.128\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.650,0.111\n",
      "Accuracy,0.908,0.065\n",
      "\n",
      "-------------\n",
      "threshold:  0.75\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13976.162\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.380,0.497,0.774,14101.853\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.330,0.000,0.128\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.650,0.111\n",
      "Accuracy,0.908,0.065\n",
      "\n",
      "-------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  0.8\n",
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.486,0.345,0.153,0.236,0.499,13976.162\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.501,0.512,0.380,0.497,0.774,14101.853\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.507,0.500,0.452\n",
      "AUPRC,0.238,0.073,0.723\n",
      "F-measure,0.330,0.000,0.128\n",
      "Accuracy,0.921,0.000,0.072\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.524,0.477\n",
      "AUPRC,0.537,0.487\n",
      "F-measure,0.650,0.111\n",
      "Accuracy,0.908,0.065\n",
      "\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for th1 in [0.01, 0.05, 0.1, 0.15,0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8] :\n",
    "    murmur_binary_outputs[:,0] = murmur_scalar_outputs[:,0] > th1\n",
    "    murmur_binary_outputs[:,2] = murmur_scalar_outputs[:,2] > 1 - th1\n",
    "    outcome_binary_outputs[:,0] = outcome_scalar_outputs[:,0] > th1\n",
    "    outcome_binary_outputs[:,1] = outcome_scalar_outputs[:,1] > 1 - th1\n",
    "    # For each patient, set the 'Present' or 'Abnormal' class to positive if no class is positive or if multiple classes are positive.\n",
    "    murmur_labels = enforce_positives(murmur_labels, murmur_classes, 'Present')\n",
    "    murmur_binary_outputs = enforce_positives(murmur_binary_outputs, murmur_classes, 'Present')\n",
    "    outcome_labels = enforce_positives(outcome_labels, outcome_classes, 'Abnormal')\n",
    "    outcome_binary_outputs = enforce_positives(outcome_binary_outputs, outcome_classes, 'Abnormal')\n",
    "    # Evaluate the murmur model by comparing the labels and model outputs.\n",
    "    murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes = compute_auc(murmur_labels, murmur_scalar_outputs)\n",
    "    murmur_f_measure, murmur_f_measure_classes = compute_f_measure(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_accuracy, murmur_accuracy_classes = compute_accuracy(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_weighted_accuracy = compute_weighted_accuracy(murmur_labels, murmur_binary_outputs, murmur_classes) # This is the murmur scoring metric.\n",
    "    murmur_cost = compute_cost(outcome_labels, murmur_binary_outputs, outcome_classes, murmur_classes) # Use *outcomes* to score *murmurs* for the Challenge cost metric, but this is not the actual murmur scoring metric.\n",
    "    murmur_scores = (murmur_classes, murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes, \\\n",
    "                 murmur_f_measure, murmur_f_measure_classes, murmur_accuracy, murmur_accuracy_classes, murmur_weighted_accuracy, murmur_cost)\n",
    "\n",
    "    # Evaluate the outcome model by comparing the labels and model outputs.\n",
    "    outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes = compute_auc(outcome_labels, outcome_scalar_outputs)\n",
    "    outcome_f_measure, outcome_f_measure_classes = compute_f_measure(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_accuracy, outcome_accuracy_classes = compute_accuracy(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_weighted_accuracy = compute_weighted_accuracy(outcome_labels, outcome_binary_outputs, outcome_classes)\n",
    "    outcome_cost = compute_cost(outcome_labels, outcome_binary_outputs, outcome_classes, outcome_classes) # This is the clinical outcomes scoring metric.\n",
    "    outcome_scores = (outcome_classes, outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes, \\\n",
    "                  outcome_f_measure, outcome_f_measure_classes, outcome_accuracy, outcome_accuracy_classes, outcome_weighted_accuracy, outcome_cost)\n",
    "\n",
    "\n",
    "\n",
    "    classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "    murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "    murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "    classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "    outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "    outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "    output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "                + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "    print(\"threshold: \", th1)\n",
    "    print(output_string)\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bd0be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
