{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *\n",
    "import numpy as np, scipy as sp, scipy.stats, os, sys, joblib\n",
    "from sklearn.impute import SimpleImputer\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from models import *\n",
    "from get_feature import *\n",
    "from Generator0 import *\n",
    "import pickle as pk\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "import datetime\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math\n",
    "import sys\n",
    "sys.path.insert(0,'lucashnegri-peakutils-51a679cd8428')\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "import peakutils\n",
    "from scipy import special\n",
    "import scipy.io as sio\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import peakutils\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    train_folder =  '/home/jk21/Downloads/Data/data/murmur/train'\n",
    "    test_folder = '/home/jk21/Downloads/Data/data/murmur/test'\n",
    "    patient_files_trn = find_patient_files(train_folder)\n",
    "    patient_files_test = find_patient_files(test_folder)\n",
    "    \n",
    "    per_sec=4000\n",
    "    winlen = 512\n",
    "    hoplen = 256\n",
    "    nmel = 120 \n",
    "    nsec = 20 \n",
    "    trim = 1 \n",
    "    use_mel=True\n",
    "    use_cqt = False \n",
    "    use_stft = False\n",
    "    ord1 = True #np.random.choice([True,False])\n",
    "    maxlen1 = 120000\n",
    "    min_dist = np.random.choice(list(range(10,2000 ,10)))\n",
    "    max_interval_len = np.random.choice(list(range(100,300 ,10)))\n",
    "    \n",
    "    params_feature = {'samp_sec': nsec,\n",
    "                  #### melspec, stft 피쳐 옵션들  \n",
    "                  'pre_emphasis': 0,\n",
    "                  'hop_length': hoplen,\n",
    "                  'win_length': winlen,\n",
    "                  'n_mels': nmel,\n",
    "                  #### cqt 피쳐 옵션들  \n",
    "                  'filter_scale': 1,\n",
    "                  'n_bins': 80,\n",
    "                  'fmin': 10,\n",
    "                  'maxlen1': maxlen1,\n",
    "                  'min_dist':min_dist,\n",
    "                  'max_interval_len' : max_interval_len,\n",
    "                  'trim' :1,\n",
    "                  'use_mel' : use_mel,\n",
    "                  'use_cqt' : use_cqt,\n",
    "                  'use_stft' : use_stft,\n",
    "                  'per_sec' : per_sec}\n",
    "    \n",
    "    model_folder = 'lcnn2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/64 [00:00<?, ?it/s]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 17%|█▋        | 11/64 [00:12<00:52,  1.00it/s]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 19%|█▉        | 12/64 [00:14<00:55,  1.07s/it]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 27%|██▋       | 17/64 [00:19<00:54,  1.16s/it]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 45%|████▌     | 29/64 [00:33<00:45,  1.29s/it]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 61%|██████    | 39/64 [00:45<00:31,  1.25s/it]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      " 98%|█████████▊| 63/64 [01:18<00:01,  1.19s/it]/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/jk21/anaconda3/envs/new_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 64/64 [01:20<00:00,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melspec:  120 313\n",
      "cqt:  1 1\n",
      "stft:  1 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    def sigmoidal_decay(e, start=0, end=100, lr_start=1e-3, lr_end=1e-5):\n",
    "        \n",
    "        if e < start:\n",
    "            return lr_start\n",
    "        elif e > end:\n",
    "            return lr_end\n",
    "\n",
    "        middle = (start + end) / 2\n",
    "        s = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "        return s(13 * (-e + middle) / np.abs(end - start)) * np.abs(lr_start - lr_end) + lr_end\n",
    "\n",
    "    if ord1 :\n",
    "        features_trn, mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape = get_features_3lb_all_ord_rr(train_folder, patient_files_trn[:64], **params_feature)\n",
    "    else :\n",
    "        features_trn, mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape = get_features_3lb_all(train_folder, patient_files_trn, **params_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samp_sec': 20,\n",
       " 'pre_emphasis': 0,\n",
       " 'hop_length': 256,\n",
       " 'win_length': 512,\n",
       " 'n_mels': 120,\n",
       " 'filter_scale': 1,\n",
       " 'n_bins': 80,\n",
       " 'fmin': 10,\n",
       " 'maxlen1': 120000,\n",
       " 'min_dist': 1990,\n",
       " 'max_interval_len': 150,\n",
       " 'trim': 1,\n",
       " 'use_mel': True,\n",
       " 'use_cqt': False,\n",
       " 'use_stft': False,\n",
       " 'per_sec': 4000}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "params_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mm_weight = 3 #np.random.choice([2,3,4,5])\n",
    "    oo_weight = 3 #np.random.choice([2,3,4,5,6])\n",
    "    ord1 = True #np.random.choice([True,False])\n",
    "    mm_mean = False #np.random.choice([True,False])\n",
    "    dp = 0 #np.random.choice([0, .1, .2, .3])\n",
    "    fc = False #np.random.choice([True,False])\n",
    "    interval_seq = np.random.choice([True,False])\n",
    "    ext = False\n",
    "    ext2 = True\n",
    "    if interval_seq==True:\n",
    "        \n",
    "        model_index=np.random.choice([0,1])\n",
    "        model_list = [['lcnn1','lcnn2'],['lcnn5','lcnn6']][model_index]\n",
    "        m1,m2 = model_list\n",
    "      \n",
    "    if interval_seq==False:\n",
    "        model_index=np.random.choice([0,1])\n",
    "        model_list = [['lcnn3','lcnn4'],['lcnn7','lcnn8']][model_index]\n",
    "        m1,m2 = model_list\n",
    "    \n",
    "    \n",
    "    chaug = 10 #np.random.choice([0, 10])\n",
    "    mixup = True #np.random.choice([True,False])\n",
    "    cout = .8 #np.random.choice([0, 0.8])\n",
    "    wunknown = 1 #np.random.choice([1, 0.7, .5, .2])\n",
    "    n1 = 0 #np.random.choice([0,2])\n",
    "    \n",
    "    if n1 == 0 :\n",
    "        ranfil = False\n",
    "    else :\n",
    "        ranfil = [n1, [18,19,20,21,22,23]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcnn5'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "    nep = 5\n",
    "    \n",
    "    params_feature['ord1'] = ord1\n",
    "    params_feature['mm_mean'] = mm_mean\n",
    "    params_feature['dp'] = dp\n",
    "    params_feature['fc'] = fc\n",
    "    params_feature['ext'] = ext\n",
    "    params_feature['oo_weight'] = oo_weight\n",
    "    params_feature['mm_weight'] = mm_weight\n",
    "    params_feature['chaug'] = chaug\n",
    "    params_feature['cout'] = cout\n",
    "    params_feature['wunknown'] = wunknown\n",
    "    params_feature['mixup'] = mixup\n",
    "    params_feature['n1'] = n1\n",
    "    params_feature['use_interval_seq'] = interval_seq\n",
    "    params_feature['m_name1'] = m1\n",
    "    params_feature['m_name2'] = m2\n",
    "    mel_input_shape = features_trn['mel1'].shape[1:]\n",
    "    cqt_input_shape = features_trn['cqt1'].shape[1:]\n",
    "    stft_input_shape = features_trn['stft1'].shape[1:]\n",
    "    interval_input_shape= features_trn['interval'].shape[1:]\n",
    "    interval_mean_input_shape = (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if m1 =='lcnn1':\n",
    "        model1=LCNN_seq_mean_model_1(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape, ord1= ord1,dp = dp, fc = fc, ext = False, ext2=True)\n",
    "    if m2 =='lcnn2':\n",
    "        model2=LCNN_seq_mean_model_2(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape, dp = dp, fc = fc, ext = True,ext2=False)\n",
    "    if m1 =='lcnn3':\n",
    "        model1=LCNN_mean_model_1(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,ord1= ord1,dp = dp, fc = fc, ext = False, ext2=True)\n",
    "    if m2 =='lcnn4':\n",
    "        model2=LCNN_mean_model_2(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,dp = dp, fc = fc, ext = True,ext2=False)    \n",
    "\n",
    "    if m1 =='lcnn5':\n",
    "        model1=LCNN_seq_mean_jk_model_1(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape, ord1= ord1,dp = dp, fc = fc, ext = False, ext2=True)\n",
    "    if m2 =='lcnn6':\n",
    "        model2=LCNN_seq_mean_jk_model_2(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape, dp = dp, fc = fc, ext = True,ext2=False)\n",
    "    if m1 =='lcnn7':\n",
    "        model1=LCNN_mean_jk_model_1(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,ord1= ord1,dp = dp, fc = fc, ext = False, ext2=True)\n",
    "    if m2 =='lcnn8' :\n",
    "        model2=LCNN_mean_jk_model_2(mel_input_shape, cqt_input_shape, stft_input_shape,interval_input_shape,dp = dp, fc = fc, ext = True,ext2=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcnn6'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4/4 [==============================] - 15s 3s/step - loss: 1.3134 - accuracy: 0.4102 - auc: 0.4184 - lr: 9.9851e-04\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.2201 - accuracy: 0.4336 - auc: 0.4080 - lr: 9.8036e-04\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.2278 - accuracy: 0.5273 - auc: 0.5195 - lr: 7.8798e-04\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.2494 - accuracy: 0.4414 - auc: 0.4622 - lr: 2.2202e-04\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.1266 - accuracy: 0.4102 - auc: 0.4970 - lr: 2.9642e-05\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 16s 3s/step - loss: 46.1701 - accuracy: 0.1680 - auc: 0.1267 - lr: 9.9851e-04\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 10s 3s/step - loss: 36.8332 - accuracy: 0.1953 - auc: 0.1466 - lr: 9.8036e-04\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 11s 3s/step - loss: 30.1162 - accuracy: 0.1406 - auc: 0.1373 - lr: 7.8798e-04\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 10s 3s/step - loss: 25.3095 - accuracy: 0.1758 - auc: 0.1579 - lr: 2.2202e-04\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 10s 2s/step - loss: 25.7434 - accuracy: 0.1328 - auc: 0.1296 - lr: 2.9642e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    n_epoch = nep\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "    batch_size = 64\n",
    "\n",
    "    if mixup :\n",
    "        beta_param = .7\n",
    "    else :\n",
    "        beta_param = 0\n",
    "\n",
    "\n",
    "\n",
    "    params = {'batch_size': batch_size,\n",
    "              #          'input_shape': (100, 313, 1),\n",
    "              'shuffle': True,\n",
    "              'chaug': chaug,\n",
    "              'beta_param': beta_param,\n",
    "              'cout': cout\n",
    "    #              'mixup': mixup,\n",
    "              #          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "              #          'highpass': [.5, [78,79,80,81,82,83,84,85]]\n",
    "    #              'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "              #           'dropblock' : [30, 100]\n",
    "              #'device' : device\n",
    "    }\n",
    "\n",
    "    if mixup :\n",
    "        params['mixup'] = mixup\n",
    "        params['ranfilter2'] = ranfil\n",
    "    else :\n",
    "        params['cutout'] = cout\n",
    "\n",
    "    params_no_shuffle = {'batch_size': batch_size,\n",
    "                         #          'input_shape': (100, 313, 1),\n",
    "                         'shuffle': False,\n",
    "                         'beta_param': 0.7,\n",
    "                         'mixup': False\n",
    "                         #'device': device\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    if ord1 :\n",
    "        class_weight = {0: mm_weight, 1: 1.}\n",
    "    else :\n",
    "        class_weight = {0: mm_weight, 1: wunknown, 2:1.}\n",
    "\n",
    "\n",
    "    if mixup :\n",
    "\n",
    "\n",
    "        TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], \n",
    "                                  features_trn['preg'], features_trn['loc'],\n",
    "                                  features_trn['mel1'], features_trn['cqt1'],features_trn['stft1'],\n",
    "                                  features_trn['interval_mean'],features_trn['interval']],features_trn['mm_labels'],**params)()\n",
    "\n",
    "        model1.fit(TrainDGen_1,\n",
    "#                    validation_data = ([features_test['age'],features_test['sex'], features_test['hw'],                                   \n",
    "#                                        features_test['preg'], features_test['loc'],\n",
    "#                                        features_test['interval'],\n",
    "#                                        features_test['mel1'],\n",
    "#                                        features_test['cqt1'],\n",
    "#                                        features_test['stft1'],features_test['interval_mean']],features_test['mm_labels']),\n",
    "\n",
    "                   callbacks=[lr],\n",
    "                   steps_per_epoch=np.ceil(len(features_trn['mm_labels'])/batch_size),\n",
    "                   class_weight=class_weight, \n",
    "                   epochs = n_epoch)\n",
    "    \n",
    "    \n",
    " \n",
    "    n_epoch = nep\n",
    "    lr = LearningRateScheduler(lambda e: sigmoidal_decay(e, end=n_epoch))\n",
    "\n",
    "    batch_size = 64\n",
    "\n",
    "    if mixup :\n",
    "        beta_param = .7\n",
    "    else :\n",
    "        beta_param = 0\n",
    "\n",
    "    params = {'batch_size': batch_size,\n",
    "              #          'input_shape': (100, 313, 1),\n",
    "              'shuffle': True,\n",
    "              'chaug': 0,\n",
    "              'beta_param': beta_param,\n",
    "              'cout': cout,\n",
    "    #              'mixup': True,\n",
    "              #          'lowpass': [.5, [11,12,13,14,15,16,17,18]]\n",
    "    #            'highpass': [.5, [78,79,80,81,82,83,84,85]],\n",
    "    #              'ranfilter2' : [3, [18,19,20,21,22,23]]\n",
    "            #           'dropblock' : [30, 100]\n",
    "              #'device' : device\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    if mixup :\n",
    "        params['mixup'] = mixup\n",
    "        params['ranfilter2'] = ranfil\n",
    "    else :\n",
    "        params['cutout'] = cout\n",
    "\n",
    "\n",
    "    params_no_shuffle = {'batch_size': batch_size,\n",
    "                         #          'input_shape': (100, 313, 1),\n",
    "                         'shuffle': False,\n",
    "                         'beta_param': 0.7,\n",
    "                         'mixup': False\n",
    "                         #'device': device\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if mixup :\n",
    "\n",
    "\n",
    "        class_weight = {0: oo_weight, 1: 1.}\n",
    "        TrainDGen_1 = Generator0([features_trn['age'],features_trn['sex'], features_trn['hw'], \n",
    "                                  features_trn['preg'], features_trn['loc'],\n",
    "                                  features_trn['mel1'], features_trn['cqt1'],features_trn['stft1'],\n",
    "                                  features_trn['interval_mean'],features_trn['interval']],features_trn['out_labels'],**params)()\n",
    "\n",
    "        model2.fit(TrainDGen_1,\n",
    "#                    validation_data = ([features_test['age'],features_test['sex'], features_test['hw'],                                   \n",
    "#                                        features_test['preg'], features_test['loc'],features_test['interval'],\n",
    "#                                        features_test['mel1'],\n",
    "#                                        features_test['cqt1'],\n",
    "#                                        features_test['stft1'],features_test['interval_mean']],features_test['out_labels']), \n",
    "                   callbacks=[lr],\n",
    "            \n",
    "                   steps_per_epoch=np.ceil(len(features_trn['out_labels'])/batch_size),\n",
    "                   class_weight=class_weight, \n",
    "                   epochs = n_epoch)\n",
    "    \n",
    "    params_feature['mel_shape'] = mel_input_shape\n",
    "    params_feature['cqt_shape'] = cqt_input_shape\n",
    "    params_feature['stft_shape'] = stft_input_shape\n",
    "    params_feature['interval_shape'] = interval_input_shape\n",
    "    params_feature['interval_mean_shape'] = interval_mean_input_shape\n",
    "    params_feature['max_interval_len'] = max_interval_len\n",
    "    \n",
    "    \n",
    "    import pickle as pk\n",
    "    def save_challenge_model(model_folder, model1, model2, m_name1, m_name2, param_feature) :\n",
    "        os.makedirs(model_folder, exist_ok=True)\n",
    "        info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "        filename1 = os.path.join(model_folder, m_name1 + '_model1.hdf5')\n",
    "        filename2 = os.path.join(model_folder, m_name2 + '_model2.hdf5')\n",
    "        model1.save(filename1)\n",
    "        model2.save(filename2)\n",
    "        params_feature['model1'] = m_name1\n",
    "        params_feature['model2'] = m_name2\n",
    "        params_feature['model_fnm1'] = filename1\n",
    "        params_feature['model_fnm2'] = filename2\n",
    "        with open(info_fnm, 'wb') as f:\n",
    "            pk.dump(params_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "        return 1\n",
    "\n",
    "        with open(info_fnm, 'wb') as f:\n",
    "            pk.dump(params_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "        return 1\n",
    "    \n",
    "    save_challenge_model(model_folder, model1, model2, m_name1 = m1, m_name2 = m2, param_feature = params_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pk\n",
    "def save_challenge_model(model_folder, model1, model2, m_name1, m_name2, param_feature) :\n",
    "    os.makedirs(model_folder, exist_ok=True)\n",
    "    info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "    filename1 = os.path.join(model_folder, m_name1 + '_model1.hdf5')\n",
    "    filename2 = os.path.join(model_folder, m_name2 + '_model2.hdf5')\n",
    "    model1.save(filename1)\n",
    "    model2.save(filename2)\n",
    "    params_feature['model1'] = m_name1\n",
    "    params_feature['model2'] = m_name2\n",
    "    params_feature['model_fnm1'] = filename1\n",
    "    params_feature['model_fnm2'] = filename2\n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(params_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "\n",
    "    with open(info_fnm, 'wb') as f:\n",
    "        pk.dump(params_feature, f, pk.HIGHEST_PROTOCOL)\n",
    "    return 1\n",
    "    \n",
    "save_challenge_model(model_folder, model1, model2, m_name1 = m1, m_name2 = m2, param_feature = params_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_challenge_model(model_folder, model1, model2, m_name1 = m1, m_name2 = m2, param_feature = params_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lcnn2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def load_challenge_model(model_folder, verbose):\n",
    "        info_fnm = os.path.join(model_folder, 'desc.pk')\n",
    "        with open(info_fnm, 'rb') as f:\n",
    "            info_m = pk.load(f)\n",
    "\n",
    "        return info_m\n",
    "    \n",
    "    ########################RunModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_challenge_model(model_folder, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'samp_sec': 20,\n",
       " 'pre_emphasis': 0,\n",
       " 'hop_length': 256,\n",
       " 'win_length': 512,\n",
       " 'n_mels': 120,\n",
       " 'filter_scale': 1,\n",
       " 'n_bins': 80,\n",
       " 'fmin': 10,\n",
       " 'maxlen1': 120000,\n",
       " 'min_dist': 210,\n",
       " 'max_interval_len': 170,\n",
       " 'trim': 1,\n",
       " 'use_mel': True,\n",
       " 'use_cqt': False,\n",
       " 'use_stft': False,\n",
       " 'use_interval_seq': True,\n",
       " 'per_sec': 4000,\n",
       " 'ord1': True,\n",
       " 'mm_mean': False,\n",
       " 'dp': 0,\n",
       " 'fc': False,\n",
       " 'ext': False,\n",
       " 'oo_weight': 3,\n",
       " 'mm_weight': 3,\n",
       " 'chaug': 10,\n",
       " 'cout': 0.8,\n",
       " 'wunknown': 1,\n",
       " 'mixup': True,\n",
       " 'n1': 0,\n",
       " 'm_name1': 'lcnn1',\n",
       " 'm_name2': 'lcnn2',\n",
       " 'mel_shape': (120, 313, 1),\n",
       " 'cqt_shape': (1, 1, 1),\n",
       " 'stft_shape': (1, 1, 1),\n",
       " 'interval_shape': (170, 1),\n",
       " 'interval_mean_shape': (1,),\n",
       " 'model1': 'lcnn1',\n",
       " 'model2': 'lcnn2',\n",
       " 'model_fnm1': 'lcnn2/lcnn1_model1.hdf5',\n",
       " 'model_fnm2': 'lcnn2/lcnn2_model2.hdf5'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_challenge_model(model, data, recordings, verbose):\n",
    "        \n",
    "        murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "        outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "    ##########################################################################    \n",
    "        if model['model1'] == 'lcnn1' :\n",
    "            model1 = get_LCNN_o_1_dr_rr(model['mel_shape'],model['cqt_shape'],model['stft_shape'], model['interval_shape'],\n",
    "                                     use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "                                     use_stft = model['use_stft'],\n",
    "                                     ord1 = model['ord1'], dp = model['dp'], fc = model['fc'], \n",
    "                                     ext = False, ext2= True,use_interval_seq=model['use_interval_seq'])  \n",
    "        if model['model2'] == 'lcnn2' :\n",
    "            model2 = get_LCNN_2_dr_rr(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \n",
    "                                       model['interval_shape'],\n",
    "                                       use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "                                       use_stft = model['use_stft'],\n",
    "                                       dp = model['dp'], fc = model['fc'], \n",
    "                                       ext = True, ext2=False,use_interval_seq=model['use_interval_seq']) \n",
    "\n",
    "        \n",
    "        # if model['model1'] == 'lcnn3' :\n",
    "        #     model1 = get_LCNN_pi_seq_mean_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \n",
    "        #                                       model['interval_shape'],model['interval_mean_shape'],\n",
    "        #                                       use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "        #                                       use_stft = model['use_stft'],\n",
    "        #                                       ord1 = model['ord1'], dp = model['dp'], fc = model['fc'], \n",
    "        #                                       ext = False, ext2= True) \n",
    "            \n",
    "        # if model['model2'] == 'lcnn4' :\n",
    "        #     model2 = get_LCNN_pi_seq_mean_2(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \n",
    "        #                                         model['interval_shape'], model['interval_mean_shape'],\n",
    "        #                                         use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "        #                                         use_stft = model['use_stft'],ord1 = model['ord1'], \n",
    "        #                                         dp = model['dp'], fc = model['fc'], \n",
    "        #                                     ext = True, ext2=False)\n",
    "\n",
    "#         if model['model1'] == 'lcnn5' :\n",
    "#             model1 = get_LCNN_o_4_dr_interval_mean(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \n",
    "#                                                    model['interval_shape'],model['interval_mean_shape'],\n",
    "#                                                    use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "#                                                    use_stft = model['use_stft'], ord1 = model['ord1'], \n",
    "#                                                    dp = model['dp'], fc = model['fc'], ext = model['ext'])  \n",
    "            \n",
    "#         if model['model2'] == 'lcnn6' :\n",
    "#             model2 = get_LCNN_o_4_dr_1_interval_mean(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \n",
    "#                                                      model['interval_shape'],model['interval_mean_shape'],\n",
    "#                                                      use_mel = model['use_mel'],use_cqt = model['use_cqt'], \n",
    "#                                                      use_stft = model['use_stft'],ord1 = model['ord1'], \n",
    "#                                                      dp = model['dp'], fc = model['fc'], ext = model['ext'])\n",
    "        \n",
    "        \n",
    "\n",
    "        model1.load_weights(model['model_fnm1'])\n",
    "        model2.load_weights(model['model_fnm2'])\n",
    "    ############################################################################ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Load features.\n",
    "        features = get_feature_one(data, verbose = 0)\n",
    "\n",
    "        samp_sec = model['samp_sec'] \n",
    "        pre_emphasis = model['pre_emphasis']\n",
    "        hop_length = model['hop_length']\n",
    "        win_length = model['win_length']\n",
    "        n_mels = model['n_mels']\n",
    "        filter_scale = model['filter_scale']\n",
    "        n_bins = model['n_bins']\n",
    "        fmin = model['fmin']\n",
    "        trim = model['trim']\n",
    "        use_mel = model['use_mel']\n",
    "        use_cqt = model['use_cqt']\n",
    "        use_stft = model['use_stft']\n",
    "        use_interval_seq = model['use_interval_seq']\n",
    "        maxlen1 = model['maxlen1']\n",
    "        min_dist = model['min_dist']\n",
    "        per_sec = model['per_sec']\n",
    "\n",
    "    #    use_raw = model['use_raw']\n",
    "\n",
    "        max_interval_len = model['max_interval_len']\n",
    "\n",
    "\n",
    "        # Load features.\n",
    "\n",
    "\n",
    "        tmp_total_interval = [] \n",
    "        tmp_total_interval_mean = []\n",
    "\n",
    "        features['interval'] = []\n",
    "        features['interval_mean']=[]\n",
    "\n",
    "        if use_interval_seq:\n",
    "            \n",
    "\n",
    "            for i in range(len(recordings)):\n",
    "                datos=recordings[i]\n",
    "                filtros=sio.loadmat('./Filters1')\n",
    "                tmp_interval = []\n",
    "\n",
    "\n",
    "                try:\n",
    "                    X = datos\n",
    "                    Fs= 4000\n",
    "                    Fpa20=filtros['Fpa20'];\t\t\t        # High pass filter\n",
    "                    Fpa20=Fpa20[0];\t\t\t\t\t# High pass filter\n",
    "                    Fpb100=filtros['Fpb100'];\t\t        # Low-pass Filter\n",
    "                    Fpb100=Fpb100[0];\t\t\t\t# Low-pass Filter\n",
    "                    Xf=FpassBand(X,Fpa20,Fpb100); \t                # Apply a passband filter\n",
    "                    Xf=vec_nor(Xf);\t\t\t\n",
    "\n",
    "        # Derivate of the Signal\n",
    "                    dX=derivate(Xf);\t\t\t\t# Derivate of the signal\n",
    "                    dX=vec_nor(dX);\t\t\t\t\t# Vector Normalizing\n",
    "        # Square of the signal\n",
    "                    dy=np.square(Xf);\n",
    "                    dy=vec_nor(dy);\n",
    "\n",
    "                    size=np.shape(Xf)\t\t\t\t# Rank or dimension of the array\n",
    "                    fil=size[0];\t\t\t\t\t# Number of rows\n",
    "\n",
    "                    positive=np.zeros((1,fil+1));                   # Initializating Positives Values Vector \n",
    "                    positive=positive[0];                           # Getting the Vector\n",
    "\n",
    "                    points=np.zeros((1,fil));                       # Initializating the all Peak Points Vector\n",
    "                    points=points[0];                               # Getting the point vector\n",
    "\n",
    "                    peaks=np.zeros((1,fil));                        # Initializating the s1-s1 Peak Vector\n",
    "                    peaks=peaks[0];                                 # Getting the point vector\n",
    "\n",
    "\n",
    "                    for i in range(0,fil):\n",
    "                        if dX[i]>0:\n",
    "                            positive[i]=1;\n",
    "                        else:\n",
    "                            positive[i]=0;\n",
    "\n",
    "                    for i in range(0,fil):\n",
    "                        if (positive[i]==1 and positive[i+1]==0):\n",
    "                            points[i]=Xf[i];\n",
    "                        else:\n",
    "                            points[i]=0;\n",
    "\n",
    "                    indexes=peakutils.indexes(points,thres=0.5/max(points), min_dist=min_dist);\n",
    "                    lenght=np.shape(indexes)\t\t\t# Get the length of the index vector\t\t\n",
    "                    lenght=lenght[0];\t\t\t\t# Get the value of the index vector\n",
    "\n",
    "                    for i in range(0,lenght):\n",
    "                        p=indexes[i];\n",
    "                        peaks[p]=points[p];\n",
    "\n",
    "                    n=np.arange(0,fil);\n",
    "\n",
    "                    ############### interval distance ##############                   \n",
    "                    tmp_peaks = np.diff(indexes)/4000\n",
    "\n",
    "                    ############## interval sequence ###############\n",
    "                    tmp_peaks_inteval = tmp_peaks\n",
    "\n",
    "\n",
    "                    ########### interval distance mean ############\n",
    "                    tmp_peaks = np.array(tmp_peaks)\n",
    "                    tmp_peaks = np.mean(tmp_peaks)\n",
    "\n",
    "                    if len(tmp_peaks_inteval) == 1:\n",
    "                        tmp_peaks_inteval = np.zeros(1)\n",
    "\n",
    "    #                         tmp_peaks_mean = np.mean(tmp_peaks)\n",
    "    #                         tmp_peaks_std = np.std(tmp_peaks)\n",
    "\n",
    "    #                         tmp_final = np.divide((tmp_peaks-tmp_peaks_mean),tmp_peaks_std)\n",
    "\n",
    "                    tmp_peaks = np.nan_to_num(tmp_peaks)\n",
    "    #                     print(tmp_final)\n",
    "                    tmp_total_interval_mean.append(tmp_peaks)\n",
    "                    tmp_total_interval.append(tmp_peaks_inteval)\n",
    "\n",
    "\n",
    "                except:\n",
    "                    print(i)\n",
    "                    tmp_peaks = np.zeros(1)\n",
    "                    tmp_peaks_inteval = np.zeros(1)\n",
    "                    tmp_total_interval_mean.append(tmp_peaks)\n",
    "                    tmp_total_interval.append(tmp_peaks_inteval)\n",
    "\n",
    "        else :\n",
    "            tmp_peaks = np.zeros(1)\n",
    "            tmp_peaks_inteval = np.zeros(1)\n",
    "            tmp_total_interval_mean.append(tmp_peaks)\n",
    "            tmp_total_interval.append(tmp_peaks_inteval)      \n",
    "\n",
    "\n",
    "        if use_interval_seq:\n",
    "\n",
    "\n",
    "            ############ interval Sequence #################\n",
    "            padded =pad_sequences(tmp_total_interval, maxlen=max_interval_len, dtype='float32', padding='post', truncating='post',\n",
    "                                  value=0.0)\n",
    "\n",
    "            for i in range(len(padded)):\n",
    "                features['interval'].append(padded[i])\n",
    "            for i in range(len(features['interval'])):\n",
    "                features['interval'][i]= features['interval'][i].reshape(-1,1)\n",
    "            features['interval']= np.array(features['interval'])\n",
    "\n",
    "\n",
    "            features['interval_mean'] = np.array(tmp_total_interval_mean,dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "        features['mel1'] = []\n",
    "        for i in range(len(recordings)) :\n",
    "            if use_mel :\n",
    "                mel1 = feature_extract_melspec(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length,\n",
    "                                               win_length = win_length, n_mels = n_mels)[0]\n",
    "            else :\n",
    "                mel1 = np.zeros( (1,1) )\n",
    "\n",
    "            features['mel1'].append(mel1)\n",
    "\n",
    "        M, N = features['mel1'][0].shape\n",
    "\n",
    "        if use_mel :\n",
    "            for i in range(len(features['mel1'])) :\n",
    "                features['mel1'][i] = features['mel1'][i].reshape(M,N,1)\n",
    "\n",
    "        features['mel1'] = np.array(features['mel1'])\n",
    "\n",
    "        features['cqt1'] = []\n",
    "        for i in range(len(recordings)) :\n",
    "            if use_cqt :\n",
    "                mel1 = feature_extract_cqt(recordings[i], samp_sec=samp_sec, pre_emphasis = pre_emphasis, filter_scale = filter_scale,\n",
    "                                            n_bins = n_bins, fmin = fmin)[0]\n",
    "            else:\n",
    "                mel1 = np.zeros( (1,1,1) )\n",
    "\n",
    "            features['cqt1'].append(mel1)\n",
    "\n",
    "        M, N,__ = features['cqt1'][0].shape\n",
    "\n",
    "        if use_cqt :\n",
    "            for i in range(len(features['cqt1'])) :\n",
    "                features['cqt1'][i] = features['cqt1'][i].reshape(M,N,1)\n",
    "\n",
    "        features['cqt1'] = np.array(features['cqt1'])\n",
    "\n",
    "\n",
    "        features['stft1'] = []\n",
    "        for i in range(len(recordings)) :\n",
    "            if use_stft :\n",
    "                mel1 = feature_extract_stft(recordings[i]/ 32768, samp_sec=samp_sec, pre_emphasis = pre_emphasis, hop_length=hop_length,\n",
    "                                            win_length = win_length)[0]\n",
    "            else :\n",
    "                mel1 = np.zeros( (1,1,1) )\n",
    "\n",
    "            features['stft1'].append(mel1)\n",
    "\n",
    "        M, N,__ = features['stft1'][0].shape\n",
    "        if use_stft :\n",
    "            for i in range(len(features['stft1'])) :\n",
    "                features['stft1'][i] = features['stft1'][i].reshape(M,N,1)\n",
    "        features['stft1'] = np.array(features['stft1'])\n",
    "\n",
    "    #     return features\n",
    "\n",
    "        #    print(features)\n",
    "        # Impute missing data.\n",
    "        \n",
    "        \n",
    "        \n",
    "        res1 = model1.predict([features['age'], features['sex'], features['hw'], features['preg'],\n",
    "                               features['loc'], features['mel1'], features['stft1'], features['cqt1'],features['interval_mean'],features['interval']])\n",
    "        res2 = model2.predict([features['age'], features['sex'], features['hw'], features['preg'],\n",
    "                               features['loc'], features['mel1'], features['stft1'], features['cqt1'],features['interval_mean'],features['interval']])\n",
    "        \n",
    "        if model['ord1'] :\n",
    "            idx1 = res1.argmax(axis=0)[0]\n",
    "            murmur_p = res1[idx1,]  ## mumur 확률 최대화 되는 애 뽑기ddd\n",
    "            murmur_probabilities = np.zeros((3,))\n",
    "            murmur_probabilities[0] = murmur_p[0]\n",
    "            murmur_probabilities[1] = 0\n",
    "            murmur_probabilities[2] = murmur_p[1]\n",
    "            outcome_probabilities = res2.mean(axis = 0) ##  outcome 은 그냥 평균으로 뽑기\n",
    "\n",
    "        else :\n",
    "            if model['mm_mean'] :\n",
    "                murmur_probabilities = res1.mean(axis = 0)\n",
    "            else :\n",
    "                idx1 = res1.argmax(axis=0)[0]\n",
    "                murmur_probabilities = res1[idx1,]  ## mumur 확률 최대화 되는 애 뽑기\n",
    "            outcome_probabilities = res2.mean(axis = 0) ##  outcome 은 그냥 평균으로 뽑기\n",
    "\n",
    "\n",
    "        murmur_labels = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "\n",
    "\n",
    "        if murmur_probabilities[0] > 0.482 :\n",
    "            idx = 0\n",
    "        else :\n",
    "            idx = 2\n",
    "        murmur_labels[idx] = 1\n",
    "\n",
    "        outcome_labels = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "        if outcome_probabilities[0] > 0.607 :\n",
    "            idx = 0\n",
    "        else :\n",
    "            idx = 1\n",
    "            # idx = np.argmax(outcome_probabilities)\n",
    "        outcome_labels[idx] = 1\n",
    "\n",
    "        # Concatenate classes, labels, and probabilities.\n",
    "        classes = murmur_classes + outcome_classes\n",
    "        labels = np.concatenate((murmur_labels, outcome_labels))\n",
    "        probabilities = np.concatenate((murmur_probabilities, outcome_probabilities))\n",
    "\n",
    "        return classes, labels, probabilities\n",
    "    \n",
    "output_folder ='/home/jk21/Documents/submission_paper_out/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(data_folder)\n",
    "num_patient_files = len(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "            patient_data = load_patient_data(patient_files[10])\n",
    "            recordings = load_recordings(data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer count mismatch when loading weights from file. Model expected 51 layers, found 99 saved layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes, labels, probabilities \u001b[38;5;241m=\u001b[39m \u001b[43mrun_challenge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecordings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [42]\u001b[0m, in \u001b[0;36mrun_challenge_model\u001b[0;34m(model, data, recordings, verbose)\u001b[0m\n\u001b[1;32m     14\u001b[0m         model2 \u001b[38;5;241m=\u001b[39m get_LCNN_2_dr_rr(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmel_shape\u001b[39m\u001b[38;5;124m'\u001b[39m],model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcqt_shape\u001b[39m\u001b[38;5;124m'\u001b[39m],model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstft_shape\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     15\u001b[0m                                    model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterval_shape\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     16\u001b[0m                                    use_mel \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_mel\u001b[39m\u001b[38;5;124m'\u001b[39m],use_cqt \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_cqt\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     17\u001b[0m                                    use_stft \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_stft\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     18\u001b[0m                                    dp \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdp\u001b[39m\u001b[38;5;124m'\u001b[39m], fc \u001b[38;5;241m=\u001b[39m model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[1;32m     19\u001b[0m                                    ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, ext2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,use_interval_seq\u001b[38;5;241m=\u001b[39mmodel[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_interval_seq\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# if model['model1'] == 'lcnn3' :\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m#     model1 = get_LCNN_pi_seq_mean_1(model['mel_shape'],model['cqt_shape'],model['stft_shape'], \u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m#                                       model['interval_shape'],model['interval_mean_shape'],\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#                                                      use_stft = model['use_stft'],ord1 = model['ord1'], \u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#                                                      dp = model['dp'], fc = model['fc'], ext = model['ext'])\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_fnm1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     model2\u001b[38;5;241m.\u001b[39mload_weights(model[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_fnm2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m############################################################################ \u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# Load features.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/saving/hdf5_format.py:728\u001b[0m, in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, model)\u001b[0m\n\u001b[1;32m    726\u001b[0m layer_names \u001b[38;5;241m=\u001b[39m filtered_layer_names\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(layer_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(filtered_layers):\n\u001b[0;32m--> 728\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    729\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer count mismatch when loading weights from file. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    730\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_layers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m layers, found \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    731\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(layer_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m saved layers.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# We batch weight value assignments in a single backend call\u001b[39;00m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;66;03m# which provides a speedup in TensorFlow.\u001b[39;00m\n\u001b[1;32m    735\u001b[0m weight_value_tuples \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: Layer count mismatch when loading weights from file. Model expected 51 layers, found 99 saved layers."
     ]
    }
   ],
   "source": [
    "classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Present', 'Unknown', 'Absent', 'Abnormal', 'Normal']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6cec2361aeb74e0b5ee9454472a5f6ffeaee3c517f88c30ed339271084c4c5a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
