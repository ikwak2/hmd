{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d722d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jh20/narin/physionet/python-classifier-2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f632a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1a3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, warnings, sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/jh20/narin/dcase/DESED_task')\n",
    "sys.path.append('/home/jh20/narin/dcase/DESED_task/recipes/dcase2022_task4_baseline')\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description = \"HMD_trainer\")\n",
    "## Training Settings\n",
    "parser.add_argument('--train_data_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train/',     help='train data path')\n",
    "parser.add_argument('--valid_data_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/validation/',     help='validation data path')\n",
    "parser.add_argument('--output_folder',    default='./output_folder',     help='output folder')\n",
    "parser.add_argument(\"--label_type\",default=\"murmur\", type=str, help=\"label type\")\n",
    "parser.add_argument(\"--lr\",default=1e-3, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--minibatchsize_train\", default=64, type=int)\n",
    "parser.add_argument(\"--minibatchsize_valid\", default=1, type=int)\n",
    "parser.add_argument(\"--train_num_workers\", default=6, type=int, help=\"number of training workers\")\n",
    "parser.add_argument(\"--dev_num_workers\", default=1, type=int, help=\"number of validation workers\")\n",
    "parser.add_argument(\"--seed\", default=617, type=int)\n",
    "parser.add_argument(\"--model_path\", default='./hmd_CNN', type=str)\n",
    "parser.add_argument(\"--logdir\", default='./log_hmd/', type=str)\n",
    "parser.add_argument(\"--model_name\", default='hmd_CNN_model', type=str)\n",
    "parser.add_argument(\"--start_iter\", default=0, type=int)\n",
    "parser.add_argument(\"--end_iter\", default=200, type=int)\n",
    "parser.add_argument(\"--gpu\", default=\"0\", type=str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbf04e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    murmur_train_model = torch.load(model_folder + '/' + args.model_name + '_63.model')\n",
    "    outcome_train_model = torch.load(model_folder + '/' + args.outcome_model_name + '_63.model')\n",
    "    return murmur_train_model, outcome_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d345cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    murmur_train_model = torch.load('/home/jh20/narin/physionet/hmd_CNN' + '/' + 'hmd_CNN_model_40.model')\n",
    "    outcome_train_model = torch.load('/home/jh20/narin/physionet/hmd_CNN_outcome' + '/' + 'hmd_CNN_outcome_model_25.model')\n",
    "    return [murmur_train_model, outcome_train_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045e9623",
   "metadata": {},
   "outputs": [],
   "source": [
    "murmur_train_model, outcome_train_model = load_challenge_model(args.model_path, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7565f35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.0669,  0.0362,  0.0159,  ...,  0.0085,  0.0040, -0.0800],\n",
       "                      [-0.0303,  0.0435, -0.0681,  ...,  0.0288, -0.0548,  0.0466],\n",
       "                      [-0.0541,  0.0562, -0.0333,  ..., -0.0497, -0.0148,  0.0251],\n",
       "                      ...,\n",
       "                      [ 0.0235, -0.0228,  0.0315,  ...,  0.0803,  0.0513,  0.0184],\n",
       "                      [-0.0145,  0.0434,  0.0549,  ...,  0.0055, -0.0203, -0.0847],\n",
       "                      [ 0.0231, -0.0186, -0.0321,  ...,  0.0056,  0.0444, -0.0545]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.0393, -0.0399, -0.0400,  0.0117,  0.0555,  0.0568,  0.0174,  0.0164,\n",
       "                       0.0067, -0.0350, -0.0510, -0.0031,  0.0277, -0.0607, -0.0567,  0.0506,\n",
       "                       0.0001, -0.0140,  0.0182,  0.0333, -0.0540,  0.0312, -0.0268,  0.0404,\n",
       "                      -0.0507,  0.0143,  0.0635, -0.0481, -0.0057, -0.0036, -0.0544, -0.0583,\n",
       "                      -0.0585,  0.0209, -0.0131, -0.0441,  0.0241,  0.0412,  0.0439,  0.0610,\n",
       "                       0.0281,  0.0327, -0.0398,  0.0496, -0.0586,  0.0198, -0.0384,  0.0112,\n",
       "                      -0.0119,  0.0349,  0.0058, -0.0148, -0.0113,  0.0576,  0.0095, -0.0552,\n",
       "                      -0.0007,  0.0590, -0.0130,  0.0102, -0.0545,  0.0568, -0.0423, -0.0033,\n",
       "                       0.0139,  0.0100, -0.0202, -0.0452,  0.0196,  0.0114, -0.0469, -0.0152,\n",
       "                       0.0126,  0.0275,  0.0189, -0.0233, -0.0323,  0.0051, -0.0457, -0.0491,\n",
       "                       0.0568,  0.0267,  0.0292,  0.0384,  0.0132, -0.0330, -0.0258, -0.0192,\n",
       "                       0.0471,  0.0117,  0.0195,  0.0353,  0.0630,  0.0054, -0.0157, -0.0553,\n",
       "                      -0.0302, -0.0428, -0.0129, -0.0519,  0.0357,  0.0089, -0.0088,  0.0375,\n",
       "                      -0.0290,  0.0030,  0.0037, -0.0324,  0.0346, -0.0362, -0.0600, -0.0565,\n",
       "                       0.0583, -0.0434, -0.0542, -0.0640, -0.0147, -0.0355, -0.0577, -0.0416,\n",
       "                      -0.0096,  0.0421, -0.0077,  0.0551, -0.0357,  0.0015,  0.0426,  0.0038,\n",
       "                       0.0182,  0.0444,  0.0158, -0.0229], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0692, -0.0502,  0.0406, -0.0506, -0.0662, -0.0539, -0.0356,  0.0841,\n",
       "                       -0.0438,  0.0373,  0.0790, -0.0775,  0.0328,  0.0129, -0.0207, -0.0554,\n",
       "                        0.0155,  0.0124,  0.0136,  0.0533, -0.0766, -0.0265,  0.0346, -0.0158,\n",
       "                       -0.0683, -0.0324,  0.0564,  0.0845,  0.0458,  0.0130,  0.0055, -0.0085,\n",
       "                       -0.0098,  0.0189, -0.0619,  0.0379, -0.0709,  0.0308, -0.0192, -0.0043,\n",
       "                        0.0655, -0.0280, -0.0583,  0.0961,  0.0314,  0.0693,  0.0857, -0.0285,\n",
       "                       -0.0525,  0.0259, -0.0266, -0.0406, -0.0553, -0.0461,  0.0551,  0.0382,\n",
       "                        0.0697, -0.0069, -0.0539,  0.0839,  0.0097, -0.0752, -0.0002,  0.0110,\n",
       "                       -0.0384,  0.0376, -0.0842, -0.0615,  0.0236,  0.0347,  0.0823,  0.0402,\n",
       "                       -0.0362,  0.0851, -0.0298,  0.0480, -0.0555,  0.0056, -0.0573,  0.0772,\n",
       "                        0.0841,  0.0391,  0.0370, -0.0276, -0.0028, -0.0577,  0.0724,  0.0172,\n",
       "                       -0.0447,  0.0846,  0.0504,  0.0796, -0.0087, -0.0067, -0.0149, -0.0741,\n",
       "                        0.0111,  0.0143, -0.0245, -0.0752, -0.0283, -0.0031,  0.0405,  0.0466,\n",
       "                        0.0081,  0.0332,  0.0814,  0.0688, -0.0266,  0.0404,  0.0110, -0.0046,\n",
       "                        0.0155, -0.0079,  0.0465,  0.0351, -0.0149, -0.0154, -0.0715,  0.0464,\n",
       "                        0.0467,  0.0939,  0.0803, -0.0826, -0.0016,  0.0563,  0.1007,  0.0556,\n",
       "                       -0.0410,  0.0485,  0.0293,  0.0119],\n",
       "                      [-0.0618,  0.0056, -0.0620,  0.0845,  0.0432,  0.0113, -0.0748,  0.0692,\n",
       "                        0.0232, -0.0305,  0.0586, -0.0467, -0.0538, -0.0582, -0.0160, -0.0384,\n",
       "                       -0.0809,  0.0664,  0.0185,  0.0877,  0.0677,  0.0584,  0.0348, -0.0619,\n",
       "                       -0.0130,  0.0583,  0.0629,  0.0778, -0.0346, -0.0112,  0.0714,  0.0314,\n",
       "                       -0.0778, -0.0590, -0.0406, -0.0290,  0.0470,  0.0131, -0.0265,  0.0015,\n",
       "                       -0.0391,  0.0367, -0.0692, -0.0558, -0.0483, -0.0582, -0.0670,  0.0867,\n",
       "                       -0.0616,  0.0351, -0.0044, -0.0663, -0.0537,  0.0066, -0.0695,  0.0747,\n",
       "                        0.0657,  0.0464, -0.0495, -0.0039,  0.0794, -0.0398, -0.0088,  0.0277,\n",
       "                        0.0012,  0.0060,  0.0775, -0.0687, -0.0041,  0.0770, -0.0791,  0.0809,\n",
       "                        0.0266, -0.0266, -0.0825, -0.0642, -0.0317,  0.0469,  0.0365, -0.0173,\n",
       "                       -0.0669,  0.0589,  0.0162, -0.0305,  0.0608, -0.0599, -0.1014, -0.0794,\n",
       "                       -0.0490, -0.0412, -0.0818, -0.0868,  0.0872,  0.0458,  0.0304, -0.0772,\n",
       "                        0.0496,  0.0027, -0.0558,  0.0107,  0.0064, -0.0784,  0.0078, -0.0596,\n",
       "                        0.0850, -0.0219, -0.0554, -0.0549, -0.0741,  0.0830,  0.0265, -0.0404,\n",
       "                        0.0277,  0.0094, -0.0588,  0.0514, -0.0106, -0.0039, -0.0668, -0.0792,\n",
       "                       -0.0645,  0.0399, -0.0744,  0.0795,  0.0469,  0.0655,  0.0841,  0.0038,\n",
       "                        0.0112, -0.0115,  0.0665, -0.0866],\n",
       "                      [-0.0757, -0.0190,  0.0130, -0.0766, -0.0156, -0.0165,  0.0603, -0.0512,\n",
       "                       -0.0117,  0.0386, -0.0152,  0.0124, -0.0543, -0.0425,  0.0567,  0.0856,\n",
       "                        0.0518, -0.0666, -0.0033,  0.0451, -0.0074, -0.0195, -0.0122, -0.0773,\n",
       "                        0.0831,  0.0093,  0.0575,  0.0692, -0.0703,  0.0337,  0.0764, -0.0517,\n",
       "                        0.0767,  0.0637,  0.0117,  0.0268, -0.0002,  0.0229,  0.0087,  0.0405,\n",
       "                       -0.0665,  0.0639,  0.0770, -0.0885,  0.0575,  0.0399, -0.0615,  0.0335,\n",
       "                        0.0080, -0.0185,  0.0599,  0.0088, -0.0497,  0.0785, -0.0781, -0.0496,\n",
       "                        0.0185,  0.0774, -0.0754, -0.0238,  0.0195, -0.0252,  0.0131, -0.0765,\n",
       "                       -0.0546, -0.0100, -0.0092,  0.0831,  0.0146, -0.0021, -0.0314, -0.0845,\n",
       "                       -0.0050,  0.0614, -0.0082,  0.0456,  0.0344, -0.0495, -0.0661, -0.0229,\n",
       "                       -0.0663, -0.0065, -0.0387,  0.0755,  0.0329,  0.0220,  0.0118, -0.0643,\n",
       "                        0.0163,  0.0397, -0.0532,  0.0115,  0.0282,  0.0598, -0.0680,  0.0219,\n",
       "                        0.0762,  0.0141,  0.0537,  0.0248,  0.0238,  0.0200,  0.0044, -0.0800,\n",
       "                       -0.0681,  0.0459,  0.0241, -0.0764,  0.0316, -0.0732,  0.0836,  0.0284,\n",
       "                       -0.0909,  0.0372, -0.0447, -0.0337, -0.0248,  0.0432, -0.0686, -0.0646,\n",
       "                        0.0373, -0.0861, -0.0365, -0.0261,  0.0645,  0.0429, -0.0756,  0.0155,\n",
       "                        0.0708, -0.0724, -0.0048, -0.0600]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0077, -0.0664,  0.0234], device='cuda:0')),\n",
       "             ('fc_age.weight',\n",
       "              tensor([[ 0.1138,  0.1634,  0.2978,  0.0401, -0.4059,  0.2018],\n",
       "                      [-0.1625, -0.1253, -0.0067,  0.1277, -0.2488, -0.5355],\n",
       "                      [-0.1399,  0.3005, -0.1709,  0.1635,  0.1267, -0.6456]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc_age.bias',\n",
       "              tensor([ 0.0497, -0.1599, -0.0835], device='cuda:0')),\n",
       "             ('fc_sex.weight', tensor([[ 0.4849, -0.0108]], device='cuda:0')),\n",
       "             ('fc_sex.bias', tensor([-0.0975], device='cuda:0')),\n",
       "             ('fc_hw.weight', tensor([[-0.6005, -0.4076]], device='cuda:0')),\n",
       "             ('fc_hw.bias', tensor([0.2382], device='cuda:0')),\n",
       "             ('fc_preg.weight', tensor([[-0.7910,  0.1136]], device='cuda:0')),\n",
       "             ('fc_preg.bias', tensor([0.3936], device='cuda:0')),\n",
       "             ('fc_loc.weight',\n",
       "              tensor([[ 0.0447,  0.4023, -0.2006, -0.2082, -0.2576],\n",
       "                      [ 0.0164, -0.4360, -0.2148,  0.1706, -0.3666]], device='cuda:0')),\n",
       "             ('fc_loc.bias', tensor([-0.0115,  0.2352], device='cuda:0')),\n",
       "             ('cnn.conv0.weight',\n",
       "              tensor([[[[ 0.0068,  0.3053,  0.0397],\n",
       "                        [ 0.0696, -0.0723,  0.1584],\n",
       "                        [ 0.2759, -0.1374, -0.2831]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2014,  0.1924,  0.1419],\n",
       "                        [-0.3449,  0.3060, -0.1456],\n",
       "                        [-0.2661, -0.1483,  0.2249]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2381, -0.1773,  0.1791],\n",
       "                        [ 0.0194,  0.0761,  0.1438],\n",
       "                        [-0.2950,  0.2194, -0.2164]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2960, -0.2998,  0.2117],\n",
       "                        [ 0.2474,  0.0953, -0.1792],\n",
       "                        [-0.0695, -0.2089, -0.1911]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0977,  0.1885, -0.1132],\n",
       "                        [-0.3529, -0.1526, -0.3085],\n",
       "                        [-0.0280,  0.1873, -0.2005]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1084,  0.1036,  0.1707],\n",
       "                        [-0.0075, -0.1279,  0.0264],\n",
       "                        [-0.1110, -0.2058,  0.0646]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2610, -0.2972,  0.3133],\n",
       "                        [ 0.2707, -0.1597, -0.1393],\n",
       "                        [-0.1257, -0.3227, -0.1394]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0740,  0.1464, -0.2372],\n",
       "                        [-0.1350, -0.2279,  0.0600],\n",
       "                        [ 0.1087,  0.0366, -0.0430]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2217,  0.0496, -0.1842],\n",
       "                        [-0.2843, -0.0663,  0.0947],\n",
       "                        [ 0.2625,  0.1141, -0.2476]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2538,  0.2869, -0.2503],\n",
       "                        [ 0.0715, -0.0853, -0.1251],\n",
       "                        [ 0.2545, -0.2795, -0.1589]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1893, -0.0174,  0.3177],\n",
       "                        [ 0.2363,  0.0080,  0.2574],\n",
       "                        [ 0.2650,  0.3283,  0.1179]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0522, -0.0482,  0.3008],\n",
       "                        [ 0.3009, -0.0833, -0.3504],\n",
       "                        [ 0.0898, -0.1115,  0.1104]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1913, -0.0330,  0.1021],\n",
       "                        [ 0.1285, -0.1705,  0.0125],\n",
       "                        [ 0.3110,  0.0618,  0.1616]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0279,  0.1568,  0.2701],\n",
       "                        [ 0.0428, -0.0261, -0.1034],\n",
       "                        [-0.1430,  0.1619, -0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0645, -0.1744, -0.2565],\n",
       "                        [ 0.3706, -0.0915, -0.1425],\n",
       "                        [-0.1100,  0.0643, -0.2674]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1899, -0.3194,  0.2107],\n",
       "                        [ 0.2238,  0.2919,  0.0028],\n",
       "                        [-0.1226, -0.1097, -0.3086]]]], device='cuda:0')),\n",
       "             ('cnn.conv0.bias',\n",
       "              tensor([ 0.0785,  0.0998,  0.1906, -0.0976,  0.1429, -0.1135, -0.2924, -0.0856,\n",
       "                      -0.2638,  0.0947, -0.2566,  0.1008, -0.1670,  0.0988, -0.2070,  0.3252],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.weight',\n",
       "              tensor([1.0089, 0.9916, 1.0105, 1.0140, 0.9622, 0.9792, 0.9629, 0.9707, 1.0144,\n",
       "                      0.9912, 1.0102, 0.9894, 1.0124, 1.0306, 0.9931, 0.9828],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.bias',\n",
       "              tensor([-0.0274, -0.0192, -0.0144,  0.0085, -0.0507,  0.0438, -0.0358, -0.0017,\n",
       "                       0.0144,  0.0152, -0.0109, -0.0114, -0.0043, -0.0372,  0.0183,  0.0165],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.running_mean',\n",
       "              tensor([ 19.8358,   8.9130,  10.5041,  -5.2615, -47.5695, -10.6513, -46.8113,\n",
       "                      -19.9887,  -2.5142, -29.1256,  91.8873,  14.1476,  20.3635,   7.6694,\n",
       "                      -29.4990, -16.7726], device='cuda:0')),\n",
       "             ('cnn.batchnorm0.running_var',\n",
       "              tensor([ 30.4457,  28.7486,  10.7508,  20.7378, 130.8554,  16.1716, 139.9980,\n",
       "                       22.7280,   7.7346,  58.5880, 486.7786,  19.5998,  33.5681,  12.1797,\n",
       "                       74.0296,  25.3953], device='cuda:0')),\n",
       "             ('cnn.batchnorm0.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0')),\n",
       "             ('cnn.conv1.weight',\n",
       "              tensor([[[[ 0.1055,  0.0707,  0.0203],\n",
       "                        [ 0.1055, -0.0415, -0.0071],\n",
       "                        [ 0.0083,  0.0107,  0.0050]],\n",
       "              \n",
       "                       [[-0.0522, -0.0157, -0.1020],\n",
       "                        [ 0.0511, -0.0443, -0.0596],\n",
       "                        [-0.0246, -0.0914, -0.0428]],\n",
       "              \n",
       "                       [[ 0.0623,  0.0052,  0.0347],\n",
       "                        [-0.0621, -0.0706, -0.0232],\n",
       "                        [-0.0073,  0.0132,  0.0685]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0815,  0.0371, -0.0199],\n",
       "                        [-0.0273,  0.0206, -0.0614],\n",
       "                        [ 0.0332, -0.0838, -0.0172]],\n",
       "              \n",
       "                       [[ 0.0070,  0.0592,  0.0959],\n",
       "                        [ 0.0124, -0.0103, -0.0248],\n",
       "                        [-0.0364, -0.0587,  0.0687]],\n",
       "              \n",
       "                       [[ 0.1108, -0.0188, -0.0132],\n",
       "                        [ 0.0474,  0.0215, -0.0703],\n",
       "                        [-0.0014,  0.0103,  0.0673]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0098,  0.0261, -0.0439],\n",
       "                        [ 0.0708,  0.0414,  0.0287],\n",
       "                        [ 0.0011,  0.0299, -0.0908]],\n",
       "              \n",
       "                       [[ 0.0897, -0.0561,  0.0763],\n",
       "                        [ 0.0461, -0.0558, -0.0754],\n",
       "                        [-0.0402,  0.0127, -0.0843]],\n",
       "              \n",
       "                       [[-0.0011, -0.1185, -0.0339],\n",
       "                        [ 0.0165, -0.0450, -0.0580],\n",
       "                        [-0.0220,  0.0142,  0.0251]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0407,  0.0090, -0.0998],\n",
       "                        [-0.0330, -0.1199,  0.0708],\n",
       "                        [-0.0919, -0.0976, -0.0814]],\n",
       "              \n",
       "                       [[ 0.0097, -0.0593,  0.0027],\n",
       "                        [ 0.0708,  0.0571,  0.0168],\n",
       "                        [ 0.0073, -0.0513,  0.0425]],\n",
       "              \n",
       "                       [[-0.0880, -0.0033,  0.0648],\n",
       "                        [-0.0303,  0.0561,  0.0522],\n",
       "                        [ 0.0402, -0.0273, -0.0129]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0399, -0.0178,  0.0618],\n",
       "                        [-0.0432,  0.0038,  0.0512],\n",
       "                        [ 0.0450,  0.0754, -0.0504]],\n",
       "              \n",
       "                       [[ 0.0549,  0.0445,  0.0406],\n",
       "                        [ 0.0816,  0.0275, -0.0448],\n",
       "                        [-0.0156,  0.0666, -0.0316]],\n",
       "              \n",
       "                       [[ 0.0102,  0.0524,  0.0566],\n",
       "                        [ 0.0163, -0.0475, -0.0256],\n",
       "                        [-0.0004, -0.0489,  0.0230]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0462, -0.0429, -0.0457],\n",
       "                        [ 0.0728, -0.0618, -0.0823],\n",
       "                        [ 0.0266,  0.0695,  0.0525]],\n",
       "              \n",
       "                       [[-0.0860, -0.0888, -0.0742],\n",
       "                        [-0.0050, -0.0279,  0.0902],\n",
       "                        [-0.0120, -0.0390, -0.0191]],\n",
       "              \n",
       "                       [[ 0.0830, -0.0308,  0.0789],\n",
       "                        [ 0.0284,  0.0711,  0.0855],\n",
       "                        [ 0.0365, -0.0324,  0.0673]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0599, -0.0422, -0.0700],\n",
       "                        [ 0.0589, -0.0112, -0.0453],\n",
       "                        [-0.0203,  0.0853,  0.1238]],\n",
       "              \n",
       "                       [[-0.0134,  0.0701,  0.0353],\n",
       "                        [-0.0509, -0.0261, -0.0395],\n",
       "                        [-0.0242, -0.0409,  0.0382]],\n",
       "              \n",
       "                       [[ 0.0802,  0.0264,  0.0151],\n",
       "                        [-0.0179, -0.0060,  0.0212],\n",
       "                        [-0.0052,  0.0835,  0.0358]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0101, -0.0326, -0.0186],\n",
       "                        [ 0.0841, -0.0489, -0.0578],\n",
       "                        [-0.0400,  0.0330, -0.0446]],\n",
       "              \n",
       "                       [[ 0.0253, -0.0470, -0.0265],\n",
       "                        [ 0.0557,  0.0450,  0.0700],\n",
       "                        [-0.0046, -0.0454,  0.0634]],\n",
       "              \n",
       "                       [[-0.0321,  0.0235,  0.0301],\n",
       "                        [ 0.0079,  0.0323, -0.0144],\n",
       "                        [-0.0151, -0.0335,  0.0095]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0065,  0.0189, -0.0513],\n",
       "                        [ 0.0251, -0.0814, -0.0547],\n",
       "                        [-0.0594,  0.0339, -0.0177]],\n",
       "              \n",
       "                       [[-0.0853, -0.0160, -0.0624],\n",
       "                        [ 0.0469, -0.0774,  0.0239],\n",
       "                        [ 0.0169, -0.0113, -0.0811]],\n",
       "              \n",
       "                       [[-0.0046, -0.0170, -0.0026],\n",
       "                        [ 0.0068,  0.0633, -0.0853],\n",
       "                        [ 0.0402, -0.0505, -0.0160]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0694,  0.0423, -0.0200],\n",
       "                        [-0.0424, -0.0284, -0.0894],\n",
       "                        [-0.0910, -0.0067, -0.0943]],\n",
       "              \n",
       "                       [[ 0.0577, -0.0734,  0.0799],\n",
       "                        [-0.0361,  0.0497,  0.0437],\n",
       "                        [-0.0618,  0.0346,  0.0853]],\n",
       "              \n",
       "                       [[ 0.0576, -0.0002,  0.0641],\n",
       "                        [ 0.1010,  0.1091, -0.0283],\n",
       "                        [ 0.0681,  0.0661, -0.0373]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0065,  0.0687,  0.0260],\n",
       "                        [-0.0359, -0.0748,  0.0730],\n",
       "                        [-0.0161, -0.0710,  0.0035]],\n",
       "              \n",
       "                       [[-0.0613, -0.0567, -0.0717],\n",
       "                        [-0.0338,  0.0526, -0.1348],\n",
       "                        [ 0.0401,  0.0054, -0.0770]],\n",
       "              \n",
       "                       [[-0.0196, -0.0720, -0.0866],\n",
       "                        [-0.0053, -0.0795, -0.1078],\n",
       "                        [ 0.0003,  0.0096, -0.0703]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0146,  0.0055, -0.0387],\n",
       "                        [ 0.0500,  0.0452, -0.0474],\n",
       "                        [-0.0706,  0.0329, -0.0646]],\n",
       "              \n",
       "                       [[-0.0240, -0.0286,  0.0642],\n",
       "                        [-0.0875, -0.0015,  0.0275],\n",
       "                        [-0.0319,  0.0272,  0.0322]],\n",
       "              \n",
       "                       [[-0.0871, -0.0795,  0.0034],\n",
       "                        [-0.0590, -0.0423, -0.0439],\n",
       "                        [-0.0386,  0.0285, -0.0352]]]], device='cuda:0')),\n",
       "             ('cnn.conv1.bias',\n",
       "              tensor([ 0.0448,  0.0035,  0.0321, -0.0691,  0.0719,  0.0105, -0.0149,  0.0185,\n",
       "                      -0.0176,  0.0813, -0.0890, -0.0139, -0.0546, -0.0515, -0.0604,  0.0706,\n",
       "                       0.0181, -0.0241,  0.0410,  0.0313, -0.0059, -0.0127,  0.0103, -0.0123,\n",
       "                      -0.0468,  0.0763, -0.0261, -0.0327, -0.0534, -0.0804, -0.0093,  0.0358],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.weight',\n",
       "              tensor([1.0227, 0.9714, 1.0212, 1.0281, 0.9917, 0.9434, 0.9907, 1.0251, 1.0056,\n",
       "                      1.0456, 1.0220, 0.9917, 1.0072, 1.0386, 0.9941, 0.9611, 0.9539, 0.9695,\n",
       "                      0.9865, 0.9578, 1.0065, 0.9954, 0.9733, 1.0144, 1.0070, 0.9974, 0.9933,\n",
       "                      0.9724, 0.9471, 0.9930, 0.9407, 0.9884], device='cuda:0')),\n",
       "             ('cnn.batchnorm1.bias',\n",
       "              tensor([-0.0330, -0.0097, -0.0180, -0.0275, -0.0068, -0.0411, -0.0228,  0.0297,\n",
       "                      -0.0144, -0.0220, -0.0189, -0.0062,  0.0064, -0.0182, -0.0347, -0.0335,\n",
       "                      -0.0451, -0.0432, -0.0274, -0.0295, -0.0272, -0.0043, -0.0174,  0.0050,\n",
       "                       0.0082, -0.0602, -0.0227, -0.0305, -0.0291,  0.0047, -0.0489,  0.0078],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.running_mean',\n",
       "              tensor([-0.1687, -0.4559, -0.2988, -0.0258,  0.3089, -0.0242,  0.5997, -0.7923,\n",
       "                      -0.3926, -0.4646, -0.4272, -0.5894, -0.3703, -0.0634,  0.2101,  0.0700,\n",
       "                       0.3191,  0.2739,  0.1491, -0.1736, -0.7493, -1.0221, -0.2195, -0.3004,\n",
       "                      -0.3938, -0.7219,  0.5681,  0.6273, -0.9131,  0.0118, -0.2883, -1.0931],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.running_var',\n",
       "              tensor([0.1155, 0.7880, 0.1530, 0.0552, 0.1440, 0.2585, 0.5031, 0.3386, 0.2376,\n",
       "                      0.1260, 0.0789, 0.1751, 0.1348, 0.0762, 0.1561, 1.2955, 1.2386, 1.1352,\n",
       "                      0.3484, 0.6510, 0.1818, 0.4191, 0.5655, 0.2205, 0.1949, 0.2366, 0.2649,\n",
       "                      1.1435, 0.7266, 0.8215, 2.0220, 0.3308], device='cuda:0')),\n",
       "             ('cnn.batchnorm1.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0')),\n",
       "             ('cnn.conv2.weight',\n",
       "              tensor([[[[ 0.0692, -0.0181,  0.0273],\n",
       "                        [ 0.0316,  0.0193,  0.0329],\n",
       "                        [ 0.0169,  0.0312,  0.0469]],\n",
       "              \n",
       "                       [[ 0.0347, -0.0468,  0.0328],\n",
       "                        [-0.0159,  0.0168,  0.0250],\n",
       "                        [-0.0042, -0.0359, -0.0219]],\n",
       "              \n",
       "                       [[ 0.0558, -0.0601, -0.0372],\n",
       "                        [-0.0519, -0.0491, -0.0264],\n",
       "                        [-0.0695, -0.0621,  0.0005]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0021,  0.0172,  0.0106],\n",
       "                        [-0.0367, -0.0310, -0.0109],\n",
       "                        [ 0.0445, -0.0323,  0.0480]],\n",
       "              \n",
       "                       [[-0.0534,  0.0378,  0.0021],\n",
       "                        [-0.0463,  0.0318,  0.0543],\n",
       "                        [-0.0048,  0.0374,  0.0615]],\n",
       "              \n",
       "                       [[-0.0429, -0.0210,  0.0559],\n",
       "                        [ 0.0005,  0.0417,  0.0344],\n",
       "                        [-0.0486, -0.0365, -0.0177]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0069,  0.0054,  0.0569],\n",
       "                        [-0.0106,  0.0013, -0.0116],\n",
       "                        [ 0.0227, -0.0214, -0.0533]],\n",
       "              \n",
       "                       [[-0.0845,  0.0266, -0.0019],\n",
       "                        [-0.0563, -0.0190, -0.0637],\n",
       "                        [ 0.0071, -0.0017,  0.0142]],\n",
       "              \n",
       "                       [[ 0.0041, -0.0021,  0.0736],\n",
       "                        [-0.0322,  0.0206, -0.0007],\n",
       "                        [-0.0222,  0.0071, -0.0336]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0100,  0.0130, -0.0074],\n",
       "                        [-0.0071,  0.0406,  0.0328],\n",
       "                        [ 0.0161, -0.0664, -0.0089]],\n",
       "              \n",
       "                       [[ 0.0135, -0.0028, -0.0086],\n",
       "                        [ 0.0409,  0.0290,  0.0287],\n",
       "                        [-0.0089,  0.0042,  0.0085]],\n",
       "              \n",
       "                       [[-0.0082,  0.0469, -0.0515],\n",
       "                        [ 0.0245,  0.0273, -0.0327],\n",
       "                        [-0.0016, -0.0235,  0.0543]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0138, -0.0008, -0.0247],\n",
       "                        [-0.0182,  0.0040,  0.0308],\n",
       "                        [ 0.0310, -0.0186, -0.0617]],\n",
       "              \n",
       "                       [[-0.0291, -0.0223, -0.0425],\n",
       "                        [ 0.0482,  0.0333, -0.0591],\n",
       "                        [-0.0049,  0.0298,  0.0364]],\n",
       "              \n",
       "                       [[-0.0163, -0.0446, -0.0098],\n",
       "                        [-0.0254, -0.0175, -0.0133],\n",
       "                        [-0.0440,  0.0403,  0.0607]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0226, -0.0072,  0.0827],\n",
       "                        [-0.0154,  0.0146, -0.0121],\n",
       "                        [-0.0350, -0.0035, -0.0092]],\n",
       "              \n",
       "                       [[-0.0676, -0.0009, -0.0595],\n",
       "                        [-0.0322,  0.0445, -0.0129],\n",
       "                        [-0.0155,  0.0373, -0.0161]],\n",
       "              \n",
       "                       [[-0.0611, -0.0378,  0.0317],\n",
       "                        [-0.0134, -0.0108, -0.0541],\n",
       "                        [-0.0593,  0.0512,  0.0358]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0391,  0.0148,  0.0066],\n",
       "                        [ 0.0468,  0.0021,  0.0043],\n",
       "                        [ 0.0755, -0.0509,  0.0248]],\n",
       "              \n",
       "                       [[-0.0556, -0.0542, -0.0035],\n",
       "                        [ 0.0476, -0.0066,  0.0043],\n",
       "                        [-0.0008,  0.0363,  0.0017]],\n",
       "              \n",
       "                       [[-0.0065,  0.0021, -0.0216],\n",
       "                        [-0.0204, -0.0552, -0.0147],\n",
       "                        [ 0.0093, -0.0328, -0.0624]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0443, -0.0588, -0.0376],\n",
       "                        [ 0.0175, -0.0328, -0.0349],\n",
       "                        [ 0.0527, -0.0129, -0.0566]],\n",
       "              \n",
       "                       [[ 0.0293, -0.0093,  0.0245],\n",
       "                        [ 0.0152,  0.0183,  0.0354],\n",
       "                        [-0.0128, -0.0528, -0.0078]],\n",
       "              \n",
       "                       [[-0.0505, -0.0393,  0.0201],\n",
       "                        [-0.0248,  0.0304, -0.0319],\n",
       "                        [ 0.0009,  0.0508, -0.0371]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0467, -0.0452,  0.0178],\n",
       "                        [-0.0136,  0.0579,  0.0205],\n",
       "                        [-0.0199,  0.0260,  0.0236]],\n",
       "              \n",
       "                       [[ 0.0446,  0.0198, -0.0335],\n",
       "                        [-0.0324,  0.0322, -0.0250],\n",
       "                        [ 0.0122, -0.0493, -0.0206]],\n",
       "              \n",
       "                       [[ 0.0322, -0.0068,  0.0237],\n",
       "                        [-0.0200,  0.0588,  0.0362],\n",
       "                        [ 0.0097,  0.0353, -0.0473]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0009, -0.0465, -0.0024],\n",
       "                        [ 0.0093, -0.0337, -0.0138],\n",
       "                        [-0.0567,  0.0446, -0.0156]],\n",
       "              \n",
       "                       [[-0.0361, -0.0431, -0.0229],\n",
       "                        [-0.0212,  0.0316, -0.0322],\n",
       "                        [ 0.0016,  0.0109, -0.0327]],\n",
       "              \n",
       "                       [[ 0.0086, -0.0496, -0.0281],\n",
       "                        [-0.0131,  0.0243, -0.0312],\n",
       "                        [-0.0447,  0.0200,  0.0778]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0548, -0.0054,  0.0159],\n",
       "                        [ 0.0038,  0.0076,  0.0415],\n",
       "                        [-0.0118, -0.0171,  0.0502]],\n",
       "              \n",
       "                       [[-0.0281,  0.0428,  0.0108],\n",
       "                        [-0.0061,  0.0150, -0.0349],\n",
       "                        [ 0.0128,  0.0509, -0.0013]],\n",
       "              \n",
       "                       [[-0.0892, -0.0214, -0.0581],\n",
       "                        [-0.0602, -0.0745, -0.0624],\n",
       "                        [-0.0518, -0.0654, -0.0798]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0296,  0.0200, -0.0399],\n",
       "                        [ 0.0289, -0.0591,  0.0110],\n",
       "                        [-0.0438, -0.0467,  0.0408]],\n",
       "              \n",
       "                       [[-0.0527, -0.0414,  0.0104],\n",
       "                        [ 0.0150, -0.0549, -0.0322],\n",
       "                        [ 0.0018, -0.0398,  0.0494]],\n",
       "              \n",
       "                       [[ 0.0270, -0.0019, -0.0249],\n",
       "                        [-0.0234, -0.0507, -0.0606],\n",
       "                        [ 0.0143, -0.0140, -0.0607]]]], device='cuda:0')),\n",
       "             ('cnn.conv2.bias',\n",
       "              tensor([-0.0131, -0.0499, -0.0368, -0.0577, -0.0026,  0.0055, -0.0093,  0.0531,\n",
       "                       0.0267,  0.0105,  0.0435, -0.0113, -0.0557, -0.0188, -0.0191,  0.0450,\n",
       "                       0.0089, -0.0137,  0.0529, -0.0160,  0.0348,  0.0012,  0.0442, -0.0480,\n",
       "                       0.0497,  0.0414,  0.0234,  0.0145,  0.0134,  0.0013,  0.0092,  0.0016,\n",
       "                      -0.0528,  0.0606, -0.0449,  0.0260, -0.0110,  0.0094,  0.0571,  0.0544,\n",
       "                       0.0602, -0.0541, -0.0077,  0.0007, -0.0407,  0.0142, -0.0125, -0.0241,\n",
       "                      -0.0035,  0.0545,  0.0542, -0.0005, -0.0332, -0.0259,  0.0542,  0.0344,\n",
       "                      -0.0562, -0.0032,  0.0424, -0.0056,  0.0119,  0.0560, -0.0547, -0.0292],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm2.weight',\n",
       "              tensor([0.9896, 1.0366, 1.0185, 1.0143, 0.9574, 0.9827, 0.9550, 0.9649, 1.0230,\n",
       "                      0.9963, 0.9902, 1.0043, 0.9743, 0.9840, 1.0205, 1.0339, 0.9697, 0.9766,\n",
       "                      0.9852, 1.0274, 0.9812, 0.9590, 0.9813, 1.0285, 1.0291, 0.9678, 0.9693,\n",
       "                      0.9688, 1.0003, 0.9630, 1.0322, 0.9858, 0.9865, 0.9933, 1.0173, 0.9869,\n",
       "                      1.0079, 0.9698, 1.0218, 1.0317, 1.0390, 0.9704, 0.9675, 0.9486, 0.9915,\n",
       "                      1.0377, 0.9588, 0.9971, 1.0090, 1.0277, 1.0273, 0.9773, 0.9646, 0.9584,\n",
       "                      0.9478, 1.0154, 0.9781, 0.9970, 1.0130, 1.0024, 1.0272, 0.9963, 0.9964,\n",
       "                      0.9674], device='cuda:0')),\n",
       "             ('cnn.batchnorm2.bias',\n",
       "              tensor([-0.0254, -0.0177, -0.0089, -0.0055, -0.0381, -0.0089, -0.0146, -0.0265,\n",
       "                      -0.0070, -0.0136, -0.0179, -0.0179, -0.0173, -0.0399, -0.0241, -0.0103,\n",
       "                      -0.0469, -0.0137, -0.0111, -0.0495, -0.0428, -0.0554, -0.0270, -0.0160,\n",
       "                       0.0170, -0.0347, -0.0191, -0.0383, -0.0092, -0.0582, -0.0100, -0.0242,\n",
       "                      -0.0271, -0.0332, -0.0015, -0.0315, -0.0219, -0.0490, -0.0504, -0.0217,\n",
       "                      -0.0143, -0.0484, -0.0071, -0.0415, -0.0375, -0.0194, -0.0315, -0.0088,\n",
       "                      -0.0237, -0.0427, -0.0167, -0.0416, -0.0584, -0.0382, -0.0326,  0.0003,\n",
       "                      -0.0447, -0.0067, -0.0019, -0.0164, -0.0002, -0.0346, -0.0087, -0.0349],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm2.running_mean',\n",
       "              tensor([-1.1495, -0.8616, -0.4910,  0.1242, -0.9524, -0.1095, -1.3671, -1.5212,\n",
       "                      -1.1510, -1.2958,  0.6088,  0.6316, -0.1808, -0.9518, -1.3638, -0.5497,\n",
       "                       0.8922, -0.0149, -0.5610, -0.8927,  0.3374,  1.4316,  0.6409, -0.5551,\n",
       "                       0.0619,  0.1172, -0.6587, -0.2025, -1.5804,  0.0618,  0.1349,  0.3928,\n",
       "                      -0.5307, -0.1448, -0.7083, -0.4427, -0.4611, -0.3939,  0.2850, -0.7703,\n",
       "                      -0.7816,  0.1108, -0.2872, -0.7171,  1.3092, -1.0234, -0.2094, -0.3682,\n",
       "                      -0.6040, -0.0878, -0.3319,  0.3455,  0.0990, -0.1877, -0.8779, -0.1652,\n",
       "                       0.1150,  0.2678, -0.4778,  0.0739, -0.1025, -0.8174, -0.0661, -0.9267],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm2.running_var',\n",
       "              tensor([0.1943, 0.2106, 0.2350, 0.2375, 0.2250, 1.2615, 0.9770, 0.4842, 0.5676,\n",
       "                      0.3955, 0.8555, 0.3301, 0.2371, 0.3091, 0.2506, 0.3853, 0.3157, 0.6922,\n",
       "                      1.2191, 0.3151, 0.2712, 0.6673, 0.6700, 0.2078, 0.3963, 0.8815, 0.3281,\n",
       "                      0.3123, 0.9051, 0.2422, 0.3895, 0.3101, 0.2072, 0.2445, 0.2533, 0.3047,\n",
       "                      0.2399, 0.4902, 0.6710, 0.1649, 0.3387, 0.2398, 0.6634, 0.4683, 0.2851,\n",
       "                      0.4903, 0.3759, 0.6473, 0.2928, 0.2855, 0.3391, 0.3871, 0.3742, 0.7831,\n",
       "                      0.5880, 0.2615, 0.9987, 1.3486, 0.2077, 0.1795, 0.2132, 0.1670, 0.3372,\n",
       "                      0.5220], device='cuda:0')),\n",
       "             ('cnn.batchnorm2.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0')),\n",
       "             ('cnn.conv3.weight',\n",
       "              tensor([[[[-2.9211e-02, -2.8197e-02, -2.4120e-02],\n",
       "                        [ 1.1456e-02, -2.1334e-02, -1.8976e-02],\n",
       "                        [-1.6761e-02,  4.7793e-02,  2.9687e-02]],\n",
       "              \n",
       "                       [[ 3.0969e-02,  2.1173e-02,  2.1255e-02],\n",
       "                        [-2.3113e-02, -5.2328e-02, -5.0055e-02],\n",
       "                        [ 2.7456e-02,  6.4997e-04, -4.9700e-02]],\n",
       "              \n",
       "                       [[-3.1753e-02, -5.4583e-03,  2.6114e-02],\n",
       "                        [ 3.8948e-03, -3.6982e-02,  2.7292e-02],\n",
       "                        [-2.9987e-02, -1.1513e-02,  1.2378e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.7506e-02, -3.6475e-02,  6.1145e-03],\n",
       "                        [ 4.8766e-02, -1.0065e-02, -9.2419e-03],\n",
       "                        [-2.0899e-02,  1.8643e-02,  1.3897e-02]],\n",
       "              \n",
       "                       [[ 3.3069e-02, -1.2488e-02,  5.9375e-02],\n",
       "                        [-3.2224e-02, -1.8710e-02, -6.3546e-03],\n",
       "                        [ 1.4623e-02, -3.0988e-02, -2.6174e-02]],\n",
       "              \n",
       "                       [[-1.9927e-02, -6.3164e-03, -2.3805e-02],\n",
       "                        [ 2.4408e-02, -8.5129e-03, -1.1565e-02],\n",
       "                        [-3.3692e-03, -2.3887e-02, -9.4710e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.7463e-02,  4.5479e-02,  4.0767e-02],\n",
       "                        [ 9.8285e-03,  4.6734e-02,  9.7847e-03],\n",
       "                        [-1.2515e-02,  3.8632e-02,  1.9959e-02]],\n",
       "              \n",
       "                       [[-1.4807e-02, -1.4845e-02, -1.1206e-02],\n",
       "                        [ 3.5054e-02, -2.9459e-02,  2.0523e-02],\n",
       "                        [ 4.4234e-02,  1.7200e-02, -3.8128e-02]],\n",
       "              \n",
       "                       [[-4.1016e-02,  3.0874e-02,  5.1156e-02],\n",
       "                        [-4.0101e-02,  3.1995e-02,  4.0549e-02],\n",
       "                        [-7.1167e-03,  3.7688e-02,  4.6068e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.8310e-02, -7.1243e-03,  6.8163e-04],\n",
       "                        [ 4.3582e-02,  6.3268e-02,  1.7425e-02],\n",
       "                        [ 2.2538e-02,  3.7365e-02, -4.5292e-03]],\n",
       "              \n",
       "                       [[-3.9597e-02,  8.8534e-03, -9.6758e-03],\n",
       "                        [-4.1325e-02,  2.0267e-02,  2.1486e-02],\n",
       "                        [-1.5804e-02, -1.2534e-02,  5.1816e-03]],\n",
       "              \n",
       "                       [[-1.2240e-02,  3.5322e-02,  2.6778e-02],\n",
       "                        [ 5.3973e-03,  3.3209e-02,  5.6865e-03],\n",
       "                        [-1.5731e-02,  4.9268e-02, -1.9490e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.2473e-02, -1.3676e-02, -1.5755e-02],\n",
       "                        [-3.9177e-03, -4.1173e-02, -3.3010e-03],\n",
       "                        [ 3.5414e-02, -1.7938e-02, -3.1988e-02]],\n",
       "              \n",
       "                       [[ 3.8645e-03, -4.9898e-02,  1.7152e-03],\n",
       "                        [-8.8799e-04, -1.0124e-02, -3.7217e-02],\n",
       "                        [-2.7277e-02,  3.4493e-02, -4.3994e-02]],\n",
       "              \n",
       "                       [[ 1.3589e-02, -5.3432e-02,  2.3206e-02],\n",
       "                        [ 7.7212e-03, -5.0540e-02, -2.1390e-04],\n",
       "                        [-3.6922e-02,  1.9626e-03, -1.7869e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.1675e-03,  5.9006e-03,  1.8689e-02],\n",
       "                        [ 3.2940e-02, -2.6006e-02, -1.9381e-02],\n",
       "                        [ 6.9461e-02, -1.2696e-02,  2.2308e-02]],\n",
       "              \n",
       "                       [[-1.8042e-02, -3.2360e-02, -5.3404e-02],\n",
       "                        [-2.2508e-02,  5.0661e-04, -5.3034e-03],\n",
       "                        [ 2.6854e-02,  3.0327e-02, -2.2036e-02]],\n",
       "              \n",
       "                       [[-1.1261e-02,  1.9171e-02,  3.2414e-03],\n",
       "                        [ 2.2906e-02,  6.5719e-05,  2.0006e-02],\n",
       "                        [-1.5109e-02, -3.8161e-03,  1.3572e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 2.3911e-03,  3.1574e-02,  3.1049e-02],\n",
       "                        [ 8.0826e-03, -2.0030e-02, -2.6158e-02],\n",
       "                        [ 2.5413e-02,  3.9400e-02,  2.0887e-02]],\n",
       "              \n",
       "                       [[ 4.0250e-02, -3.5402e-02, -2.0755e-03],\n",
       "                        [ 3.6836e-02, -2.7641e-02,  1.4330e-02],\n",
       "                        [ 9.4575e-03,  1.6833e-02, -1.1070e-02]],\n",
       "              \n",
       "                       [[ 1.3764e-02,  2.8261e-02,  3.4537e-02],\n",
       "                        [ 1.2088e-02, -2.0515e-02, -3.5119e-02],\n",
       "                        [ 4.3005e-02, -3.6833e-02, -2.9047e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 1.2025e-02,  2.4138e-03,  4.6337e-03],\n",
       "                        [-1.0074e-02, -6.7159e-03,  3.1036e-02],\n",
       "                        [ 3.8040e-03, -2.6746e-02, -6.6683e-03]],\n",
       "              \n",
       "                       [[-1.3097e-02,  3.2867e-02,  6.8022e-03],\n",
       "                        [ 1.5938e-02,  9.6032e-03, -3.7337e-02],\n",
       "                        [ 1.2002e-02,  1.3404e-02,  1.4456e-02]],\n",
       "              \n",
       "                       [[-2.4894e-03, -3.6492e-02, -1.5106e-02],\n",
       "                        [-3.5717e-02, -2.5689e-02, -7.5873e-04],\n",
       "                        [ 3.0775e-02,  3.1818e-03, -1.4686e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2331e-02,  1.2098e-02, -1.5567e-02],\n",
       "                        [-4.1920e-02, -4.1088e-02,  8.0163e-03],\n",
       "                        [-9.6078e-03, -1.0976e-03, -2.7264e-02]],\n",
       "              \n",
       "                       [[-6.1655e-04,  1.5615e-02,  5.0292e-02],\n",
       "                        [ 1.8797e-03, -3.2815e-03,  1.4235e-02],\n",
       "                        [ 2.9733e-02, -1.0019e-03,  3.2340e-02]],\n",
       "              \n",
       "                       [[ 1.7696e-02, -2.3013e-03, -1.4184e-02],\n",
       "                        [ 8.1902e-03, -3.5872e-02, -3.1203e-02],\n",
       "                        [ 3.3925e-02, -1.0915e-02, -3.7666e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.2951e-02, -1.0747e-02, -1.3370e-02],\n",
       "                        [-1.8805e-02, -4.9337e-02,  3.0544e-02],\n",
       "                        [ 1.6355e-02,  8.5610e-03, -1.3335e-02]],\n",
       "              \n",
       "                       [[-9.7903e-03, -1.3382e-02, -5.1943e-02],\n",
       "                        [ 3.3462e-02, -5.6597e-02, -3.1304e-02],\n",
       "                        [ 1.0540e-02, -5.6309e-03, -4.6696e-02]],\n",
       "              \n",
       "                       [[ 1.4405e-03, -3.6138e-02, -7.5914e-03],\n",
       "                        [ 7.3278e-03, -9.1353e-03,  2.7790e-02],\n",
       "                        [ 4.7876e-02, -9.9550e-03,  2.1224e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.9214e-02,  1.1570e-02, -2.2452e-03],\n",
       "                        [ 3.3193e-02, -4.1420e-02, -2.3378e-02],\n",
       "                        [-2.3899e-02, -4.2297e-02,  1.6689e-03]],\n",
       "              \n",
       "                       [[-7.3120e-03,  4.1326e-02, -5.1588e-02],\n",
       "                        [-3.5763e-02, -2.2644e-03, -8.7298e-03],\n",
       "                        [-3.5203e-02,  4.7057e-02, -2.1706e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02, -1.5508e-02, -2.0608e-02],\n",
       "                        [-3.2433e-02, -3.7652e-02,  2.5761e-02],\n",
       "                        [ 4.1814e-03,  1.0683e-02,  3.3601e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.2697e-02,  1.1941e-02,  1.4156e-02],\n",
       "                        [ 9.0772e-03, -4.5716e-02,  2.7596e-02],\n",
       "                        [-3.2912e-02, -3.3264e-02, -2.6608e-02]],\n",
       "              \n",
       "                       [[ 3.7853e-02, -1.2556e-02,  7.0450e-03],\n",
       "                        [-2.1975e-02, -3.8439e-02, -2.2498e-02],\n",
       "                        [ 3.1055e-02, -2.3426e-02, -4.4915e-02]],\n",
       "              \n",
       "                       [[-4.4457e-02, -1.2776e-02,  1.4355e-02],\n",
       "                        [-1.0413e-02, -2.4554e-02,  8.8741e-03],\n",
       "                        [ 2.8038e-02,  5.6790e-02, -2.9296e-02]]]], device='cuda:0')),\n",
       "             ('cnn.conv3.bias',\n",
       "              tensor([ 0.0316, -0.0186,  0.0085, -0.0116,  0.0300, -0.0355, -0.0376, -0.0402,\n",
       "                      -0.0344,  0.0147,  0.0270, -0.0180,  0.0028, -0.0180,  0.0315,  0.0118,\n",
       "                       0.0153, -0.0026,  0.0300, -0.0206, -0.0379, -0.0288, -0.0039,  0.0039,\n",
       "                      -0.0383, -0.0165, -0.0116, -0.0365,  0.0256,  0.0271,  0.0369, -0.0380,\n",
       "                      -0.0382, -0.0076, -0.0234,  0.0314,  0.0289,  0.0003, -0.0187, -0.0039,\n",
       "                      -0.0195,  0.0349,  0.0066, -0.0409, -0.0057, -0.0385,  0.0187, -0.0159,\n",
       "                       0.0027,  0.0185,  0.0026,  0.0312,  0.0201, -0.0083,  0.0316,  0.0256,\n",
       "                       0.0058,  0.0080, -0.0403,  0.0050, -0.0044, -0.0007, -0.0150, -0.0126,\n",
       "                       0.0199,  0.0289,  0.0025, -0.0170, -0.0061,  0.0182,  0.0293, -0.0118,\n",
       "                       0.0050, -0.0403,  0.0211,  0.0039, -0.0380, -0.0237, -0.0172,  0.0005,\n",
       "                       0.0163, -0.0176,  0.0298,  0.0292,  0.0266, -0.0053,  0.0191, -0.0394,\n",
       "                      -0.0423,  0.0257,  0.0097, -0.0120, -0.0353,  0.0120,  0.0302, -0.0166,\n",
       "                       0.0118,  0.0368, -0.0232,  0.0016,  0.0349, -0.0044,  0.0091, -0.0349,\n",
       "                       0.0407,  0.0323,  0.0116, -0.0240,  0.0106, -0.0358,  0.0110,  0.0068,\n",
       "                       0.0013, -0.0026,  0.0340,  0.0276,  0.0123, -0.0390,  0.0323, -0.0261,\n",
       "                       0.0348,  0.0391,  0.0044,  0.0200,  0.0307,  0.0100,  0.0322,  0.0053],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm3.weight',\n",
       "              tensor([1.0230, 1.0334, 0.9714, 0.9805, 0.9952, 0.9942, 0.9872, 0.9614, 1.0223,\n",
       "                      0.9801, 1.0169, 0.9650, 0.9965, 1.0083, 0.9999, 0.9771, 1.0003, 1.0041,\n",
       "                      1.0188, 0.9864, 0.9931, 0.9641, 0.9898, 1.0153, 0.9678, 0.9961, 1.0026,\n",
       "                      1.0001, 0.9881, 0.9723, 1.0165, 1.0023, 0.9834, 1.0029, 1.0276, 0.9817,\n",
       "                      0.9704, 0.9680, 1.0362, 0.9840, 0.9795, 0.9882, 0.9921, 0.9689, 0.9836,\n",
       "                      1.0450, 0.9988, 1.0122, 1.0184, 0.9916, 1.0062, 0.9803, 0.9900, 0.9852,\n",
       "                      1.0033, 1.0170, 0.9860, 0.9912, 0.9735, 1.0269, 1.0382, 0.9937, 0.9751,\n",
       "                      0.9922, 0.9918, 0.9820, 0.9727, 1.0166, 1.0200, 1.0311, 0.9983, 0.9889,\n",
       "                      1.0016, 0.9916, 0.9795, 1.0363, 1.0098, 1.0054, 0.9596, 0.9968, 0.9988,\n",
       "                      0.9662, 0.9819, 0.9710, 1.0383, 0.9709, 0.9799, 1.0345, 1.0288, 0.9947,\n",
       "                      0.9885, 1.0073, 0.9977, 0.9717, 1.0065, 0.9972, 0.9717, 1.0264, 1.0357,\n",
       "                      1.0027, 0.9816, 0.9855, 0.9689, 0.9764, 0.9684, 0.9797, 0.9649, 1.0113,\n",
       "                      0.9906, 0.9803, 0.9935, 1.0300, 0.9628, 0.9876, 1.0222, 0.9827, 1.0041,\n",
       "                      0.9863, 0.9939, 0.9865, 1.0537, 1.0217, 1.0217, 0.9906, 0.9519, 0.9939,\n",
       "                      0.9804, 1.0292], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.bias',\n",
       "              tensor([-7.5856e-02, -1.4575e-02, -1.9696e-02, -3.3799e-02,  4.5358e-03,\n",
       "                      -4.9813e-02, -5.2498e-02, -9.6549e-03, -2.6169e-02, -3.7770e-02,\n",
       "                      -2.5330e-02, -3.4456e-02, -3.6715e-02, -2.4389e-02, -3.5355e-02,\n",
       "                      -3.2934e-02, -4.8489e-02, -3.5353e-02, -1.8527e-02, -1.6506e-02,\n",
       "                       1.2317e-02, -5.5032e-02, -3.1733e-02, -1.0236e-02, -4.1593e-02,\n",
       "                      -3.0199e-02, -3.7692e-02, -2.2893e-02, -3.0207e-02, -1.9619e-02,\n",
       "                      -2.2171e-02, -4.9414e-03, -5.2274e-03, -2.8876e-02, -7.7264e-02,\n",
       "                      -1.0446e-02, -4.5663e-02, -3.4034e-02, -1.6897e-02, -3.2604e-02,\n",
       "                      -3.6252e-02, -3.5278e-02, -5.5721e-03, -3.9588e-02, -4.4808e-03,\n",
       "                      -3.0447e-02, -3.1155e-02, -3.5908e-02, -3.3682e-02, -1.5031e-02,\n",
       "                      -2.7739e-02, -3.5338e-02, -2.8485e-02, -3.2398e-02, -2.8382e-02,\n",
       "                      -3.6171e-02, -2.0714e-02, -1.8378e-02,  5.5133e-03, -4.4989e-02,\n",
       "                      -1.7624e-02, -2.0018e-02, -3.5392e-02, -4.5919e-02, -2.4337e-02,\n",
       "                      -2.9571e-02, -4.2508e-02, -2.0524e-02, -1.3786e-05, -3.9475e-02,\n",
       "                      -2.6859e-02, -4.1839e-02, -4.2169e-02, -4.2201e-02, -3.6559e-02,\n",
       "                      -2.0046e-02, -4.3507e-02, -3.0393e-02, -2.7490e-02, -2.9202e-02,\n",
       "                      -2.5568e-02, -6.9243e-03, -3.5898e-02, -8.2055e-03, -2.0057e-02,\n",
       "                      -5.0520e-03, -2.2345e-02, -1.2570e-02, -5.4582e-02, -2.9853e-02,\n",
       "                      -2.7145e-02, -5.1628e-02, -3.8064e-03, -1.9523e-02, -2.5189e-02,\n",
       "                      -1.8608e-02,  1.9494e-03, -6.1594e-02,  7.2139e-03, -2.7501e-02,\n",
       "                      -3.6024e-02, -4.2725e-02, -2.4651e-03, -4.0231e-02, -1.2394e-02,\n",
       "                      -4.8333e-02, -3.1261e-02, -2.0562e-02, -1.9583e-02,  1.2601e-02,\n",
       "                      -4.5344e-02,  1.2180e-02, -1.4892e-02, -5.5866e-02, -1.3063e-02,\n",
       "                      -2.7467e-02, -3.4212e-02, -2.7500e-02,  1.2501e-02, -2.8551e-02,\n",
       "                      -2.5404e-02, -1.7609e-02, -2.6561e-02, -4.2884e-02, -4.0427e-02,\n",
       "                      -2.0871e-02,  5.3414e-03, -3.5176e-02], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.running_mean',\n",
       "              tensor([-0.3899, -0.4091, -0.3080,  0.0181,  0.5849, -0.5677, -0.6275, -1.6156,\n",
       "                      -0.9102, -0.9763, -0.1431,  0.4876, -1.1298, -1.0874, -0.1851,  0.5714,\n",
       "                      -0.4571,  0.0321,  0.0290, -0.2235, -1.7194,  0.4238, -0.2519,  0.8699,\n",
       "                       0.0394, -0.4841, -0.0043, -1.1575, -0.4472, -1.1875, -0.8957, -1.4945,\n",
       "                      -0.0675, -0.9492,  0.5281,  0.4173, -0.5333, -0.3719,  0.4824, -0.8361,\n",
       "                      -0.7281, -0.0342, -0.9983, -0.5750, -0.6743, -0.9184, -1.1991, -0.4124,\n",
       "                      -0.2795, -0.9279, -0.6375, -0.2164, -0.8009,  0.0341, -0.1211, -0.2524,\n",
       "                      -0.4280, -0.9946, -2.3655, -0.4329, -0.1701, -0.5740,  0.7765, -0.3166,\n",
       "                      -0.5115, -0.6188, -0.5789, -1.0533, -0.3472, -0.2524,  1.6438,  0.5504,\n",
       "                      -0.6821, -0.4273, -0.1040, -0.1644, -1.1290, -0.1004, -0.2890, -0.3187,\n",
       "                       0.1238, -1.6552, -0.4369, -1.9497, -0.6722, -2.0945, -2.1259, -0.8498,\n",
       "                      -0.2662, -0.4801, -1.6787, -0.3426, -0.5642, -0.5209, -1.3712,  2.6516,\n",
       "                      -2.4333, -0.7257, -0.1637, -0.9479,  0.3769,  0.4814, -2.6988,  1.2852,\n",
       "                      -0.8344,  0.0834, -1.0822, -0.6429, -0.2393, -2.1145, -0.0243, -0.7244,\n",
       "                      -0.8407,  0.9144, -0.8068, -0.9598, -0.0604,  0.1194, -1.2958, -0.5143,\n",
       "                      -0.6080, -1.4539, -0.8528, -0.0106, -0.6339,  1.4402, -1.5571, -0.8618],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm3.running_var',\n",
       "              tensor([0.7111, 0.4189, 0.3070, 1.6164, 0.7383, 0.3550, 0.6040, 0.6137, 0.6610,\n",
       "                      0.2857, 0.4496, 0.2329, 0.4844, 0.3846, 1.1009, 0.8690, 0.3755, 0.6190,\n",
       "                      0.6009, 0.7685, 2.2365, 0.3199, 1.8534, 0.4916, 0.5424, 0.5399, 0.3235,\n",
       "                      0.8229, 0.4157, 2.5585, 0.5874, 0.5297, 0.9699, 0.7210, 0.4958, 0.8249,\n",
       "                      0.9187, 0.6556, 0.6394, 0.3988, 0.8031, 0.5589, 0.4113, 0.8615, 1.5919,\n",
       "                      0.7278, 1.0006, 1.2097, 1.2903, 0.4068, 0.4928, 1.1087, 1.1803, 0.7354,\n",
       "                      0.4607, 0.9417, 0.2490, 0.3217, 2.4033, 0.3111, 0.3396, 0.7707, 0.5092,\n",
       "                      0.7554, 0.3199, 1.0090, 0.9702, 0.3056, 1.3917, 0.4594, 1.5574, 0.4752,\n",
       "                      0.5501, 0.7125, 0.7138, 0.4213, 0.8067, 0.9024, 0.8181, 0.3662, 0.6661,\n",
       "                      1.3910, 0.2736, 1.5208, 0.3265, 1.3255, 0.4319, 0.4326, 1.7697, 0.9136,\n",
       "                      0.3774, 0.6159, 1.1627, 1.2077, 0.2862, 1.2057, 2.5695, 0.5844, 0.4209,\n",
       "                      1.7172, 0.5699, 0.3685, 2.2492, 1.1735, 2.1027, 0.1899, 1.0143, 0.6651,\n",
       "                      0.4434, 2.0218, 1.1186, 1.3901, 0.9066, 0.5870, 1.2540, 0.3222, 2.0995,\n",
       "                      1.6529, 1.3056, 0.5621, 0.3090, 0.3561, 0.6929, 0.7324, 0.3045, 1.2378,\n",
       "                      2.1182, 1.0028], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0')),\n",
       "             ('cnn.conv4.weight',\n",
       "              tensor([[[[-1.3042e-02, -4.7314e-02, -8.9947e-04],\n",
       "                        [-1.9954e-02,  2.3123e-03, -9.3867e-03],\n",
       "                        [ 1.6382e-02, -1.0445e-03,  6.0696e-03]],\n",
       "              \n",
       "                       [[ 3.1836e-02,  2.9345e-02,  1.7593e-02],\n",
       "                        [ 3.0390e-02,  3.0118e-02,  1.1764e-02],\n",
       "                        [-1.3742e-03,  1.6833e-02,  8.1866e-03]],\n",
       "              \n",
       "                       [[ 1.0265e-02,  2.3122e-02, -1.8851e-02],\n",
       "                        [ 4.1385e-03,  4.3484e-04,  2.0947e-03],\n",
       "                        [ 5.2653e-03,  2.6572e-02, -3.4068e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.5583e-02,  1.1621e-02,  7.5265e-03],\n",
       "                        [ 1.5590e-02, -3.2643e-02, -1.8470e-02],\n",
       "                        [-1.7279e-02,  1.3755e-02, -6.3761e-03]],\n",
       "              \n",
       "                       [[ 7.3182e-03, -1.7677e-02,  6.3280e-03],\n",
       "                        [ 5.8067e-03, -1.1913e-02,  1.6936e-02],\n",
       "                        [-1.0764e-02, -8.6530e-03, -6.1633e-03]],\n",
       "              \n",
       "                       [[ 3.1468e-02,  2.5997e-02,  3.2345e-02],\n",
       "                        [ 1.2960e-02,  2.0869e-03,  4.5825e-02],\n",
       "                        [ 1.5101e-02,  2.2894e-02,  4.0029e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.1906e-04, -3.5171e-03, -1.3912e-02],\n",
       "                        [-8.1136e-03, -2.6743e-02,  1.0642e-02],\n",
       "                        [ 3.2546e-02,  1.8039e-02, -3.2957e-02]],\n",
       "              \n",
       "                       [[-1.6691e-02,  2.1285e-02,  1.9860e-02],\n",
       "                        [-3.0119e-02, -7.6808e-03, -2.5022e-03],\n",
       "                        [ 1.0238e-02,  1.6205e-03, -4.1617e-03]],\n",
       "              \n",
       "                       [[-8.4214e-03, -2.6067e-03,  5.6833e-03],\n",
       "                        [ 1.1679e-03,  3.0025e-02,  4.6859e-02],\n",
       "                        [ 1.7946e-02, -2.0977e-02,  1.3945e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-8.3077e-03,  4.8147e-03, -2.5945e-02],\n",
       "                        [ 4.9883e-03, -2.5558e-02, -3.2795e-02],\n",
       "                        [-1.6058e-02, -3.3247e-02, -2.5121e-02]],\n",
       "              \n",
       "                       [[ 1.1558e-02,  9.5029e-03,  1.3020e-02],\n",
       "                        [-1.2616e-02, -9.4528e-03,  3.5507e-02],\n",
       "                        [ 3.0948e-02, -2.1331e-02,  3.3675e-02]],\n",
       "              \n",
       "                       [[-2.6674e-02, -3.1676e-05, -1.2204e-02],\n",
       "                        [-3.3353e-02,  1.6110e-02, -1.5226e-02],\n",
       "                        [ 2.1081e-03, -1.1385e-03, -8.1428e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.5971e-03, -2.9344e-02, -6.9350e-02],\n",
       "                        [-2.9798e-02, -1.6558e-02, -2.1590e-02],\n",
       "                        [-5.1325e-02, -1.8170e-02, -4.9732e-02]],\n",
       "              \n",
       "                       [[ 1.0400e-02,  2.4229e-03, -1.9061e-02],\n",
       "                        [-9.7955e-03,  1.1354e-02, -7.3169e-03],\n",
       "                        [ 1.9210e-02,  7.4570e-03,  1.0339e-03]],\n",
       "              \n",
       "                       [[ 1.5003e-02,  2.4360e-03, -4.7275e-03],\n",
       "                        [ 2.2005e-02,  1.8897e-02, -2.1599e-02],\n",
       "                        [-8.8603e-03, -3.0822e-02,  4.1667e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 9.3332e-03, -2.5445e-02,  7.7792e-03],\n",
       "                        [ 1.6253e-02,  2.8134e-04, -5.6794e-03],\n",
       "                        [ 1.8561e-02, -2.4139e-02,  1.1503e-02]],\n",
       "              \n",
       "                       [[ 2.4050e-02, -3.4156e-02,  5.8491e-03],\n",
       "                        [-2.0279e-02,  5.5977e-03, -2.4305e-03],\n",
       "                        [ 3.2069e-02,  4.8343e-03, -1.2624e-02]],\n",
       "              \n",
       "                       [[ 3.8287e-02, -1.5396e-02,  4.0641e-02],\n",
       "                        [ 2.5292e-02, -2.5206e-03,  4.5229e-02],\n",
       "                        [ 1.8605e-02,  4.4078e-02,  1.1180e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-3.3218e-02, -3.1650e-02, -1.5100e-02],\n",
       "                        [ 1.5966e-02, -2.8366e-02,  3.2763e-02],\n",
       "                        [ 1.1017e-02,  1.0746e-02,  1.7646e-02]],\n",
       "              \n",
       "                       [[ 2.2926e-02,  9.1003e-03,  6.6475e-02],\n",
       "                        [-1.1841e-02,  9.5510e-03,  1.6882e-02],\n",
       "                        [ 1.9237e-02,  4.5605e-03,  2.7834e-02]],\n",
       "              \n",
       "                       [[-2.8122e-02, -8.4933e-03,  2.2174e-02],\n",
       "                        [-3.9451e-02, -2.8059e-02, -3.2113e-02],\n",
       "                        [ 3.0517e-03, -6.3762e-03,  2.4552e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.0316e-02,  2.6532e-02,  2.3133e-02],\n",
       "                        [ 1.5367e-02, -2.6892e-02,  9.2424e-03],\n",
       "                        [-2.2236e-03, -8.8846e-03,  7.1603e-03]],\n",
       "              \n",
       "                       [[ 6.7096e-03, -1.7540e-02,  3.3973e-02],\n",
       "                        [ 1.7529e-02, -1.6263e-02,  1.7757e-02],\n",
       "                        [-9.2379e-03,  2.2198e-02,  2.8943e-02]],\n",
       "              \n",
       "                       [[ 2.6005e-03, -1.1893e-02, -8.4361e-03],\n",
       "                        [-1.7639e-02, -2.4768e-02, -1.0919e-03],\n",
       "                        [ 1.5404e-02,  4.2980e-03, -1.7843e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.9366e-02, -2.5489e-02, -1.3151e-02],\n",
       "                        [-3.9730e-02, -3.0497e-02,  1.4374e-02],\n",
       "                        [ 7.3175e-03, -3.8151e-03,  2.5711e-02]],\n",
       "              \n",
       "                       [[-1.6131e-02, -1.6088e-02,  9.8039e-03],\n",
       "                        [ 6.0349e-03,  1.9299e-02,  5.3893e-03],\n",
       "                        [-3.1577e-02, -2.3532e-02,  2.1787e-02]],\n",
       "              \n",
       "                       [[-8.4418e-03,  2.8468e-02, -3.7534e-03],\n",
       "                        [ 2.8860e-02, -1.8725e-03, -3.5685e-02],\n",
       "                        [ 1.6562e-02, -1.8627e-02, -9.3722e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-7.4466e-03, -1.9100e-02, -1.2270e-02],\n",
       "                        [-1.8106e-02, -1.9322e-02,  3.9091e-02],\n",
       "                        [-2.5515e-02,  5.4745e-03,  3.3218e-02]],\n",
       "              \n",
       "                       [[ 1.3685e-03,  1.9370e-02, -3.0956e-02],\n",
       "                        [-8.9142e-03,  1.3811e-02,  6.1967e-03],\n",
       "                        [-4.7135e-03, -1.0429e-02, -2.4251e-02]],\n",
       "              \n",
       "                       [[ 3.0329e-02,  2.0375e-02, -2.0744e-02],\n",
       "                        [ 3.6042e-02, -1.8044e-02,  2.0766e-03],\n",
       "                        [ 4.4832e-03, -1.9960e-02,  2.1386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.4812e-02,  9.7211e-03, -1.8978e-03],\n",
       "                        [ 3.9579e-02,  4.1787e-03, -6.1072e-03],\n",
       "                        [ 2.2106e-02,  2.5041e-03, -2.9706e-02]],\n",
       "              \n",
       "                       [[ 2.8615e-03, -3.1132e-02,  6.0076e-03],\n",
       "                        [-3.5726e-02, -2.4956e-03, -1.8306e-02],\n",
       "                        [-1.1704e-02, -2.6406e-02, -2.2211e-03]],\n",
       "              \n",
       "                       [[ 3.0386e-02, -9.0837e-03, -1.3622e-02],\n",
       "                        [ 2.7117e-02, -3.3625e-02, -2.1912e-02],\n",
       "                        [ 2.6335e-02, -3.0824e-02, -5.6924e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.7091e-02, -1.4433e-02,  9.3711e-03],\n",
       "                        [-2.3910e-02, -3.5697e-03,  2.4339e-02],\n",
       "                        [-8.3671e-03, -2.3920e-02, -2.3720e-02]],\n",
       "              \n",
       "                       [[-8.6753e-03, -2.9376e-02, -6.6657e-04],\n",
       "                        [-5.5607e-03, -2.6767e-02, -2.1619e-02],\n",
       "                        [ 2.6098e-02,  7.8963e-03, -3.8887e-02]],\n",
       "              \n",
       "                       [[-2.4608e-02, -1.7731e-02, -2.5025e-03],\n",
       "                        [-9.4012e-03, -1.5577e-02, -9.3565e-03],\n",
       "                        [-1.9251e-02,  1.4368e-03,  2.1448e-02]]]], device='cuda:0')),\n",
       "             ('cnn.conv4.bias',\n",
       "              tensor([ 2.3011e-02,  1.5628e-02,  2.6415e-02, -8.6668e-03,  2.1564e-02,\n",
       "                       4.9507e-03,  2.4338e-02, -3.7726e-03,  1.1888e-02, -2.6181e-02,\n",
       "                      -1.6142e-02,  1.2774e-02,  6.5046e-03,  1.8909e-02, -9.9459e-03,\n",
       "                       2.0512e-04,  2.4097e-02,  1.3741e-02, -1.2339e-02,  2.6177e-02,\n",
       "                       1.8784e-03,  9.6357e-04, -5.4046e-03, -2.7516e-02,  8.5097e-03,\n",
       "                      -1.4972e-02,  2.6463e-02,  1.9379e-03, -1.2130e-02,  8.5661e-03,\n",
       "                      -1.7116e-02, -2.8113e-02,  2.4803e-02,  2.8989e-02, -2.2120e-02,\n",
       "                      -1.4474e-02,  1.9074e-02,  2.7369e-02,  1.8712e-02,  3.4173e-03,\n",
       "                       5.4105e-03,  3.3001e-03,  1.8000e-02,  2.2089e-02, -2.2746e-02,\n",
       "                       2.8450e-02,  1.4194e-02, -1.6325e-02, -2.1765e-02, -2.8581e-02,\n",
       "                      -1.5305e-02,  1.1741e-02,  4.1869e-03, -2.0326e-02, -7.4246e-03,\n",
       "                      -6.5841e-03, -1.1645e-02, -1.3467e-02,  1.1557e-02, -2.0237e-02,\n",
       "                      -1.8373e-02,  1.7939e-02, -4.2691e-03, -2.2124e-02,  1.4290e-02,\n",
       "                       2.2176e-02,  9.0597e-03,  2.6498e-02,  7.1947e-03, -1.0998e-02,\n",
       "                       1.1437e-02,  1.2536e-02,  6.5961e-03,  2.2167e-02, -3.0987e-03,\n",
       "                      -2.5342e-02,  2.2706e-02,  1.2312e-02,  2.3895e-02, -1.0939e-03,\n",
       "                       8.0435e-03,  1.0885e-02,  1.4359e-02,  8.1717e-03,  9.4750e-04,\n",
       "                       2.7040e-02, -4.3459e-03, -1.8085e-02,  4.7882e-03,  1.7284e-02,\n",
       "                       2.3165e-02,  2.4741e-02,  9.1396e-03, -1.4374e-02, -4.7556e-03,\n",
       "                      -4.8233e-04, -7.8199e-03, -1.1527e-02, -9.7987e-03,  1.6691e-02,\n",
       "                       2.1300e-02, -1.1901e-02, -1.2595e-02, -6.6181e-03,  6.6954e-03,\n",
       "                       1.4273e-03, -1.2054e-02,  2.0729e-02, -3.4721e-03, -1.8560e-02,\n",
       "                      -1.3758e-03,  1.9058e-02, -9.9256e-03,  2.2886e-02,  4.0987e-03,\n",
       "                       1.5786e-04,  4.0279e-03, -7.7561e-03,  2.5734e-02,  1.0670e-03,\n",
       "                      -2.5665e-02,  2.8324e-02, -1.4428e-02, -1.8203e-02, -2.3675e-02,\n",
       "                      -1.5465e-02,  5.0909e-03, -2.2268e-02,  5.8132e-03, -8.2600e-03,\n",
       "                      -1.0068e-02,  1.9980e-03, -6.1240e-03,  1.5072e-02,  8.4032e-03,\n",
       "                      -1.1243e-02,  5.8455e-03, -3.2473e-03, -1.2914e-02,  1.8869e-04,\n",
       "                       2.5162e-02, -7.5804e-03,  1.4606e-02,  2.0209e-02,  2.1807e-02,\n",
       "                       2.9388e-02,  9.6885e-03, -2.6535e-02, -2.0330e-02,  6.4009e-03,\n",
       "                       2.4409e-02,  1.7950e-02, -2.1697e-02, -1.5568e-02,  2.3034e-02,\n",
       "                      -6.7864e-03,  2.5959e-04, -2.7987e-02, -1.9393e-02,  4.8959e-03,\n",
       "                      -1.5449e-02,  1.5421e-02, -1.7925e-02,  4.9205e-03, -1.5211e-02,\n",
       "                      -1.0640e-02,  1.0355e-02,  2.9023e-02,  2.3599e-02,  1.7994e-02,\n",
       "                       2.3403e-03,  1.6420e-02, -1.0775e-02,  2.5419e-02, -1.3973e-02,\n",
       "                      -1.4459e-02, -9.2055e-03,  5.4105e-03,  2.2623e-04,  2.1520e-02,\n",
       "                      -1.9261e-02, -5.9863e-03,  2.7792e-02,  1.3014e-02,  1.4081e-02,\n",
       "                      -2.4926e-02, -1.8737e-02, -1.7668e-02,  8.0420e-03,  8.3818e-03,\n",
       "                      -1.6252e-02,  1.2689e-02, -1.4708e-02, -7.8078e-03,  2.3654e-03,\n",
       "                      -1.7458e-02, -1.7778e-02, -1.1945e-02, -1.3602e-02,  1.8851e-02,\n",
       "                      -2.7315e-02, -2.8040e-03, -4.1681e-03, -1.0449e-02, -9.0004e-03,\n",
       "                       3.0078e-03,  2.2721e-02,  8.3717e-03, -6.5946e-03,  1.9177e-02,\n",
       "                       2.8240e-02,  1.0709e-02,  1.9479e-02, -2.1063e-02, -2.0223e-02,\n",
       "                      -2.0430e-02, -2.1788e-02,  2.5704e-02, -1.7193e-02,  2.7879e-02,\n",
       "                       9.3113e-03, -6.8588e-03, -2.9505e-02,  2.6561e-02, -2.4488e-02,\n",
       "                       1.1147e-02, -1.7519e-02, -2.7044e-02, -1.1146e-03,  2.4633e-02,\n",
       "                      -7.6263e-03, -1.8556e-02, -2.8032e-02,  2.7846e-03, -2.0216e-02,\n",
       "                      -4.0575e-03,  2.2429e-02, -1.4565e-03,  2.7422e-02, -1.2742e-02,\n",
       "                      -2.7621e-02, -9.1526e-03,  3.5793e-03, -5.6695e-03, -3.4840e-03,\n",
       "                      -2.7684e-02,  1.6064e-02, -2.7222e-02,  6.1010e-03,  4.1387e-04,\n",
       "                      -2.4081e-02, -7.9629e-05, -4.7087e-03, -1.5694e-02,  1.4873e-02,\n",
       "                      -6.9092e-03], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.weight',\n",
       "              tensor([0.9905, 0.9830, 1.0144, 1.0012, 1.0015, 0.9997, 0.9996, 1.0221, 0.9856,\n",
       "                      1.0192, 0.9924, 0.9877, 0.9877, 0.9915, 1.0243, 1.0195, 0.9580, 1.0113,\n",
       "                      0.9817, 0.9955, 1.0053, 1.0095, 1.0001, 0.9940, 1.0096, 0.9666, 1.0335,\n",
       "                      0.9708, 0.9806, 0.9945, 0.9878, 0.9970, 0.9787, 1.0145, 0.9835, 0.9756,\n",
       "                      0.9865, 0.9877, 0.9670, 0.9896, 1.0008, 1.0123, 1.0068, 0.9876, 0.9725,\n",
       "                      1.0065, 0.9760, 1.0022, 1.0110, 0.9832, 0.9654, 1.0020, 0.9827, 1.0008,\n",
       "                      1.0191, 1.0038, 0.9959, 0.9686, 1.0135, 0.9568, 1.0079, 0.9840, 0.9720,\n",
       "                      0.9835, 0.9599, 0.9758, 0.9952, 0.9573, 0.9906, 0.9924, 0.9813, 1.0096,\n",
       "                      0.9796, 0.9836, 1.0270, 0.9918, 1.0422, 1.0239, 1.0295, 0.9800, 1.0290,\n",
       "                      1.0009, 0.9807, 0.9897, 0.9728, 0.9806, 0.9957, 1.0117, 0.9893, 0.9858,\n",
       "                      1.0051, 0.9993, 0.9913, 0.9778, 0.9754, 0.9802, 0.9987, 1.0007, 0.9871,\n",
       "                      1.0034, 0.9858, 1.0341, 1.0076, 1.0108, 1.0042, 0.9796, 0.9768, 0.9845,\n",
       "                      0.9825, 1.0152, 0.9874, 1.0199, 1.0003, 1.0200, 0.9787, 0.9975, 0.9979,\n",
       "                      0.9996, 1.0123, 0.9940, 1.0124, 0.9840, 0.9920, 0.9747, 1.0257, 1.0103,\n",
       "                      0.9794, 1.0172, 0.9750, 0.9746, 1.0154, 1.0012, 1.0014, 0.9755, 0.9875,\n",
       "                      0.9929, 0.9794, 0.9937, 0.9959, 0.9881, 0.9949, 1.0228, 1.0161, 1.0076,\n",
       "                      1.0132, 0.9762, 0.9932, 0.9741, 0.9852, 0.9808, 1.0138, 1.0091, 0.9983,\n",
       "                      0.9922, 0.9749, 0.9955, 1.0007, 1.0079, 1.0024, 0.9928, 0.9825, 0.9860,\n",
       "                      1.0165, 0.9919, 1.0092, 1.0084, 1.0034, 0.9945, 1.0148, 1.0047, 0.9866,\n",
       "                      1.0165, 0.9995, 1.0212, 1.0053, 0.9993, 0.9923, 0.9679, 1.0186, 1.0250,\n",
       "                      1.0009, 0.9777, 0.9388, 1.0013, 0.9961, 1.0115, 1.0033, 1.0291, 0.9689,\n",
       "                      0.9972, 1.0053, 1.0054, 1.0026, 0.9846, 0.9920, 0.9810, 1.0051, 0.9998,\n",
       "                      0.9899, 1.0019, 0.9968, 0.9912, 0.9756, 0.9576, 0.9977, 1.0017, 1.0246,\n",
       "                      0.9986, 0.9945, 1.0203, 1.0016, 0.9991, 1.0008, 1.0203, 1.0331, 0.9907,\n",
       "                      1.0295, 0.9728, 0.9860, 0.9880, 1.0187, 0.9981, 0.9678, 1.0096, 1.0396,\n",
       "                      1.0313, 0.9837, 1.0084, 0.9962, 1.0361, 1.0039, 1.0075, 0.9830, 0.9868,\n",
       "                      0.9630, 1.0069, 0.9994, 0.9827, 1.0079, 1.0280, 0.9990, 0.9630, 0.9976,\n",
       "                      0.9966, 0.9877, 0.9735, 0.9799, 1.0416, 0.9972, 0.9751, 0.9810, 0.9928,\n",
       "                      1.0024, 1.0072, 0.9780, 1.0393], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.bias',\n",
       "              tensor([-0.0245, -0.0169, -0.0049, -0.0366, -0.0353, -0.0353, -0.0276, -0.0277,\n",
       "                      -0.0180, -0.0199, -0.0248, -0.0343, -0.0167, -0.0096, -0.0526, -0.0398,\n",
       "                      -0.0316, -0.0622, -0.0325, -0.0062, -0.0423, -0.0131, -0.0411, -0.0101,\n",
       "                      -0.0360, -0.0229, -0.0326, -0.0238, -0.0021, -0.0170, -0.0354, -0.0079,\n",
       "                      -0.0164,  0.0065, -0.0082, -0.0612, -0.0127, -0.0289, -0.0254, -0.0384,\n",
       "                      -0.0412, -0.0599, -0.0126, -0.0405, -0.0149,  0.0066, -0.0089, -0.0109,\n",
       "                      -0.0631, -0.0379, -0.0370, -0.0385, -0.0137, -0.0254, -0.0353,  0.0053,\n",
       "                      -0.0334, -0.0317, -0.0483, -0.0449, -0.0516, -0.0196, -0.0376, -0.0199,\n",
       "                      -0.0477, -0.0275, -0.0077, -0.0415, -0.0339, -0.0515, -0.0256, -0.0456,\n",
       "                      -0.0056, -0.0043, -0.0687, -0.0449, -0.0248, -0.0201, -0.0621, -0.0520,\n",
       "                      -0.0461, -0.0081, -0.0238, -0.0056, -0.0135, -0.0227, -0.0224,  0.0037,\n",
       "                      -0.0199, -0.0174, -0.0426, -0.0412, -0.0369, -0.0349, -0.0237, -0.0250,\n",
       "                      -0.0096, -0.0051, -0.0584, -0.0288, -0.0204, -0.0495, -0.0469, -0.0361,\n",
       "                      -0.0398, -0.0113, -0.0055, -0.0017, -0.0511, -0.0633,  0.0068, -0.0378,\n",
       "                      -0.0155, -0.0450, -0.0156, -0.0351, -0.0356, -0.0158, -0.0805, -0.0065,\n",
       "                      -0.0103, -0.0347, -0.0048, -0.0253, -0.0467, -0.0547, -0.0442, -0.0115,\n",
       "                      -0.0224, -0.0198, -0.0315, -0.0296, -0.0460, -0.0059, -0.0056, -0.0536,\n",
       "                      -0.0048, -0.0421, -0.0426, -0.0146, -0.0412, -0.0458, -0.0273, -0.0400,\n",
       "                      -0.0401, -0.0484, -0.0306, -0.0028,  0.0066, -0.0020, -0.0160, -0.0409,\n",
       "                      -0.0453, -0.0424, -0.0392, -0.0286, -0.0534, -0.0076, -0.0219, -0.0394,\n",
       "                      -0.0338, -0.0108, -0.0500, -0.0113, -0.0375, -0.0211, -0.0160, -0.0341,\n",
       "                      -0.0335, -0.0352, -0.0173, -0.0160, -0.0232, -0.0339, -0.0124, -0.0370,\n",
       "                      -0.0178, -0.0317, -0.0510, -0.0464, -0.0206, -0.0235, -0.0532, -0.0445,\n",
       "                      -0.0224, -0.0234, -0.0577, -0.0539, -0.0231, -0.0445, -0.0037, -0.0276,\n",
       "                      -0.0038, -0.0138, -0.0271, -0.0495, -0.0491, -0.0154, -0.0301, -0.0398,\n",
       "                      -0.0499, -0.0053, -0.0149, -0.0533, -0.0474, -0.0270, -0.0573, -0.0359,\n",
       "                      -0.0366, -0.0126, -0.0279, -0.0344, -0.0083, -0.0647, -0.0379, -0.0497,\n",
       "                      -0.0489, -0.0130, -0.0169, -0.0023, -0.0631, -0.0157, -0.0386, -0.0420,\n",
       "                      -0.0298, -0.0406, -0.0470, -0.0068, -0.0394, -0.0391, -0.0493, -0.0145,\n",
       "                      -0.0079, -0.0202, -0.0319, -0.0508, -0.0555, -0.0536, -0.0529, -0.0315,\n",
       "                      -0.0516, -0.0142, -0.0087, -0.0187, -0.0067, -0.0140, -0.0264, -0.0521,\n",
       "                       0.0054, -0.0058, -0.0262, -0.0375, -0.0070, -0.0056, -0.0423, -0.0279],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm4.running_mean',\n",
       "              tensor([ 0.5832, -1.5401, -0.1478, -0.5255, -0.9524, -1.6559, -1.0843, -1.0004,\n",
       "                      -2.8346, -1.9411, -3.3749, -0.8709,  2.1788, -1.7772, -1.0315, -3.0102,\n",
       "                      -4.0621, -0.7102,  0.7073, -2.4039, -2.5698, -0.6703, -0.5335, -2.4639,\n",
       "                      -0.6635, -1.0685,  1.7731, -3.2927, -1.8654, -1.7631,  1.8487, -2.8678,\n",
       "                      -3.2065, -0.1181, -2.0489, -0.0125,  0.2648,  1.1486, -1.4545, -0.5657,\n",
       "                      -1.0249,  0.3261,  1.3011, -0.2392, -3.1064, -1.2734, -2.3630, -0.6840,\n",
       "                      -1.3965, -3.9617, -2.3055, -1.0321, -2.0185,  0.6143, -1.8724, -0.7487,\n",
       "                      -1.2328, -3.4820, -3.1299, -1.0494, -0.0847, -1.7772, -2.4647,  0.3219,\n",
       "                       0.5052, -1.0317, -1.5725, -0.4215,  0.5915, -2.2056, -0.5330, -2.5532,\n",
       "                      -2.1652, -3.0842, -1.5931, -3.3320, -2.9793, -4.5879, -3.1322, -1.7478,\n",
       "                       0.0476,  1.2711, -2.2654, -2.8411, -3.8605,  0.7814, -2.6135, -0.4929,\n",
       "                      -2.0730, -0.4995, -0.7239,  0.4063, -1.0654, -2.1386, -3.3744, -3.2301,\n",
       "                      -2.3610, -1.8554, -1.3319, -1.3515, -3.3565, -0.1966, -1.0363,  0.7972,\n",
       "                      -0.5025, -2.3257, -2.7914, -4.0214,  0.2040, -2.9544, -0.2709, -3.5107,\n",
       "                      -1.4159, -3.8598,  0.4906, -0.6664, -0.6656,  1.7326, -2.2605, -2.2666,\n",
       "                      -3.2169,  2.0144, -2.4536, -2.4704, -0.8160, -2.1255, -0.1095, -1.3792,\n",
       "                      -2.7611, -3.2605, -3.7039,  0.8498,  0.0896, -3.3603, -3.8230, -1.2334,\n",
       "                      -2.6753, -1.2350, -0.7183, -2.3352, -1.5737, -2.5083,  0.2462,  1.4474,\n",
       "                      -3.4855, -0.3631, -2.1117, -3.8136, -1.0528, -2.7572,  0.3831, -0.8513,\n",
       "                      -1.6737, -0.0444, -1.9695,  2.4910, -1.4122,  0.1290, -1.0746, -0.7154,\n",
       "                       2.7083, -2.0702, -1.3403, -2.0228, -0.6088,  0.9483, -0.4716, -0.8483,\n",
       "                       0.0964, -0.4855, -2.0419, -1.2032, -1.2107, -2.5684, -1.3955,  0.3885,\n",
       "                       2.2851, -2.7692, -2.3298, -2.9840,  1.5616, -3.2850,  0.5860,  0.4239,\n",
       "                      -1.3665,  0.2285, -1.1825, -0.7454, -3.4613,  0.6690, -0.6369, -1.3306,\n",
       "                      -1.4090, -4.0967, -1.2907, -0.7141,  0.4569, -3.4871,  0.0554, -2.0843,\n",
       "                      -0.5110, -1.3236, -3.7024,  0.5668, -0.9156, -1.8688, -3.4901, -1.0816,\n",
       "                      -0.9095,  0.1918, -1.5692,  1.9568, -1.0831, -1.1302, -3.3151,  0.3891,\n",
       "                      -2.7310, -3.5757, -2.3158, -2.8223, -2.6505, -0.9486,  0.3236, -2.5162,\n",
       "                      -3.4943, -3.5136, -0.3103,  2.4240, -1.1547, -0.4882,  0.1471,  3.1330,\n",
       "                      -3.3114, -2.0849, -3.7255,  0.1935,  0.3281, -0.2066, -3.9561, -4.4293,\n",
       "                      -0.8187, -2.3722, -2.0312, -0.2417, -1.1872, -3.0706,  0.5872, -3.6561,\n",
       "                      -1.6020, -3.0533, -0.1978,  0.5801, -0.8370,  2.6749, -0.4934, -2.5698],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm4.running_var',\n",
       "              tensor([1.2273, 1.8100, 2.6372, 1.6699, 1.5459, 1.3436, 1.1227, 3.7433, 1.2132,\n",
       "                      1.3841, 1.9179, 0.6586, 2.9317, 1.5371, 1.5364, 1.3592, 4.9267, 2.0294,\n",
       "                      2.3305, 1.8114, 0.9329, 1.2633, 1.5193, 0.9744, 1.0016, 2.1255, 0.9264,\n",
       "                      1.9039, 1.8080, 1.2634, 2.2213, 1.1713, 3.2055, 1.5670, 1.5458, 0.8164,\n",
       "                      1.8257, 0.6760, 1.2557, 1.0105, 1.4502, 1.6054, 1.8656, 1.5368, 0.8980,\n",
       "                      2.9871, 3.0090, 2.0579, 2.6127, 2.5292, 0.9452, 1.5685, 4.4038, 1.3718,\n",
       "                      2.6274, 2.5961, 3.0695, 1.1128, 2.5164, 1.1675, 1.4741, 0.8317, 0.8801,\n",
       "                      1.2946, 1.0917, 1.4317, 1.8648, 0.5115, 1.8981, 1.5117, 1.5996, 3.4484,\n",
       "                      2.4170, 6.0842, 3.2068, 2.9353, 0.8533, 3.5793, 1.2974, 1.9754, 1.0929,\n",
       "                      1.6056, 1.4015, 1.5936, 5.4221, 3.2689, 1.4279, 1.9177, 1.6510, 3.0259,\n",
       "                      1.5249, 1.9538, 1.8284, 1.1888, 4.0036, 1.5375, 0.8203, 2.8684, 1.6494,\n",
       "                      0.9170, 2.0377, 2.3677, 1.3245, 1.3981, 1.4178, 0.7808, 4.9385, 1.9114,\n",
       "                      1.5902, 1.5501, 0.6118, 2.6148, 0.6481, 2.3888, 1.7046, 1.4485, 1.3373,\n",
       "                      2.1076, 1.1686, 0.9419, 1.1965, 1.2008, 3.1407, 2.8013, 1.7315, 3.9662,\n",
       "                      1.9123, 1.0837, 1.1738, 1.9548, 1.5438, 1.0083, 1.9325, 3.0459, 2.4489,\n",
       "                      0.6942, 1.2851, 1.4016, 1.4625, 1.8559, 1.1230, 3.1565, 1.2846, 1.6689,\n",
       "                      2.0947, 2.0663, 1.1161, 2.4661, 0.7208, 4.1826, 1.6242, 1.4329, 1.5365,\n",
       "                      0.9234, 3.4713, 1.1482, 2.2061, 1.9326, 1.3005, 1.5227, 1.1846, 0.9273,\n",
       "                      1.8531, 1.0130, 1.5712, 2.6296, 0.8469, 1.8745, 1.2678, 0.8817, 2.3313,\n",
       "                      1.7308, 1.0706, 1.6064, 1.2882, 2.3034, 1.6903, 1.4573, 1.5845, 1.5507,\n",
       "                      4.0593, 2.0413, 1.0135, 1.7960, 0.6363, 1.7081, 2.7186, 1.5294, 1.8710,\n",
       "                      1.5428, 1.3488, 1.6004, 1.4494, 2.0996, 1.6347, 1.6260, 1.7574, 1.4138,\n",
       "                      0.8225, 2.0319, 1.3027, 1.0961, 1.3799, 1.7134, 2.8167, 1.0035, 1.8119,\n",
       "                      2.2324, 1.2623, 1.4839, 0.9142, 0.8294, 1.5696, 1.6061, 4.5856, 1.9662,\n",
       "                      3.7140, 4.8450, 0.7836, 1.1562, 1.5064, 1.3248, 1.7417, 1.6394, 4.9058,\n",
       "                      1.7294, 2.3804, 1.8101, 1.0887, 3.8292, 1.9979, 1.5405, 4.4374, 0.8650,\n",
       "                      2.8835, 1.7413, 2.0728, 1.7311, 3.4659, 5.1915, 2.2278, 1.9053, 0.8357,\n",
       "                      1.2819, 4.2585, 3.9468, 1.2500, 2.2380, 1.2483, 4.9317, 1.3803, 0.8863,\n",
       "                      1.3837, 2.9279, 1.0321, 1.6831], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0')),\n",
       "             ('cnn.conv5.weight',\n",
       "              tensor([[[[-0.0185, -0.0267, -0.0164],\n",
       "                        [-0.0084,  0.0007, -0.0280],\n",
       "                        [-0.0006, -0.0139, -0.0033]],\n",
       "              \n",
       "                       [[-0.0268, -0.0211,  0.0102],\n",
       "                        [ 0.0107,  0.0194, -0.0094],\n",
       "                        [ 0.0022,  0.0084, -0.0019]],\n",
       "              \n",
       "                       [[ 0.0241, -0.0062, -0.0105],\n",
       "                        [-0.0048,  0.0260,  0.0020],\n",
       "                        [-0.0082,  0.0105,  0.0258]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0163,  0.0022, -0.0148],\n",
       "                        [-0.0016,  0.0100, -0.0036],\n",
       "                        [ 0.0207,  0.0115,  0.0143]],\n",
       "              \n",
       "                       [[-0.0270, -0.0133,  0.0061],\n",
       "                        [-0.0348, -0.0029,  0.0028],\n",
       "                        [ 0.0054, -0.0315,  0.0069]],\n",
       "              \n",
       "                       [[-0.0107,  0.0227,  0.0033],\n",
       "                        [-0.0101,  0.0241, -0.0162],\n",
       "                        [ 0.0120,  0.0022,  0.0179]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0075,  0.0013,  0.0111],\n",
       "                        [-0.0030,  0.0131, -0.0086],\n",
       "                        [ 0.0096,  0.0065,  0.0185]],\n",
       "              \n",
       "                       [[ 0.0066, -0.0188, -0.0246],\n",
       "                        [-0.0237, -0.0086, -0.0012],\n",
       "                        [ 0.0094,  0.0074,  0.0102]],\n",
       "              \n",
       "                       [[-0.0282, -0.0238, -0.0092],\n",
       "                        [-0.0052, -0.0027, -0.0068],\n",
       "                        [-0.0103, -0.0156, -0.0230]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0096,  0.0004, -0.0219],\n",
       "                        [-0.0101, -0.0279, -0.0291],\n",
       "                        [-0.0055, -0.0246, -0.0041]],\n",
       "              \n",
       "                       [[ 0.0182, -0.0141, -0.0074],\n",
       "                        [-0.0006,  0.0212, -0.0010],\n",
       "                        [-0.0061,  0.0238, -0.0002]],\n",
       "              \n",
       "                       [[-0.0403, -0.0292, -0.0279],\n",
       "                        [-0.0274, -0.0513, -0.0308],\n",
       "                        [-0.0061, -0.0421, -0.0267]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0041,  0.0078,  0.0018],\n",
       "                        [ 0.0055,  0.0087, -0.0051],\n",
       "                        [ 0.0078,  0.0065,  0.0216]],\n",
       "              \n",
       "                       [[-0.0219,  0.0057, -0.0153],\n",
       "                        [ 0.0020, -0.0025, -0.0288],\n",
       "                        [-0.0014, -0.0143, -0.0327]],\n",
       "              \n",
       "                       [[-0.0194, -0.0149,  0.0002],\n",
       "                        [-0.0277, -0.0004, -0.0103],\n",
       "                        [ 0.0054, -0.0192, -0.0251]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0240, -0.0165, -0.0158],\n",
       "                        [-0.0413, -0.0317, -0.0315],\n",
       "                        [-0.0089, -0.0034, -0.0143]],\n",
       "              \n",
       "                       [[ 0.0118, -0.0060,  0.0022],\n",
       "                        [-0.0170, -0.0142, -0.0213],\n",
       "                        [ 0.0051, -0.0057, -0.0084]],\n",
       "              \n",
       "                       [[-0.0400, -0.0546, -0.0448],\n",
       "                        [-0.0130, -0.0407, -0.0250],\n",
       "                        [-0.0380, -0.0387, -0.0504]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0030,  0.0124, -0.0069],\n",
       "                        [-0.0014, -0.0097, -0.0051],\n",
       "                        [ 0.0269, -0.0139,  0.0003]],\n",
       "              \n",
       "                       [[ 0.0143, -0.0067,  0.0023],\n",
       "                        [ 0.0167,  0.0221,  0.0033],\n",
       "                        [-0.0117,  0.0230, -0.0111]],\n",
       "              \n",
       "                       [[ 0.0504,  0.0181,  0.0291],\n",
       "                        [ 0.0468,  0.0243,  0.0068],\n",
       "                        [ 0.0297,  0.0357,  0.0066]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0344,  0.0028, -0.0242],\n",
       "                        [ 0.0028,  0.0084,  0.0059],\n",
       "                        [-0.0016, -0.0002,  0.0018]],\n",
       "              \n",
       "                       [[ 0.0506,  0.0424,  0.0193],\n",
       "                        [ 0.0281,  0.0187,  0.0248],\n",
       "                        [ 0.0351,  0.0186,  0.0025]],\n",
       "              \n",
       "                       [[ 0.0011,  0.0194, -0.0007],\n",
       "                        [ 0.0245,  0.0005, -0.0167],\n",
       "                        [-0.0138, -0.0025, -0.0322]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0163, -0.0209, -0.0166],\n",
       "                        [ 0.0151,  0.0007, -0.0160],\n",
       "                        [-0.0151, -0.0068, -0.0134]],\n",
       "              \n",
       "                       [[ 0.0028,  0.0130, -0.0089],\n",
       "                        [-0.0086,  0.0108,  0.0045],\n",
       "                        [ 0.0114, -0.0047,  0.0107]],\n",
       "              \n",
       "                       [[ 0.0152,  0.0162, -0.0047],\n",
       "                        [ 0.0296,  0.0043, -0.0008],\n",
       "                        [-0.0032,  0.0129,  0.0012]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0010,  0.0189,  0.0119],\n",
       "                        [ 0.0062,  0.0023, -0.0091],\n",
       "                        [ 0.0054,  0.0254,  0.0102]],\n",
       "              \n",
       "                       [[ 0.0013, -0.0104,  0.0104],\n",
       "                        [-0.0084,  0.0023, -0.0181],\n",
       "                        [-0.0123,  0.0107, -0.0240]],\n",
       "              \n",
       "                       [[-0.0016,  0.0003,  0.0077],\n",
       "                        [ 0.0236,  0.0344,  0.0052],\n",
       "                        [ 0.0401,  0.0405, -0.0055]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0285, -0.0046,  0.0005],\n",
       "                        [-0.0177, -0.0165, -0.0194],\n",
       "                        [ 0.0124, -0.0028, -0.0006]],\n",
       "              \n",
       "                       [[ 0.0029,  0.0166, -0.0002],\n",
       "                        [-0.0167,  0.0192, -0.0083],\n",
       "                        [ 0.0123,  0.0168, -0.0018]],\n",
       "              \n",
       "                       [[ 0.0208,  0.0056, -0.0006],\n",
       "                        [ 0.0276,  0.0164,  0.0140],\n",
       "                        [-0.0057, -0.0009,  0.0120]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0030, -0.0084, -0.0098],\n",
       "                        [-0.0109,  0.0141, -0.0162],\n",
       "                        [-0.0002,  0.0043, -0.0091]],\n",
       "              \n",
       "                       [[-0.0119, -0.0139, -0.0150],\n",
       "                        [-0.0070,  0.0156, -0.0126],\n",
       "                        [-0.0087,  0.0079,  0.0193]],\n",
       "              \n",
       "                       [[-0.0086,  0.0048,  0.0211],\n",
       "                        [ 0.0220,  0.0313,  0.0084],\n",
       "                        [-0.0029,  0.0287, -0.0019]]]], device='cuda:0')),\n",
       "             ('cnn.conv5.bias',\n",
       "              tensor([-0.0083, -0.0040, -0.0199,  0.0080,  0.0092,  0.0062, -0.0048,  0.0028,\n",
       "                       0.0082,  0.0078, -0.0192, -0.0190,  0.0154, -0.0162, -0.0150,  0.0083,\n",
       "                       0.0116, -0.0008,  0.0021,  0.0189, -0.0047, -0.0148,  0.0028,  0.0177,\n",
       "                      -0.0050, -0.0138,  0.0067, -0.0152,  0.0108,  0.0081,  0.0052,  0.0066,\n",
       "                       0.0169, -0.0169,  0.0063,  0.0196,  0.0078,  0.0130, -0.0142,  0.0169,\n",
       "                      -0.0175,  0.0060,  0.0188, -0.0098, -0.0109, -0.0190, -0.0094, -0.0078,\n",
       "                      -0.0117, -0.0154, -0.0111,  0.0175, -0.0012,  0.0126, -0.0077, -0.0076,\n",
       "                       0.0178,  0.0110,  0.0139, -0.0159,  0.0166,  0.0018,  0.0033, -0.0045,\n",
       "                       0.0198,  0.0095,  0.0148, -0.0149, -0.0087, -0.0174,  0.0091,  0.0041,\n",
       "                      -0.0079, -0.0183, -0.0016,  0.0014,  0.0116, -0.0100, -0.0187, -0.0045,\n",
       "                       0.0105, -0.0158, -0.0032,  0.0205, -0.0137,  0.0072, -0.0094,  0.0164,\n",
       "                       0.0103,  0.0040, -0.0039,  0.0187,  0.0186,  0.0061,  0.0171,  0.0120,\n",
       "                       0.0078,  0.0114, -0.0011, -0.0134, -0.0150,  0.0170, -0.0052, -0.0065,\n",
       "                       0.0129,  0.0077,  0.0047,  0.0190, -0.0062, -0.0074,  0.0164,  0.0049,\n",
       "                      -0.0092,  0.0003, -0.0138, -0.0187,  0.0044, -0.0029, -0.0061, -0.0088,\n",
       "                      -0.0089,  0.0059, -0.0029,  0.0175, -0.0190, -0.0016, -0.0044,  0.0173,\n",
       "                      -0.0180,  0.0134,  0.0005, -0.0165,  0.0041,  0.0051, -0.0098, -0.0204,\n",
       "                      -0.0074,  0.0128, -0.0049, -0.0095,  0.0188,  0.0193,  0.0098,  0.0166,\n",
       "                       0.0119,  0.0123, -0.0191, -0.0067, -0.0167, -0.0031,  0.0182,  0.0096,\n",
       "                       0.0095, -0.0189, -0.0126, -0.0203,  0.0012,  0.0047, -0.0073, -0.0161,\n",
       "                      -0.0049,  0.0137, -0.0078,  0.0028,  0.0010,  0.0106,  0.0133,  0.0035,\n",
       "                      -0.0052,  0.0016,  0.0107, -0.0181,  0.0165,  0.0098, -0.0194, -0.0012,\n",
       "                       0.0015, -0.0114,  0.0145, -0.0009,  0.0088, -0.0170,  0.0057, -0.0098,\n",
       "                       0.0089,  0.0018,  0.0035, -0.0160,  0.0058, -0.0098, -0.0142,  0.0133,\n",
       "                       0.0145, -0.0053, -0.0090, -0.0131, -0.0171, -0.0076,  0.0196, -0.0110,\n",
       "                       0.0123, -0.0181,  0.0069, -0.0033, -0.0062,  0.0193,  0.0166, -0.0066,\n",
       "                       0.0005,  0.0028, -0.0133, -0.0182,  0.0145, -0.0006,  0.0113,  0.0048,\n",
       "                      -0.0154, -0.0002,  0.0169,  0.0187, -0.0072, -0.0039, -0.0062, -0.0164,\n",
       "                      -0.0010, -0.0052, -0.0168,  0.0100,  0.0058, -0.0073, -0.0132,  0.0020,\n",
       "                       0.0160,  0.0132,  0.0140,  0.0155,  0.0123, -0.0065,  0.0081,  0.0205,\n",
       "                      -0.0003,  0.0207, -0.0138, -0.0082, -0.0106, -0.0198,  0.0161,  0.0082,\n",
       "                       0.0170, -0.0066, -0.0183, -0.0127, -0.0084, -0.0136, -0.0167, -0.0057],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm5.weight',\n",
       "              tensor([0.9980, 1.0103, 0.9893, 1.0111, 1.0120, 1.0014, 0.9960, 1.0006, 0.9971,\n",
       "                      1.0155, 1.0069, 1.0052, 1.0016, 1.0171, 1.0009, 1.0122, 0.9970, 1.0067,\n",
       "                      1.0031, 1.0038, 0.9968, 1.0162, 0.9887, 0.9965, 1.0013, 1.0064, 1.0013,\n",
       "                      1.0067, 1.0065, 0.9832, 1.0142, 1.0151, 0.9726, 1.0037, 0.9947, 1.0029,\n",
       "                      1.0140, 1.0101, 1.0112, 1.0026, 1.0065, 1.0039, 1.0052, 1.0089, 1.0085,\n",
       "                      1.0082, 1.0130, 1.0137, 0.9928, 1.0018, 0.9992, 1.0084, 1.0122, 1.0042,\n",
       "                      1.0099, 0.9984, 1.0146, 1.0005, 1.0126, 1.0008, 0.9952, 1.0120, 1.0068,\n",
       "                      1.0020, 0.9940, 0.9989, 1.0148, 1.0049, 0.9959, 1.0126, 0.9975, 1.0024,\n",
       "                      1.0023, 0.9917, 1.0164, 1.0099, 1.0071, 1.0065, 1.0105, 1.0098, 1.0093,\n",
       "                      1.0042, 1.0177, 1.0103, 1.0067, 1.0064, 0.9974, 1.0184, 1.0144, 1.0106,\n",
       "                      1.0004, 1.0054, 0.9948, 1.0096, 0.9987, 1.0168, 0.9846, 1.0101, 0.9847,\n",
       "                      1.0154, 1.0059, 1.0146, 1.0006, 1.0119, 0.9979, 0.9987, 1.0139, 0.9958,\n",
       "                      1.0121, 1.0093, 1.0134, 1.0021, 0.9988, 1.0077, 0.9830, 0.9915, 0.9954,\n",
       "                      0.9936, 0.9903, 1.0081, 1.0073, 1.0074, 0.9818, 1.0113, 1.0137, 1.0062,\n",
       "                      1.0058, 0.9811, 1.0129, 1.0100, 1.0091, 1.0096, 1.0119, 1.0047, 1.0124,\n",
       "                      1.0006, 0.9978, 0.9958, 1.0106, 0.9940, 1.0080, 1.0108, 1.0063, 0.9826,\n",
       "                      1.0141, 1.0036, 1.0165, 1.0057, 1.0082, 1.0122, 0.9938, 1.0022, 1.0036,\n",
       "                      0.9954, 1.0004, 1.0081, 0.9937, 1.0034, 1.0082, 1.0039, 1.0048, 1.0073,\n",
       "                      1.0072, 1.0088, 0.9897, 1.0077, 1.0098, 1.0116, 0.9980, 1.0111, 1.0045,\n",
       "                      1.0010, 1.0104, 1.0090, 1.0127, 0.9869, 1.0117, 1.0015, 0.9954, 0.9827,\n",
       "                      0.9920, 1.0096, 1.0063, 0.9947, 1.0130, 1.0131, 0.9986, 1.0131, 1.0011,\n",
       "                      1.0102, 1.0115, 0.9839, 1.0023, 1.0058, 0.9831, 1.0099, 1.0086, 1.0158,\n",
       "                      0.9989, 1.0121, 0.9917, 1.0048, 0.9965, 1.0018, 1.0162, 0.9961, 1.0159,\n",
       "                      1.0005, 0.9866, 1.0081, 1.0000, 1.0169, 1.0097, 1.0085, 1.0137, 1.0025,\n",
       "                      1.0070, 1.0092, 0.9936, 1.0140, 1.0069, 0.9920, 1.0098, 0.9881, 1.0144,\n",
       "                      0.9921, 1.0108, 1.0131, 1.0086, 1.0084, 0.9949, 1.0103, 0.9884, 0.9946,\n",
       "                      1.0015, 1.0072, 0.9857, 1.0104, 1.0048, 1.0016, 1.0106, 1.0134, 1.0101,\n",
       "                      1.0019, 0.9894, 1.0135, 0.9878, 0.9978, 1.0087, 1.0104, 1.0096, 1.0066,\n",
       "                      0.9948, 0.9813, 1.0127, 1.0105], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.bias',\n",
       "              tensor([-1.5804e-02, -2.1267e-02, -3.3819e-02, -1.3023e-04, -6.6218e-04,\n",
       "                      -1.4706e-02, -6.4812e-03, -2.6463e-02, -1.9919e-02, -5.4814e-03,\n",
       "                      -2.2360e-02, -1.7685e-02, -1.5779e-02, -6.9547e-03, -4.1187e-03,\n",
       "                      -7.5838e-03, -2.1978e-02, -1.4019e-02, -7.1700e-03, -2.2371e-02,\n",
       "                      -8.8453e-03,  2.6681e-03, -1.8500e-02, -2.6360e-02, -3.1705e-02,\n",
       "                      -2.2892e-02, -1.3769e-02, -7.9722e-03, -4.2245e-03, -2.8125e-02,\n",
       "                      -1.9978e-02, -5.6315e-04, -3.7532e-02, -2.7488e-02, -1.3882e-02,\n",
       "                      -1.5551e-02, -9.6341e-04,  1.7403e-03, -4.4761e-04, -2.1751e-02,\n",
       "                      -1.1366e-02, -1.3851e-02, -5.1836e-03, -6.8718e-03, -2.2150e-02,\n",
       "                      -3.3921e-03, -5.5181e-03, -2.4646e-02, -9.0206e-03, -2.1048e-03,\n",
       "                      -5.2423e-03, -1.9885e-02, -2.1986e-02, -3.2705e-02, -8.8369e-03,\n",
       "                      -3.5704e-02, -6.8362e-03, -6.8917e-03,  3.1287e-04, -1.0636e-02,\n",
       "                      -8.3908e-03, -1.7993e-02, -3.3716e-03, -1.2098e-02, -2.2983e-02,\n",
       "                      -2.3928e-02,  3.8903e-03, -9.2838e-03, -7.8926e-03, -5.6551e-03,\n",
       "                      -2.1442e-02, -1.9122e-02, -1.9929e-02, -3.1829e-02, -1.9718e-02,\n",
       "                      -1.6536e-03, -7.8651e-03, -2.2749e-02, -2.3625e-02, -2.5585e-02,\n",
       "                      -1.0342e-04, -1.5443e-02, -1.0224e-02, -2.2988e-03, -2.9720e-03,\n",
       "                      -3.9962e-03, -1.9786e-02, -5.4805e-03,  3.0838e-03, -2.5244e-02,\n",
       "                      -7.3966e-03, -1.9657e-02, -3.8716e-02, -6.0966e-03, -2.0161e-03,\n",
       "                      -1.4478e-02, -2.0052e-02, -4.7832e-03, -2.5507e-02, -1.7774e-02,\n",
       "                      -3.5675e-03, -2.0083e-02, -4.6153e-03, -8.0114e-03, -1.2484e-02,\n",
       "                      -1.1237e-02, -9.6251e-04, -1.2557e-02,  7.0026e-05, -2.8664e-03,\n",
       "                      -1.9000e-02, -2.7619e-02, -3.5411e-02, -1.6421e-02, -2.1263e-02,\n",
       "                      -1.4054e-02, -7.8610e-03, -7.7732e-03, -2.6060e-02, -2.3830e-03,\n",
       "                      -2.9144e-02, -2.9668e-03, -2.1990e-02, -7.2474e-03, -9.6523e-05,\n",
       "                      -4.1974e-03, -5.7029e-04, -2.3043e-02, -2.3369e-02, -2.0068e-02,\n",
       "                      -3.2752e-02, -2.1402e-02, -4.7726e-03, -1.4805e-02, -4.1950e-03,\n",
       "                      -1.0526e-02, -8.7556e-03, -8.1801e-03, -6.7284e-03, -2.2485e-02,\n",
       "                      -2.2609e-02, -1.3971e-02, -8.8448e-03, -5.2674e-02, -2.6257e-02,\n",
       "                      -8.1286e-03, -3.8956e-03, -2.3689e-02, -5.3794e-03,  3.2759e-03,\n",
       "                      -2.2643e-02, -2.1490e-02, -9.9073e-03, -9.5277e-03, -1.3792e-02,\n",
       "                      -2.5720e-02, -2.9756e-02, -7.2840e-03, -2.2570e-03, -3.0543e-02,\n",
       "                      -2.3248e-02, -3.1819e-02, -2.2638e-02, -2.2200e-02, -1.9188e-02,\n",
       "                      -8.9051e-04, -1.1291e-03,  1.5423e-03, -7.1938e-03, -2.7147e-02,\n",
       "                      -2.2236e-03, -1.2800e-02, -3.3597e-02, -3.4730e-03, -2.7334e-03,\n",
       "                      -1.6557e-02, -2.4419e-03, -8.6183e-03, -1.3164e-02, -2.2004e-02,\n",
       "                      -1.0726e-02,  1.1323e-03, -2.8453e-02, -1.7942e-02,  2.0769e-03,\n",
       "                      -7.1461e-03, -2.6425e-02, -6.4772e-03, -8.2971e-03, -1.5721e-02,\n",
       "                      -3.0218e-03, -2.1706e-02, -2.0348e-02, -1.2364e-02, -2.0075e-02,\n",
       "                      -2.0084e-03, -1.0005e-04, -1.8210e-02, -2.9532e-03,  3.4052e-03,\n",
       "                      -1.1311e-02, -2.4014e-02, -3.4702e-02, -2.0001e-02, -7.7876e-04,\n",
       "                      -1.6032e-02, -9.1025e-04, -6.8147e-03, -2.5946e-02, -2.7006e-02,\n",
       "                      -2.7293e-02, -1.9873e-02, -2.0227e-03, -4.6069e-03, -4.4246e-03,\n",
       "                      -1.0105e-02, -3.7288e-03, -3.6414e-03, -1.1150e-02, -2.5339e-04,\n",
       "                      -1.1993e-02, -3.4640e-02,  1.9147e-03, -1.8929e-02, -2.1089e-02,\n",
       "                      -3.1342e-02, -2.7336e-02,  1.4210e-03, -9.5011e-04, -4.8152e-03,\n",
       "                      -2.9789e-02, -3.8473e-03, -4.1320e-02, -9.8255e-03, -1.1458e-02,\n",
       "                      -3.0515e-03, -2.4124e-02, -1.1432e-03, -1.9695e-03, -1.7816e-03,\n",
       "                      -4.2958e-03, -2.7735e-03, -8.0559e-03, -2.7830e-02, -2.1532e-02,\n",
       "                      -2.6404e-02, -2.9531e-02, -2.3794e-02, -1.8107e-03, -2.2694e-04,\n",
       "                      -2.8656e-02, -7.3841e-03, -1.5596e-02, -2.6590e-02, -8.7057e-03,\n",
       "                      -9.9131e-04], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.running_mean',\n",
       "              tensor([-1.8729e-01, -1.9283e+00, -2.7152e+00, -4.4708e-01, -1.6679e+00,\n",
       "                      -1.1112e-01,  2.2969e+00, -2.7260e+00,  3.6841e-01, -1.8094e+00,\n",
       "                      -1.3862e+00, -1.8643e-01, -1.1138e-01, -7.4469e-01, -6.9950e-02,\n",
       "                       2.0408e-01,  7.5057e-02,  5.7138e-01, -9.7576e-01, -1.6465e+00,\n",
       "                       1.8113e-01, -1.6522e+00, -2.4368e-01, -1.1120e+00, -2.7228e+00,\n",
       "                      -2.8805e+00, -1.0084e+00, -1.4810e+00,  1.1562e+00, -1.4569e+00,\n",
       "                      -2.3262e+00, -1.5127e+00, -3.8706e+00, -2.5457e+00, -7.0736e-01,\n",
       "                      -1.5889e+00, -2.5262e-01,  9.5550e-01, -5.7013e-01, -1.0040e-03,\n",
       "                      -4.0613e-01, -3.2736e-02,  1.8569e-01, -1.3244e+00, -2.3611e+00,\n",
       "                       8.7894e-01, -1.6044e+00, -2.7503e+00, -1.6690e+00,  1.7125e+00,\n",
       "                       2.8261e-01, -1.7618e+00, -2.9753e+00, -2.6298e+00, -2.8450e-01,\n",
       "                      -1.8603e+00, -6.9346e-01,  2.3279e+00, -4.0744e-01,  4.1155e-01,\n",
       "                       1.1298e+00, -9.4747e-01, -1.2007e-01,  4.2476e-01, -1.6834e+00,\n",
       "                      -3.4436e-01, -1.4248e+00,  1.3596e+00,  1.3594e+00,  1.7701e+00,\n",
       "                       1.3051e-01, -7.7664e-01, -6.5316e-01, -3.1199e+00, -2.5899e+00,\n",
       "                       1.9274e+00, -2.6411e+00, -2.4474e+00, -2.8938e+00, -2.6592e+00,\n",
       "                      -2.1292e+00, -1.0803e+00,  1.2059e-01,  1.8301e+00,  7.2187e-01,\n",
       "                       1.5577e+00, -1.7170e+00, -3.5438e-01, -1.3508e+00, -2.8172e+00,\n",
       "                      -4.5615e-01, -2.1741e+00, -2.8810e+00, -1.5378e+00,  1.5773e+00,\n",
       "                      -2.5696e+00, -3.6982e-01, -1.0774e-01, -1.6686e+00, -2.6109e+00,\n",
       "                      -5.6164e-01, -2.4382e+00, -7.9057e-01, -9.3222e-02,  8.0547e-03,\n",
       "                      -4.4502e-01, -3.4088e-01, -9.0898e-01,  1.0884e+00,  3.0042e-01,\n",
       "                      -2.8564e+00, -2.4453e+00, -2.8460e+00, -1.3495e+00, -7.1647e-01,\n",
       "                       1.4016e+00,  2.1973e+00, -1.2021e+00, -1.2387e+00, -4.0980e-01,\n",
       "                      -3.3405e+00,  2.8910e-01,  7.8035e-01,  1.9978e+00, -1.8965e+00,\n",
       "                       4.7217e-01,  1.3882e+00, -2.6083e+00, -2.9855e+00, -2.2577e+00,\n",
       "                      -3.2671e+00, -2.6868e+00, -5.6683e-01,  1.4341e+00, -4.8108e-01,\n",
       "                      -6.9794e-01,  2.7146e+00,  6.9794e-01, -2.1577e-01, -1.4413e+00,\n",
       "                      -2.9137e+00, -2.2130e+00,  2.5828e-01, -2.0755e+00, -2.3988e+00,\n",
       "                       1.8065e+00, -1.4378e+00, -2.5075e+00, -1.6565e+00, -1.0530e+00,\n",
       "                      -2.0979e+00, -2.7843e+00, -1.8305e-01,  3.7709e-01,  6.2566e-01,\n",
       "                      -2.7204e+00, -2.7009e+00,  8.6293e-01,  1.5757e+00, -2.4939e+00,\n",
       "                      -3.0463e+00, -3.4079e+00, -2.8390e+00, -2.2880e+00,  1.0066e-01,\n",
       "                      -1.2052e+00, -1.1768e+00, -6.2470e-01,  7.4587e-01, -2.2811e+00,\n",
       "                       2.1234e+00,  1.0213e+00, -3.1828e+00, -6.3531e-01, -6.6702e-01,\n",
       "                      -1.3534e+00, -7.7057e-01,  1.8751e+00, -6.7159e-01, -1.6275e+00,\n",
       "                       1.4802e+00, -4.7679e-01, -2.6332e+00, -1.8467e+00, -1.3015e+00,\n",
       "                       1.8392e-01, -3.4492e+00, -2.9683e+00, -4.1454e-01, -5.0724e-01,\n",
       "                       2.1664e+00, -2.5345e+00, -1.0855e+00, -1.6995e-01, -1.5472e+00,\n",
       "                      -1.6102e-01,  4.4454e-01, -2.8363e+00,  2.9554e+00, -6.4750e-01,\n",
       "                      -1.8840e-01, -3.1729e+00, -2.9923e+00, -2.4104e+00, -1.6128e+00,\n",
       "                       6.4206e-01, -1.4918e+00, -7.3686e-03, -1.2799e+00, -2.3611e+00,\n",
       "                      -2.8566e+00, -2.5014e+00, -1.3467e+00,  1.4337e-01,  9.6075e-01,\n",
       "                      -3.0624e-01,  8.2148e-01, -1.3423e+00, -1.2902e+00, -1.4198e+00,\n",
       "                      -1.0033e+00, -3.0487e+00,  2.0789e-01, -7.2437e-01, -2.3113e+00,\n",
       "                      -3.0260e-01, -2.6378e+00, -1.0599e+00,  6.1898e-02,  9.8644e-01,\n",
       "                      -2.7977e+00, -6.2530e-02,  4.7233e-01,  2.6103e+00, -3.0873e-01,\n",
       "                       1.2872e+00, -1.2522e+00,  2.1927e-02, -2.1906e-01,  4.3241e+00,\n",
       "                      -1.9730e+00, -9.0910e-01, -1.1294e+00, -3.0266e+00, -2.3482e-01,\n",
       "                      -2.5265e+00, -2.8500e+00, -5.7451e-01,  2.8843e-01,  7.5611e-02,\n",
       "                      -2.6246e+00, -2.6263e-01, -1.5785e+00, -2.3320e+00, -7.6980e-01,\n",
       "                      -7.0826e-01], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.running_var',\n",
       "              tensor([3.2053, 2.5604, 5.9049, 2.7437, 3.6480, 3.1665, 2.2722, 5.1743, 3.9073,\n",
       "                      2.0267, 2.3758, 4.0997, 5.1472, 3.4694, 1.9826, 5.1471, 4.7914, 3.7848,\n",
       "                      2.8916, 6.0142, 1.1062, 2.1657, 2.4009, 3.4791, 2.8419, 3.7002, 2.3035,\n",
       "                      2.6480, 3.1111, 2.3645, 3.1551, 1.8291, 6.4794, 4.3999, 1.4692, 3.6785,\n",
       "                      2.8905, 3.3757, 2.2725, 6.0140, 3.5259, 4.0621, 1.7911, 3.6767, 3.2970,\n",
       "                      3.5941, 2.7838, 2.9609, 2.2138, 2.6025, 3.2244, 2.8758, 3.1377, 3.2491,\n",
       "                      2.9377, 2.6901, 4.1329, 3.3325, 3.1177, 1.8574, 2.8032, 3.5430, 2.3272,\n",
       "                      1.1091, 6.2180, 3.8937, 2.3304, 4.7532, 2.2463, 3.5833, 1.9162, 1.8222,\n",
       "                      1.9937, 4.4656, 2.6069, 3.9986, 2.4098, 2.7852, 2.4094, 2.8446, 2.6785,\n",
       "                      2.7371, 6.8089, 5.1209, 3.2998, 3.3743, 2.4248, 5.6533, 2.3304, 2.9707,\n",
       "                      2.5902, 2.7807, 4.4385, 2.0903, 1.2960, 2.7100, 1.3390, 2.9116, 3.1258,\n",
       "                      3.0892, 2.3241, 3.0039, 2.2315, 2.8319, 2.2328, 2.4816, 3.3877, 0.5166,\n",
       "                      2.9881, 1.4166, 4.0311, 3.2807, 3.3573, 3.1560, 1.9260, 2.9588, 2.7120,\n",
       "                      2.0129, 2.9320, 2.6232, 4.0140, 3.5657, 1.3153, 6.6351, 1.6518, 2.2870,\n",
       "                      3.4862, 2.8535, 2.9351, 3.4713, 4.7307, 2.9798, 2.5508, 4.3426, 3.1313,\n",
       "                      2.4620, 2.1644, 2.0588, 1.9788, 1.9381, 2.8104, 3.2702, 4.1016, 3.6010,\n",
       "                      2.9911, 4.9905, 1.7867, 2.4412, 2.3617, 2.1938, 1.9146, 3.4345, 3.5247,\n",
       "                      2.5194, 1.1228, 4.4582, 4.7123, 3.3083, 2.6098, 2.9510, 2.3132, 3.7249,\n",
       "                      1.7492, 2.1304, 1.3393, 2.0791, 1.9459, 1.9496, 2.3565, 2.2558, 2.5642,\n",
       "                      4.1469, 4.6202, 2.9375, 2.8695, 0.8710, 3.5671, 5.1296, 2.6986, 4.0301,\n",
       "                      1.8834, 2.3813, 2.9751, 3.2994, 1.7315, 2.7889, 2.6066, 2.7818, 2.3967,\n",
       "                      6.6169, 5.7527, 2.5780, 1.8226, 3.6506, 2.0603, 2.9066, 2.7598, 3.7726,\n",
       "                      2.2135, 1.8678, 1.2249, 3.4082, 2.4734, 1.4770, 1.8918, 3.2795, 2.2429,\n",
       "                      0.9242, 2.0483, 2.7246, 2.5032, 2.4811, 1.6542, 3.4523, 3.1470, 4.5426,\n",
       "                      2.9838, 2.2116, 5.9327, 2.7090, 2.7470, 6.3383, 2.3129, 0.9440, 2.3217,\n",
       "                      4.2784, 2.3931, 1.5029, 2.0647, 1.2627, 3.2136, 2.1922, 7.7512, 3.0597,\n",
       "                      2.6600, 3.4313, 1.7954, 2.3802, 2.7410, 5.6522, 2.5558, 2.7033, 2.3623,\n",
       "                      2.5911, 1.2073, 3.4416, 2.6123, 7.9432, 2.7366, 2.9903, 3.7970, 3.2590,\n",
       "                      2.3484, 4.6299, 2.0230, 1.8128], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.num_batches_tracked',\n",
       "              tensor(1640, device='cuda:0'))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "murmur_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c0203a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 5.2664e-02, -2.3621e-02, -5.7778e-03,  ..., -1.8121e-01,\n",
       "                       -2.3270e-02,  1.8890e-02],\n",
       "                      [-2.0353e-02, -1.7798e-05,  3.6760e-02,  ..., -9.0222e-02,\n",
       "                        5.7871e-02, -5.7393e-02],\n",
       "                      [ 1.2607e-02, -2.9261e-02,  5.2072e-02,  ...,  1.8439e-01,\n",
       "                       -6.4841e-02,  9.0208e-04],\n",
       "                      ...,\n",
       "                      [ 4.3480e-02, -6.7770e-03, -2.3513e-02,  ...,  1.5622e-01,\n",
       "                       -5.9886e-02,  5.3757e-02],\n",
       "                      [ 3.2086e-02, -1.7788e-02, -4.7139e-02,  ..., -1.5601e-01,\n",
       "                        6.4623e-02,  3.6662e-02],\n",
       "                      [-4.6768e-02,  2.5411e-02, -9.8036e-03,  ..., -7.2157e-02,\n",
       "                       -4.3569e-02,  2.6072e-03]], device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0567,  0.0568,  0.0258,  0.0274,  0.0398,  0.0519, -0.0299,  0.0176,\n",
       "                      -0.0615,  0.0173, -0.0350, -0.0567,  0.0109,  0.0254,  0.0219,  0.0552,\n",
       "                       0.0502,  0.0020, -0.0279, -0.0446,  0.0330, -0.0053,  0.0010,  0.0408,\n",
       "                       0.0502, -0.0149,  0.0433, -0.0165, -0.0283, -0.0167, -0.0266,  0.0095,\n",
       "                       0.0339, -0.0540,  0.0081,  0.0331,  0.0490,  0.0422, -0.0065,  0.0127,\n",
       "                       0.0129,  0.0595, -0.0352,  0.0554, -0.0575,  0.0198, -0.0531, -0.0630,\n",
       "                      -0.0039, -0.0438, -0.0124,  0.0479, -0.0253,  0.0039,  0.0136,  0.0090,\n",
       "                       0.0531,  0.0528,  0.0279,  0.0450,  0.0056, -0.0329,  0.0452,  0.0619,\n",
       "                       0.0034,  0.0461,  0.0174,  0.0015,  0.0122, -0.0187, -0.0058,  0.0092,\n",
       "                      -0.0573,  0.0408, -0.0414,  0.0323, -0.0615, -0.0316,  0.0517, -0.0405,\n",
       "                       0.0185,  0.0373, -0.0330,  0.0002, -0.0537,  0.0317, -0.0574,  0.0342,\n",
       "                      -0.0372,  0.0637,  0.0004,  0.0253, -0.0009, -0.0007,  0.0127, -0.0359,\n",
       "                       0.0388, -0.0561,  0.0011,  0.0505, -0.0208,  0.0020, -0.0022, -0.0497,\n",
       "                      -0.0624, -0.0055, -0.0383,  0.0093, -0.0147,  0.0263, -0.0261,  0.0132,\n",
       "                       0.0629, -0.0174,  0.0270,  0.0151, -0.0331, -0.0012, -0.0545, -0.0112,\n",
       "                       0.0218,  0.0214, -0.0553,  0.0462, -0.0041, -0.0008,  0.0200,  0.0314,\n",
       "                      -0.0086,  0.0347, -0.0632,  0.0586], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0345, -0.0799,  0.0751, -0.0314,  0.0536, -0.0837, -0.0293, -0.0053,\n",
       "                       -0.0135,  0.0710,  0.0533, -0.0542,  0.0606, -0.0901,  0.0398, -0.0307,\n",
       "                        0.0040,  0.0349,  0.0433, -0.0407, -0.0363, -0.0693,  0.0678, -0.0357,\n",
       "                        0.0634, -0.0354, -0.0110,  0.0133, -0.0259,  0.0786,  0.0486, -0.0103,\n",
       "                       -0.0404,  0.0089,  0.0725, -0.0075, -0.0200, -0.0327,  0.0716, -0.0791,\n",
       "                       -0.0431, -0.0449, -0.0441, -0.0604,  0.0236, -0.0232, -0.0573,  0.0303,\n",
       "                        0.0480, -0.0304, -0.0282,  0.0866, -0.0450, -0.0059,  0.0065, -0.0737,\n",
       "                       -0.0374, -0.0669, -0.0592, -0.0536, -0.0440,  0.0060, -0.0847, -0.0653,\n",
       "                        0.0775, -0.0438,  0.0727, -0.0863,  0.0497, -0.0036, -0.0822,  0.0192,\n",
       "                        0.0505,  0.0551,  0.0302, -0.0401,  0.0550, -0.0702,  0.0212, -0.0520,\n",
       "                       -0.0550, -0.0842,  0.0452, -0.0844,  0.0686, -0.0492,  0.0029,  0.0547,\n",
       "                       -0.0104, -0.0403,  0.0135, -0.0126, -0.0737, -0.0224,  0.0600,  0.0276,\n",
       "                       -0.0160,  0.0323, -0.0687, -0.0336,  0.0281, -0.0042, -0.0586, -0.0564,\n",
       "                       -0.0559, -0.0144, -0.0184,  0.0561, -0.0122,  0.0798,  0.0656,  0.0022,\n",
       "                        0.0752, -0.0361, -0.0077, -0.0370,  0.0658, -0.0675, -0.0793,  0.0802,\n",
       "                       -0.0062, -0.0073, -0.0232, -0.0302, -0.0676,  0.0383, -0.0464,  0.0778,\n",
       "                       -0.0767,  0.0777, -0.0074, -0.0244],\n",
       "                      [ 0.0506, -0.0638,  0.0359,  0.0860,  0.0238, -0.0637,  0.0137,  0.0588,\n",
       "                        0.0031, -0.0071, -0.0826,  0.0370,  0.0712,  0.0881, -0.0591,  0.0114,\n",
       "                        0.0727, -0.0633, -0.0124, -0.0062,  0.0787,  0.0559,  0.0186, -0.0198,\n",
       "                        0.0592,  0.0499,  0.0331, -0.0638,  0.0668,  0.0041,  0.0318, -0.0489,\n",
       "                        0.0566,  0.0895, -0.0620, -0.0561, -0.0612,  0.0437,  0.0086,  0.0718,\n",
       "                       -0.0761,  0.0696,  0.0065, -0.0636,  0.0591, -0.0460, -0.0563,  0.0565,\n",
       "                       -0.0350,  0.0321,  0.0474,  0.0828, -0.0638, -0.0164,  0.0188, -0.0709,\n",
       "                       -0.0038, -0.0700,  0.0256, -0.0258, -0.0626, -0.0034,  0.0414, -0.0799,\n",
       "                       -0.0799, -0.0250,  0.0208, -0.0418, -0.0274,  0.0190, -0.0067, -0.0102,\n",
       "                       -0.0203, -0.0603,  0.0776, -0.0742, -0.0377, -0.0724, -0.0495,  0.0015,\n",
       "                       -0.0166, -0.0065,  0.0097, -0.0754,  0.0048,  0.0642,  0.0779, -0.0377,\n",
       "                       -0.0044,  0.0731,  0.0026, -0.0833, -0.0022,  0.0810, -0.0695,  0.0330,\n",
       "                       -0.0321, -0.0453, -0.0501, -0.0280,  0.0796, -0.0260, -0.0690, -0.0576,\n",
       "                       -0.0678,  0.0254,  0.0220,  0.0680, -0.0684,  0.0642,  0.0458, -0.0450,\n",
       "                        0.0641,  0.0211, -0.0550, -0.0713, -0.0235,  0.0052, -0.0367,  0.0255,\n",
       "                        0.0498,  0.0378,  0.0033,  0.0087, -0.0557,  0.0772,  0.0080,  0.0742,\n",
       "                        0.0275, -0.0431,  0.0189,  0.0268]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([-0.0237,  0.0515], device='cuda:0')),\n",
       "             ('fc_age.weight',\n",
       "              tensor([[-2.5692e-01, -2.0785e-04, -7.1705e-02,  1.4075e-01,  1.4925e-01,\n",
       "                       -1.8776e-01],\n",
       "                      [-3.8351e-01,  6.9789e-02, -3.1701e-01,  2.3892e-02, -6.8890e-02,\n",
       "                       -3.8088e-01],\n",
       "                      [ 3.0801e-01,  3.3748e-02, -1.7618e-01,  4.3203e-01,  6.1474e-02,\n",
       "                       -3.4227e-01]], device='cuda:0')),\n",
       "             ('fc_age.bias',\n",
       "              tensor([-0.1523,  0.2448,  0.3122], device='cuda:0')),\n",
       "             ('fc_sex.weight', tensor([[-0.2536,  0.3885]], device='cuda:0')),\n",
       "             ('fc_sex.bias', tensor([0.1307], device='cuda:0')),\n",
       "             ('fc_hw.weight', tensor([[ 0.4014, -0.3463]], device='cuda:0')),\n",
       "             ('fc_hw.bias', tensor([-0.6549], device='cuda:0')),\n",
       "             ('fc_preg.weight', tensor([[-0.7378,  0.6921]], device='cuda:0')),\n",
       "             ('fc_preg.bias', tensor([-0.4844], device='cuda:0')),\n",
       "             ('fc_loc.weight',\n",
       "              tensor([[-0.4051, -0.2389, -0.1414,  0.3095,  0.3107],\n",
       "                      [ 0.0200, -0.3718,  0.0299, -0.3702, -0.0848]], device='cuda:0')),\n",
       "             ('fc_loc.bias', tensor([ 0.3541, -0.0873], device='cuda:0')),\n",
       "             ('cnn.conv0.weight',\n",
       "              tensor([[[[-0.3467, -0.1764, -0.1944],\n",
       "                        [ 0.0524,  0.2086, -0.2491],\n",
       "                        [ 0.0160,  0.0412, -0.2265]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0401,  0.2702,  0.0339],\n",
       "                        [ 0.2688, -0.0143,  0.1941],\n",
       "                        [ 0.2903, -0.0332, -0.0354]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2904, -0.2762,  0.3231],\n",
       "                        [ 0.2784,  0.3124,  0.0703],\n",
       "                        [ 0.3218, -0.0557,  0.1477]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1957,  0.1000,  0.2142],\n",
       "                        [-0.1471, -0.1874, -0.0119],\n",
       "                        [-0.0848,  0.1730,  0.0079]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1582, -0.1522,  0.1755],\n",
       "                        [ 0.2287, -0.2749,  0.1914],\n",
       "                        [-0.1217, -0.2244,  0.3271]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0148,  0.1591, -0.0585],\n",
       "                        [ 0.2538,  0.0406, -0.2950],\n",
       "                        [ 0.3305,  0.0335, -0.3087]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1287,  0.2933, -0.0733],\n",
       "                        [-0.1872, -0.2618, -0.3127],\n",
       "                        [ 0.2392, -0.0890, -0.3933]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1678,  0.0879,  0.2824],\n",
       "                        [ 0.0452,  0.1633, -0.2695],\n",
       "                        [-0.1130, -0.2432, -0.0802]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1742,  0.1766, -0.0435],\n",
       "                        [ 0.0183,  0.1098,  0.1697],\n",
       "                        [-0.1150, -0.1577, -0.1342]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2630,  0.0657, -0.1647],\n",
       "                        [ 0.2968,  0.1270, -0.1631],\n",
       "                        [ 0.1058, -0.2052, -0.3003]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0213, -0.1815, -0.0477],\n",
       "                        [-0.3113, -0.2285, -0.0668],\n",
       "                        [-0.2501,  0.1601,  0.2748]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0361,  0.1158,  0.2968],\n",
       "                        [-0.0898,  0.3089,  0.1898],\n",
       "                        [-0.1067, -0.2934,  0.1153]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1686, -0.3146,  0.2443],\n",
       "                        [-0.2952,  0.2879,  0.1616],\n",
       "                        [-0.1161, -0.2136, -0.0458]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2210, -0.2501,  0.2684],\n",
       "                        [ 0.2895,  0.0879,  0.1802],\n",
       "                        [-0.0152, -0.0710,  0.2094]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2523, -0.3221,  0.2007],\n",
       "                        [-0.2904, -0.1842,  0.1326],\n",
       "                        [-0.3362,  0.1198,  0.3064]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2042, -0.2414,  0.1071],\n",
       "                        [-0.2137, -0.2790, -0.0829],\n",
       "                        [ 0.1935,  0.3336, -0.1369]]]], device='cuda:0')),\n",
       "             ('cnn.conv0.bias',\n",
       "              tensor([ 0.2418, -0.2498, -0.1413,  0.3249,  0.1461,  0.3232,  0.2824, -0.0041,\n",
       "                      -0.1179, -0.1434, -0.0737, -0.2863, -0.1606, -0.1582,  0.2551,  0.3276],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.weight',\n",
       "              tensor([0.9796, 0.9782, 0.9887, 1.0182, 1.0085, 1.0226, 0.9733, 1.0311, 1.0202,\n",
       "                      1.0174, 0.9890, 1.0003, 0.9756, 0.9897, 0.9913, 0.9830],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.bias',\n",
       "              tensor([-0.0317, -0.0013, -0.0230,  0.0071, -0.0085, -0.0093, -0.0030,  0.0115,\n",
       "                      -0.0116, -0.0372, -0.0209, -0.0156, -0.0035,  0.0020, -0.0027, -0.0103],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm0.running_mean',\n",
       "              tensor([-46.6783,  49.9977,  75.7504,  -6.8515,  -0.3393,   9.4507, -48.8964,\n",
       "                        2.3048,  10.7579,   1.3828, -36.4063,  26.8257, -24.7256,  49.3389,\n",
       "                      -33.4777, -28.0835], device='cuda:0')),\n",
       "             ('cnn.batchnorm0.running_var',\n",
       "              tensor([137.2907, 145.5764, 329.5369,  12.8822,  20.3775,  39.7337, 154.9881,\n",
       "                       18.0776,  12.2720,  38.2256,  85.9691,  58.3927,  57.1267, 139.2944,\n",
       "                      114.1701,  49.9315], device='cuda:0')),\n",
       "             ('cnn.batchnorm0.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0')),\n",
       "             ('cnn.conv1.weight',\n",
       "              tensor([[[[ 0.0388, -0.0592,  0.0549],\n",
       "                        [-0.0297, -0.0463,  0.0585],\n",
       "                        [ 0.0924,  0.0343, -0.0394]],\n",
       "              \n",
       "                       [[ 0.0964, -0.0373,  0.0033],\n",
       "                        [ 0.0342,  0.0649,  0.0556],\n",
       "                        [-0.0059, -0.0641, -0.0609]],\n",
       "              \n",
       "                       [[ 0.0076, -0.0589,  0.0694],\n",
       "                        [ 0.0400,  0.0274,  0.0262],\n",
       "                        [-0.0489, -0.0714, -0.0892]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0573, -0.0395, -0.0372],\n",
       "                        [-0.0660, -0.0729, -0.0530],\n",
       "                        [-0.0764, -0.0776, -0.0165]],\n",
       "              \n",
       "                       [[ 0.0573, -0.0546,  0.0310],\n",
       "                        [-0.0223,  0.0585, -0.0530],\n",
       "                        [ 0.0068, -0.0411,  0.0575]],\n",
       "              \n",
       "                       [[-0.0417, -0.0599, -0.0479],\n",
       "                        [-0.0018,  0.0573,  0.0445],\n",
       "                        [ 0.0271,  0.0810, -0.0618]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0822,  0.0353, -0.0359],\n",
       "                        [-0.0933,  0.0101,  0.0391],\n",
       "                        [ 0.0345, -0.0428,  0.0722]],\n",
       "              \n",
       "                       [[-0.0051, -0.0664,  0.0013],\n",
       "                        [ 0.0107,  0.0432,  0.0724],\n",
       "                        [ 0.0510, -0.0190,  0.0671]],\n",
       "              \n",
       "                       [[-0.0950, -0.0119, -0.0892],\n",
       "                        [ 0.0190,  0.0185, -0.0548],\n",
       "                        [-0.0363, -0.0459, -0.0730]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0110,  0.0549,  0.0432],\n",
       "                        [ 0.0543, -0.0055,  0.0206],\n",
       "                        [-0.0664,  0.0577,  0.0369]],\n",
       "              \n",
       "                       [[-0.0276, -0.0670,  0.0100],\n",
       "                        [ 0.0567, -0.0877, -0.0450],\n",
       "                        [-0.0230,  0.0531, -0.0288]],\n",
       "              \n",
       "                       [[-0.0697,  0.0105, -0.0245],\n",
       "                        [-0.0775, -0.0141,  0.0002],\n",
       "                        [-0.1062, -0.0691,  0.0658]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0507,  0.0446,  0.0513],\n",
       "                        [-0.0314, -0.0285,  0.0151],\n",
       "                        [ 0.0253,  0.0550, -0.0043]],\n",
       "              \n",
       "                       [[-0.0447, -0.0423,  0.0260],\n",
       "                        [-0.0191, -0.0025, -0.0280],\n",
       "                        [ 0.0634,  0.0594, -0.0003]],\n",
       "              \n",
       "                       [[ 0.0033, -0.0419,  0.0957],\n",
       "                        [-0.0564, -0.0202, -0.0530],\n",
       "                        [ 0.0669, -0.0698, -0.0369]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0317,  0.0309,  0.0505],\n",
       "                        [-0.0568, -0.0544,  0.0732],\n",
       "                        [ 0.0295,  0.0719,  0.0969]],\n",
       "              \n",
       "                       [[-0.0787, -0.0285,  0.0110],\n",
       "                        [ 0.0494, -0.0570,  0.0553],\n",
       "                        [ 0.0583, -0.0244,  0.0479]],\n",
       "              \n",
       "                       [[-0.0457, -0.0656,  0.0708],\n",
       "                        [-0.0118, -0.0142, -0.0372],\n",
       "                        [-0.0102,  0.0458,  0.0388]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0260, -0.0640,  0.0075],\n",
       "                        [-0.0549, -0.0095,  0.0705],\n",
       "                        [ 0.0752,  0.0741, -0.0046]],\n",
       "              \n",
       "                       [[-0.0063,  0.0409, -0.0334],\n",
       "                        [ 0.0732, -0.0027, -0.0372],\n",
       "                        [-0.0183, -0.0069,  0.0875]],\n",
       "              \n",
       "                       [[-0.0181,  0.0880,  0.0719],\n",
       "                        [-0.0109, -0.0511, -0.0265],\n",
       "                        [-0.0375,  0.0040, -0.0730]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0297,  0.0321,  0.0059],\n",
       "                        [ 0.0755, -0.0616, -0.0359],\n",
       "                        [-0.0353,  0.0671,  0.0734]],\n",
       "              \n",
       "                       [[-0.0425,  0.0852, -0.0435],\n",
       "                        [ 0.0734,  0.0266, -0.0166],\n",
       "                        [ 0.0952,  0.0677,  0.0588]],\n",
       "              \n",
       "                       [[ 0.0777,  0.0609,  0.0570],\n",
       "                        [-0.0157,  0.0532,  0.0916],\n",
       "                        [-0.0320, -0.0604,  0.0147]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0475, -0.0203,  0.0366],\n",
       "                        [-0.0540, -0.0432,  0.0144],\n",
       "                        [-0.0965,  0.0042,  0.0486]],\n",
       "              \n",
       "                       [[-0.0700,  0.0268, -0.0846],\n",
       "                        [-0.0350, -0.0543,  0.0643],\n",
       "                        [-0.0537, -0.0104, -0.0300]],\n",
       "              \n",
       "                       [[ 0.0718, -0.0634,  0.0546],\n",
       "                        [ 0.0488, -0.0589, -0.0379],\n",
       "                        [ 0.0373,  0.0057,  0.0505]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0790,  0.0629,  0.0787],\n",
       "                        [ 0.0036,  0.0383,  0.0393],\n",
       "                        [ 0.0480,  0.0004,  0.0206]],\n",
       "              \n",
       "                       [[-0.0162,  0.0622, -0.0332],\n",
       "                        [-0.0571, -0.0052, -0.0907],\n",
       "                        [ 0.0045, -0.0486, -0.0054]],\n",
       "              \n",
       "                       [[-0.0560,  0.0402,  0.0147],\n",
       "                        [ 0.0096,  0.0369,  0.0097],\n",
       "                        [ 0.0331,  0.0297,  0.0535]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0426,  0.0230,  0.0650],\n",
       "                        [ 0.0267, -0.0696, -0.0701],\n",
       "                        [-0.0061, -0.0657,  0.0606]],\n",
       "              \n",
       "                       [[-0.0624,  0.0233, -0.0211],\n",
       "                        [ 0.0637, -0.0551,  0.0568],\n",
       "                        [ 0.0105,  0.0151, -0.0565]],\n",
       "              \n",
       "                       [[ 0.0835,  0.0456,  0.0755],\n",
       "                        [ 0.0151, -0.0701, -0.0137],\n",
       "                        [-0.0381,  0.0384, -0.0910]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0364,  0.0947,  0.0248],\n",
       "                        [-0.0638,  0.0396, -0.0459],\n",
       "                        [ 0.0636,  0.0566,  0.0672]],\n",
       "              \n",
       "                       [[ 0.0497,  0.0298, -0.0030],\n",
       "                        [-0.0783,  0.0633, -0.0078],\n",
       "                        [-0.0052,  0.0012, -0.0163]],\n",
       "              \n",
       "                       [[-0.0012,  0.0694, -0.0497],\n",
       "                        [ 0.0906,  0.0085,  0.0597],\n",
       "                        [ 0.0522,  0.0505, -0.0830]]]], device='cuda:0')),\n",
       "             ('cnn.conv1.bias',\n",
       "              tensor([-0.0258,  0.0755,  0.0013, -0.0332,  0.0290,  0.0267, -0.0655, -0.0012,\n",
       "                       0.0576, -0.0764, -0.0506,  0.0703, -0.0265, -0.0078,  0.0019, -0.0003,\n",
       "                       0.0696,  0.0650, -0.0603,  0.0688,  0.0844,  0.0321,  0.0032, -0.0596,\n",
       "                      -0.0530,  0.0434,  0.0553,  0.0608,  0.0060,  0.0181, -0.0597,  0.0608],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.weight',\n",
       "              tensor([0.9882, 1.0351, 1.0033, 1.0232, 1.0330, 0.9494, 0.9668, 0.9834, 1.0063,\n",
       "                      0.9873, 0.9705, 0.9943, 1.0278, 0.9892, 1.0128, 1.0133, 0.9928, 0.9840,\n",
       "                      0.9958, 0.9662, 1.0216, 0.9778, 0.9715, 1.0065, 0.9969, 1.0043, 0.9731,\n",
       "                      1.0219, 0.9949, 0.9967, 0.9984, 1.0355], device='cuda:0')),\n",
       "             ('cnn.batchnorm1.bias',\n",
       "              tensor([-0.0336,  0.0033, -0.0202, -0.0447,  0.0049, -0.0526, -0.0477, -0.0591,\n",
       "                      -0.0515, -0.0344, -0.0284,  0.0050, -0.0461,  0.0014, -0.0323, -0.0285,\n",
       "                      -0.0112, -0.0184, -0.0194, -0.0258,  0.0114, -0.0320, -0.0027,  0.0047,\n",
       "                      -0.0123, -0.0212, -0.0573, -0.0249, -0.0541, -0.0388, -0.0081, -0.0337],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.running_mean',\n",
       "              tensor([-0.0617, -0.1425,  0.2612,  0.4598,  0.2305, -0.4665,  0.3205,  0.2435,\n",
       "                       0.2343,  0.0728, -0.1199,  0.1011,  0.4285,  0.1611, -0.3380, -0.5440,\n",
       "                      -0.6309,  0.0466,  0.6436,  0.4665, -0.2559, -0.5440, -1.4718, -0.5742,\n",
       "                      -0.8589, -0.2978,  0.8978, -0.1329,  0.0643,  0.4245, -0.3031, -0.1236],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm1.running_var',\n",
       "              tensor([0.5812, 0.1045, 0.3426, 0.2050, 0.1635, 0.2921, 0.7721, 0.2033, 0.1322,\n",
       "                      0.1330, 0.4375, 0.2941, 0.2283, 0.3444, 0.3437, 0.1609, 0.2375, 0.2266,\n",
       "                      0.2954, 0.3821, 0.1825, 0.1689, 0.9102, 0.2565, 0.3458, 0.1329, 0.5203,\n",
       "                      0.1176, 0.3949, 0.1618, 0.1359, 0.1412], device='cuda:0')),\n",
       "             ('cnn.batchnorm1.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0')),\n",
       "             ('cnn.conv2.weight',\n",
       "              tensor([[[[ 0.0122, -0.0353, -0.0351],\n",
       "                        [ 0.0326, -0.0446, -0.0120],\n",
       "                        [ 0.0103, -0.0012, -0.0250]],\n",
       "              \n",
       "                       [[ 0.0407,  0.0440,  0.0365],\n",
       "                        [ 0.0508,  0.0686, -0.0419],\n",
       "                        [ 0.0692,  0.0684,  0.0540]],\n",
       "              \n",
       "                       [[-0.0623,  0.0174, -0.0650],\n",
       "                        [-0.0650,  0.0230, -0.0510],\n",
       "                        [ 0.0403, -0.0099,  0.0380]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0155, -0.0045, -0.0215],\n",
       "                        [ 0.0623,  0.0033, -0.0085],\n",
       "                        [-0.0340, -0.0089, -0.0742]],\n",
       "              \n",
       "                       [[-0.0613, -0.0124,  0.0275],\n",
       "                        [-0.0142,  0.0550,  0.0183],\n",
       "                        [-0.0221, -0.0069,  0.0055]],\n",
       "              \n",
       "                       [[-0.0122,  0.0318,  0.0308],\n",
       "                        [ 0.0330,  0.0220,  0.0357],\n",
       "                        [-0.0490,  0.0151,  0.0544]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0165, -0.0537, -0.0327],\n",
       "                        [-0.0399, -0.0208, -0.0091],\n",
       "                        [-0.0520,  0.0414, -0.0150]],\n",
       "              \n",
       "                       [[ 0.0142,  0.0290, -0.0103],\n",
       "                        [ 0.0466,  0.0432,  0.0393],\n",
       "                        [ 0.0137, -0.0249,  0.0325]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0307,  0.0256],\n",
       "                        [-0.0027, -0.0438,  0.0096],\n",
       "                        [-0.0251,  0.0057,  0.0130]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0534,  0.0497, -0.0618],\n",
       "                        [-0.0061,  0.0393, -0.0104],\n",
       "                        [ 0.0374, -0.0669, -0.0440]],\n",
       "              \n",
       "                       [[-0.0546,  0.0167,  0.0187],\n",
       "                        [-0.0216, -0.0151, -0.0003],\n",
       "                        [-0.0209,  0.0209, -0.0312]],\n",
       "              \n",
       "                       [[-0.0481, -0.0402, -0.0072],\n",
       "                        [-0.0411, -0.0092,  0.0614],\n",
       "                        [ 0.0042,  0.0202,  0.0134]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0602,  0.0630, -0.0151],\n",
       "                        [ 0.0075,  0.0281,  0.0211],\n",
       "                        [ 0.0159, -0.0377,  0.0135]],\n",
       "              \n",
       "                       [[ 0.0005,  0.0051, -0.0059],\n",
       "                        [-0.0243, -0.0490,  0.0552],\n",
       "                        [-0.0492, -0.0394, -0.0080]],\n",
       "              \n",
       "                       [[-0.0274,  0.0080, -0.0260],\n",
       "                        [-0.0157, -0.0052, -0.0180],\n",
       "                        [-0.0396, -0.0458, -0.0927]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0087, -0.0575,  0.0632],\n",
       "                        [-0.0025, -0.0014, -0.0418],\n",
       "                        [-0.0328, -0.0512, -0.0240]],\n",
       "              \n",
       "                       [[ 0.0368,  0.0492,  0.0550],\n",
       "                        [-0.0285, -0.0137,  0.0594],\n",
       "                        [-0.0030,  0.0697,  0.0664]],\n",
       "              \n",
       "                       [[ 0.0006, -0.0303,  0.0208],\n",
       "                        [ 0.0227, -0.0288,  0.0203],\n",
       "                        [-0.0004, -0.0161,  0.0453]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[-0.0634,  0.0250,  0.0193],\n",
       "                        [ 0.0390,  0.0335, -0.0193],\n",
       "                        [-0.0008, -0.0135,  0.0164]],\n",
       "              \n",
       "                       [[ 0.0092, -0.0502, -0.0474],\n",
       "                        [-0.0052, -0.0007,  0.0474],\n",
       "                        [-0.0369, -0.0508,  0.0688]],\n",
       "              \n",
       "                       [[ 0.0069, -0.0651,  0.0258],\n",
       "                        [-0.0368, -0.0602,  0.0444],\n",
       "                        [ 0.0349,  0.0447,  0.0203]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0030,  0.0779,  0.0155],\n",
       "                        [ 0.0428,  0.0176,  0.0067],\n",
       "                        [ 0.0301, -0.0294, -0.0491]],\n",
       "              \n",
       "                       [[-0.0263,  0.0432, -0.0003],\n",
       "                        [-0.0043, -0.0004, -0.0079],\n",
       "                        [-0.0069, -0.0062,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0298,  0.0349,  0.0717],\n",
       "                        [-0.0229,  0.0112,  0.0890],\n",
       "                        [-0.0013,  0.0281,  0.0770]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0314, -0.0288,  0.0390],\n",
       "                        [ 0.0227, -0.0090,  0.0470],\n",
       "                        [-0.0230,  0.0401, -0.0618]],\n",
       "              \n",
       "                       [[-0.0498,  0.0492, -0.0020],\n",
       "                        [-0.0326, -0.0304, -0.0231],\n",
       "                        [-0.0621,  0.0008, -0.0225]],\n",
       "              \n",
       "                       [[ 0.0650, -0.0338,  0.0307],\n",
       "                        [-0.0309,  0.0341, -0.0271],\n",
       "                        [-0.0319,  0.0205, -0.0007]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0086, -0.0220,  0.0715],\n",
       "                        [-0.0106,  0.0446,  0.0328],\n",
       "                        [ 0.0270,  0.0109, -0.0075]],\n",
       "              \n",
       "                       [[-0.0380, -0.0412,  0.0397],\n",
       "                        [-0.0257,  0.0413, -0.0511],\n",
       "                        [-0.0174,  0.0133, -0.0223]],\n",
       "              \n",
       "                       [[ 0.0358, -0.0180, -0.0215],\n",
       "                        [-0.0088,  0.0198, -0.0014],\n",
       "                        [ 0.0106, -0.0036,  0.0142]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0219, -0.0304,  0.0573],\n",
       "                        [ 0.0285,  0.0228, -0.0120],\n",
       "                        [ 0.0209,  0.0377,  0.0499]],\n",
       "              \n",
       "                       [[ 0.0805,  0.0090, -0.0187],\n",
       "                        [ 0.0614,  0.0142,  0.0481],\n",
       "                        [ 0.0648, -0.0251, -0.0374]],\n",
       "              \n",
       "                       [[ 0.0271,  0.0159, -0.0146],\n",
       "                        [ 0.0379, -0.0356, -0.0223],\n",
       "                        [-0.0124, -0.0410,  0.0056]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0375,  0.0376, -0.0417],\n",
       "                        [-0.0509,  0.0337,  0.0175],\n",
       "                        [-0.0585, -0.0300, -0.0471]],\n",
       "              \n",
       "                       [[ 0.0182, -0.0861, -0.0459],\n",
       "                        [ 0.0111,  0.0318,  0.0426],\n",
       "                        [ 0.0218, -0.0365,  0.0350]],\n",
       "              \n",
       "                       [[ 0.0561,  0.0571, -0.0755],\n",
       "                        [ 0.0700,  0.0155, -0.0308],\n",
       "                        [ 0.0573, -0.0070,  0.0056]]]], device='cuda:0')),\n",
       "             ('cnn.conv2.bias',\n",
       "              tensor([ 0.0265, -0.0437,  0.0314,  0.0329, -0.0383, -0.0448,  0.0033, -0.0535,\n",
       "                       0.0274, -0.0199, -0.0053,  0.0393, -0.0046, -0.0570,  0.0219, -0.0475,\n",
       "                      -0.0023,  0.0122, -0.0484, -0.0246, -0.0387,  0.0356, -0.0196, -0.0324,\n",
       "                       0.0157, -0.0008,  0.0031,  0.0481, -0.0025,  0.0390,  0.0003, -0.0148,\n",
       "                       0.0330, -0.0169,  0.0486, -0.0257,  0.0062,  0.0586,  0.0491, -0.0060,\n",
       "                      -0.0171,  0.0433,  0.0343,  0.0392,  0.0483,  0.0313,  0.0223,  0.0164,\n",
       "                       0.0011, -0.0164, -0.0060, -0.0384,  0.0115,  0.0447,  0.0219,  0.0113,\n",
       "                      -0.0143,  0.0301,  0.0327,  0.0121, -0.0058,  0.0203,  0.0206, -0.0079],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm2.weight',\n",
       "              tensor([0.9925, 0.9888, 0.9962, 0.9942, 0.9834, 1.0154, 0.9974, 0.9603, 1.0173,\n",
       "                      1.0010, 0.9645, 0.9596, 1.0363, 0.9752, 0.9906, 1.0640, 0.9648, 0.9796,\n",
       "                      1.0046, 1.0357, 0.9560, 1.0025, 0.9643, 1.0479, 0.9800, 0.9679, 0.9819,\n",
       "                      0.9617, 0.9633, 0.9869, 0.9656, 0.9640, 0.9979, 1.0404, 1.0146, 1.0218,\n",
       "                      0.9808, 0.9828, 1.0295, 1.0435, 1.0020, 0.9560, 1.0466, 0.9919, 1.0057,\n",
       "                      1.0143, 0.9655, 0.9970, 0.9802, 1.0043, 1.0287, 1.0176, 1.0478, 0.9818,\n",
       "                      1.0627, 0.9520, 1.0297, 0.9699, 1.0028, 0.9551, 1.0024, 0.9750, 0.9975,\n",
       "                      1.0285], device='cuda:0')),\n",
       "             ('cnn.batchnorm2.bias',\n",
       "              tensor([-0.0414, -0.0132, -0.0426, -0.0269, -0.0194, -0.0096, -0.0018, -0.0452,\n",
       "                      -0.0269, -0.0096, -0.0350, -0.0549, -0.0463, -0.0284, -0.0243,  0.0057,\n",
       "                      -0.0510, -0.0038, -0.0298, -0.0476, -0.0549, -0.0574, -0.0431, -0.0227,\n",
       "                      -0.0393, -0.0325, -0.0475, -0.0517, -0.0076, -0.0210, -0.0396, -0.0239,\n",
       "                      -0.0459, -0.0074, -0.0516, -0.0166, -0.0329, -0.0379, -0.0161, -0.0047,\n",
       "                      -0.0413, -0.0632,  0.0092, -0.0215, -0.0083, -0.0164, -0.0696, -0.0548,\n",
       "                      -0.0247, -0.0301,  0.0139, -0.0372,  0.0139, -0.0579, -0.0107, -0.0529,\n",
       "                       0.0008, -0.0495, -0.0071, -0.0452, -0.0326, -0.0400, -0.0175,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm2.running_mean',\n",
       "              tensor([ 1.4343e-03,  2.9754e-01,  4.6868e-01, -8.3792e-01, -6.6872e-01,\n",
       "                      -4.5269e-01, -5.4294e-02, -9.0842e-01, -9.2182e-01, -6.4641e-01,\n",
       "                      -1.2634e+00, -9.4078e-01, -7.2966e-01, -1.1444e+00,  1.5223e-01,\n",
       "                      -4.4597e-01, -7.6018e-01,  4.4946e-04, -8.7709e-02, -3.7797e-01,\n",
       "                       1.9496e-01,  1.0597e-02, -7.2687e-01, -1.7045e-01, -2.4320e-01,\n",
       "                       2.3567e-01, -2.9842e-02, -9.1138e-01, -1.1668e+00, -8.6749e-01,\n",
       "                      -2.3266e-01, -2.0709e-02, -4.3373e-01, -1.0148e+00, -7.6604e-01,\n",
       "                       3.1932e-01,  6.1976e-01, -2.8272e-01, -4.6697e-01, -2.6348e-01,\n",
       "                      -1.5779e-01, -1.2432e+00, -9.8439e-01,  7.9959e-01, -1.5958e-01,\n",
       "                       3.1282e-01, -6.2320e-01, -2.5963e-02, -4.8822e-01,  4.2479e-01,\n",
       "                      -1.0678e+00,  9.8491e-02,  8.6706e-02, -7.7908e-01, -4.7965e-01,\n",
       "                      -1.2672e-01, -1.1490e+00, -1.6043e+00, -1.1069e+00, -4.7743e-01,\n",
       "                       1.4865e-01,  2.2170e-01,  1.3858e+00,  1.6680e-01], device='cuda:0')),\n",
       "             ('cnn.batchnorm2.running_var',\n",
       "              tensor([0.3282, 0.5207, 0.2841, 0.4309, 0.8493, 0.3158, 0.3154, 0.3522, 0.3436,\n",
       "                      0.7299, 0.7713, 1.0696, 0.5954, 0.8526, 0.7898, 0.3604, 0.4647, 0.5313,\n",
       "                      0.5091, 0.8298, 0.7962, 0.5826, 0.3263, 0.3989, 0.3146, 0.6276, 0.6947,\n",
       "                      0.2992, 0.3104, 0.4728, 0.5253, 0.4846, 0.6471, 0.4459, 0.3325, 0.2208,\n",
       "                      0.2769, 0.2577, 0.5585, 0.3667, 0.3791, 1.0845, 0.4392, 0.9951, 0.4510,\n",
       "                      0.4662, 0.4788, 0.4090, 0.5031, 0.7652, 0.3408, 0.3587, 0.4221, 0.6735,\n",
       "                      0.4813, 0.3152, 0.4386, 0.7774, 0.4463, 0.9115, 0.4527, 0.6208, 0.6809,\n",
       "                      0.7195], device='cuda:0')),\n",
       "             ('cnn.batchnorm2.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0')),\n",
       "             ('cnn.conv3.weight',\n",
       "              tensor([[[[ 2.6021e-02,  7.0023e-03,  6.8255e-02],\n",
       "                        [-2.0505e-02,  3.2077e-02,  2.6083e-02],\n",
       "                        [-2.7642e-02, -2.9411e-02,  3.2136e-02]],\n",
       "              \n",
       "                       [[-2.1792e-03, -7.6099e-03, -4.8429e-02],\n",
       "                        [-1.0355e-02,  2.8022e-02, -1.9119e-02],\n",
       "                        [-5.6486e-02,  1.1617e-02,  1.0646e-02]],\n",
       "              \n",
       "                       [[-1.8573e-02,  4.0500e-02, -2.8796e-02],\n",
       "                        [ 3.5817e-02,  2.2858e-02,  1.9771e-02],\n",
       "                        [-1.8796e-02, -3.1376e-02, -5.7373e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.2785e-02, -4.1812e-02,  1.4504e-03],\n",
       "                        [-4.7194e-02,  1.9185e-03, -2.2286e-02],\n",
       "                        [-3.1860e-02, -1.1221e-02,  3.1732e-02]],\n",
       "              \n",
       "                       [[-1.7054e-02, -1.1856e-02, -1.3460e-02],\n",
       "                        [ 1.0673e-02,  3.0430e-03, -1.7067e-02],\n",
       "                        [-4.3455e-02, -4.2699e-02, -1.1660e-02]],\n",
       "              \n",
       "                       [[ 1.3468e-02, -7.9768e-03,  4.9281e-02],\n",
       "                        [ 1.5497e-03, -3.6896e-02, -6.8413e-03],\n",
       "                        [ 5.3158e-02, -3.1844e-02,  1.6591e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.7467e-03,  4.0754e-03,  4.7424e-02],\n",
       "                        [-7.6046e-03, -7.0323e-03,  2.5309e-02],\n",
       "                        [ 3.0247e-02,  9.9493e-03, -6.6534e-03]],\n",
       "              \n",
       "                       [[-3.3316e-02,  1.8458e-02, -3.0418e-03],\n",
       "                        [ 2.1203e-02, -2.1561e-02,  4.2407e-02],\n",
       "                        [-3.2934e-02, -3.1324e-02, -3.8421e-04]],\n",
       "              \n",
       "                       [[ 4.7989e-02,  1.6949e-02,  3.5790e-02],\n",
       "                        [ 1.2766e-02,  6.4738e-03,  3.9563e-02],\n",
       "                        [-1.1498e-03,  5.6272e-02,  4.7173e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.6262e-02,  2.2750e-03,  1.4768e-02],\n",
       "                        [ 2.9378e-02,  2.7098e-02, -2.8282e-03],\n",
       "                        [-1.4159e-02,  1.1462e-02, -7.6236e-03]],\n",
       "              \n",
       "                       [[-3.3078e-02, -2.9186e-03, -2.7649e-02],\n",
       "                        [-1.5477e-02, -2.7988e-02,  2.9904e-02],\n",
       "                        [ 3.2129e-02, -2.1312e-02, -3.3763e-02]],\n",
       "              \n",
       "                       [[-5.6629e-03,  1.0344e-02,  3.8189e-02],\n",
       "                        [-3.2277e-02, -2.8216e-02,  4.2862e-02],\n",
       "                        [ 1.4150e-02, -1.2851e-02, -4.8712e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 1.0361e-02, -5.4795e-02, -1.0455e-02],\n",
       "                        [-2.4809e-02, -1.5765e-02,  1.0712e-02],\n",
       "                        [ 4.8279e-02, -1.0103e-03,  5.0894e-02]],\n",
       "              \n",
       "                       [[-7.3535e-03, -1.4420e-02, -4.3797e-04],\n",
       "                        [-1.3276e-02,  4.0222e-02,  1.2414e-02],\n",
       "                        [ 1.1118e-02,  4.2846e-02, -2.7947e-02]],\n",
       "              \n",
       "                       [[-1.5134e-02,  1.7494e-02,  2.4262e-02],\n",
       "                        [-2.9215e-02,  2.4483e-02,  1.0055e-02],\n",
       "                        [-4.1515e-02,  2.1660e-02, -1.1182e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.0912e-02,  4.8655e-02,  2.4536e-02],\n",
       "                        [ 3.3575e-02, -1.4637e-02, -2.0180e-02],\n",
       "                        [-2.9542e-02,  1.0448e-03,  6.2675e-03]],\n",
       "              \n",
       "                       [[-4.5630e-03, -1.4581e-02, -9.6534e-03],\n",
       "                        [-1.7898e-02, -5.9458e-02, -3.4479e-02],\n",
       "                        [-4.3555e-02,  3.2977e-03,  2.3394e-02]],\n",
       "              \n",
       "                       [[ 6.4961e-02,  5.3359e-03,  4.2960e-02],\n",
       "                        [ 4.2273e-02, -3.4946e-02,  4.1834e-02],\n",
       "                        [ 1.0601e-02,  1.5495e-02, -1.4944e-02]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 3.0235e-02,  3.1172e-02,  1.8019e-02],\n",
       "                        [ 5.7309e-03,  1.3705e-02,  3.6527e-02],\n",
       "                        [-3.4435e-02,  4.9985e-02, -2.4301e-02]],\n",
       "              \n",
       "                       [[-1.9944e-02, -3.6480e-02,  2.0383e-02],\n",
       "                        [-4.0738e-02,  3.7398e-02,  2.7843e-02],\n",
       "                        [-2.9606e-02,  3.9102e-02, -6.3080e-03]],\n",
       "              \n",
       "                       [[-1.9072e-02,  5.3466e-03,  1.5352e-02],\n",
       "                        [ 1.2703e-02,  9.7729e-03,  2.0899e-02],\n",
       "                        [ 1.6920e-02,  4.8764e-02,  3.3257e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-2.8849e-02, -2.1596e-02,  2.0275e-03],\n",
       "                        [-3.2165e-02, -2.1715e-02,  9.5956e-03],\n",
       "                        [ 1.0616e-02,  1.8502e-03, -1.6785e-02]],\n",
       "              \n",
       "                       [[-1.3305e-02, -4.1092e-02,  2.9165e-02],\n",
       "                        [-2.3174e-03, -2.2758e-02, -4.0152e-02],\n",
       "                        [ 3.0718e-02,  4.6618e-02,  1.9409e-02]],\n",
       "              \n",
       "                       [[-6.3245e-02, -4.0711e-03, -6.5225e-02],\n",
       "                        [-8.3848e-03, -4.1189e-02, -5.3634e-02],\n",
       "                        [-1.3555e-02, -1.5946e-02,  3.0323e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.8753e-02,  5.5682e-02,  1.5244e-02],\n",
       "                        [ 4.0238e-02,  2.3292e-02,  1.5141e-02],\n",
       "                        [-3.0282e-02,  3.4863e-02, -3.1683e-02]],\n",
       "              \n",
       "                       [[-3.8582e-02, -3.1514e-02,  4.0301e-02],\n",
       "                        [-4.3301e-02, -3.9278e-02, -9.7051e-03],\n",
       "                        [-2.6942e-03, -2.4610e-03, -2.4650e-02]],\n",
       "              \n",
       "                       [[-7.3490e-03,  1.6175e-02, -1.3799e-02],\n",
       "                        [-1.1555e-02,  1.8775e-02,  2.1319e-02],\n",
       "                        [-5.0896e-03, -2.1233e-02, -6.8267e-04]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 5.5651e-02, -1.5591e-02, -3.0454e-02],\n",
       "                        [ 5.6595e-02, -3.4537e-02, -3.4294e-02],\n",
       "                        [ 3.6715e-02,  2.9718e-02,  9.7081e-03]],\n",
       "              \n",
       "                       [[-1.9924e-02, -1.1155e-02, -1.3706e-02],\n",
       "                        [ 3.1196e-02,  1.7857e-02,  3.0859e-03],\n",
       "                        [-2.4244e-02,  5.4412e-03, -2.5237e-02]],\n",
       "              \n",
       "                       [[ 1.4376e-02,  2.3351e-02, -7.4793e-02],\n",
       "                        [ 1.0133e-02, -1.8555e-02, -3.2021e-02],\n",
       "                        [ 1.4344e-02,  1.8204e-03, -3.8664e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.5249e-02, -4.1313e-02, -3.4956e-02],\n",
       "                        [ 1.4537e-02, -2.0241e-02,  1.3219e-02],\n",
       "                        [-6.1704e-03,  3.4420e-02, -1.6254e-02]],\n",
       "              \n",
       "                       [[-3.4979e-02, -8.0739e-03, -2.2843e-02],\n",
       "                        [ 3.7098e-02,  4.2396e-02,  3.2037e-02],\n",
       "                        [-3.8605e-02,  1.5302e-02,  1.6621e-02]],\n",
       "              \n",
       "                       [[-6.2572e-02, -5.6609e-02, -1.4300e-02],\n",
       "                        [-4.9035e-02, -3.8963e-02,  3.4300e-02],\n",
       "                        [-4.3288e-02, -4.3026e-03,  3.0765e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5290e-02, -3.4635e-05, -1.9006e-02],\n",
       "                        [ 5.0112e-02, -6.8778e-03, -2.8935e-03],\n",
       "                        [ 4.4258e-02,  1.2742e-02, -3.8279e-02]],\n",
       "              \n",
       "                       [[ 2.1353e-02, -3.6876e-02,  2.7293e-02],\n",
       "                        [-3.5648e-02, -1.1240e-02, -2.9022e-02],\n",
       "                        [ 1.9839e-02, -4.7901e-02,  9.7526e-03]],\n",
       "              \n",
       "                       [[ 3.6114e-02,  1.3667e-02,  4.6761e-02],\n",
       "                        [-1.1462e-02, -1.4534e-02,  6.2674e-02],\n",
       "                        [ 3.7249e-02, -4.1463e-02,  2.3145e-02]]]], device='cuda:0')),\n",
       "             ('cnn.conv3.bias',\n",
       "              tensor([-2.4413e-02, -3.8445e-02, -3.8165e-02, -2.6706e-02, -2.5181e-03,\n",
       "                      -1.2986e-02,  4.0105e-02,  2.6013e-02,  3.6440e-02,  3.3613e-02,\n",
       "                      -2.3344e-02, -2.3983e-02, -3.6633e-02, -1.1363e-02, -3.5869e-03,\n",
       "                       5.5122e-03,  3.7939e-02, -3.9209e-02,  1.5762e-03, -2.7773e-02,\n",
       "                       2.6284e-02,  3.6214e-02,  1.5020e-02, -1.5582e-02,  7.5826e-03,\n",
       "                      -3.5108e-02, -3.7144e-02,  3.1149e-02,  2.1802e-02,  1.7026e-03,\n",
       "                      -2.4524e-02,  2.8802e-02,  3.4369e-02,  2.9156e-02, -4.7382e-03,\n",
       "                      -2.8283e-02, -4.0400e-02,  1.3140e-02, -2.9819e-02, -1.8300e-02,\n",
       "                       2.7024e-02,  3.7313e-02, -3.4903e-02,  2.7409e-02, -3.8877e-02,\n",
       "                       1.5648e-02,  4.0356e-02,  1.1665e-02,  3.4830e-03,  2.7059e-02,\n",
       "                       3.6087e-02,  2.8612e-02, -3.4398e-02, -2.5591e-02,  1.9596e-02,\n",
       "                       1.5011e-02,  3.6273e-02, -1.5607e-02,  6.0684e-03, -1.7601e-02,\n",
       "                      -2.9988e-02, -1.9620e-02, -2.2774e-02,  7.0721e-04,  8.6251e-03,\n",
       "                       3.6868e-02,  6.8687e-03,  1.9229e-02,  1.3045e-02,  3.1693e-02,\n",
       "                       3.1249e-02,  2.8280e-02,  3.5120e-02, -4.4230e-03, -3.6588e-02,\n",
       "                       2.9451e-02,  5.9087e-04, -6.3591e-04, -1.8246e-02,  3.8281e-02,\n",
       "                       2.1173e-02,  3.3900e-02, -7.4852e-03, -3.4921e-02,  3.9956e-02,\n",
       "                       2.4034e-02,  2.2892e-02, -1.5540e-02,  3.2314e-02,  1.2168e-02,\n",
       "                       1.5485e-02, -2.6552e-02, -3.3105e-02, -2.8704e-02,  2.8321e-02,\n",
       "                      -1.1360e-02, -2.1914e-02,  5.0957e-05, -1.2733e-02, -3.1032e-02,\n",
       "                      -3.4000e-02,  7.6333e-03,  1.4007e-02,  4.1296e-02,  3.1877e-02,\n",
       "                      -3.6761e-02,  2.6400e-02, -1.1019e-02, -4.2428e-04,  3.6164e-02,\n",
       "                       4.5396e-03,  4.1473e-02,  1.4255e-02,  3.9157e-02, -1.1459e-02,\n",
       "                       1.4105e-02, -2.8122e-02,  3.2105e-02, -5.2690e-03,  1.9828e-02,\n",
       "                      -3.5511e-02, -3.2478e-02, -1.7269e-02,  3.5365e-02, -9.7842e-03,\n",
       "                       1.2676e-02,  2.5992e-03, -2.5516e-02], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.weight',\n",
       "              tensor([1.0029, 0.9810, 0.9910, 1.0140, 1.0113, 0.9954, 0.9813, 1.0151, 1.0116,\n",
       "                      1.0082, 0.9945, 1.0107, 0.9846, 0.9663, 0.9929, 0.9917, 0.9890, 0.9779,\n",
       "                      1.0082, 0.9984, 1.0147, 1.0409, 0.9895, 1.0024, 1.0208, 1.0127, 1.0012,\n",
       "                      0.9907, 1.0156, 0.9716, 0.9603, 0.9864, 0.9877, 0.9725, 0.9784, 0.9901,\n",
       "                      1.0036, 0.9739, 1.0037, 0.9731, 0.9977, 0.9905, 0.9839, 0.9632, 1.0060,\n",
       "                      0.9764, 1.0315, 0.9822, 1.0034, 1.0305, 0.9903, 0.9939, 0.9845, 1.0000,\n",
       "                      1.0309, 0.9856, 0.9897, 1.0125, 0.9921, 1.0173, 0.9761, 0.9956, 0.9799,\n",
       "                      1.0380, 1.0024, 0.9891, 1.0162, 1.0243, 1.0212, 1.0198, 0.9980, 0.9814,\n",
       "                      1.0196, 0.9897, 0.9902, 0.9939, 0.9998, 0.9865, 1.0276, 0.9970, 1.0261,\n",
       "                      0.9936, 0.9982, 1.0023, 0.9594, 0.9951, 1.0084, 0.9882, 1.0214, 1.0078,\n",
       "                      1.0042, 0.9980, 1.0027, 0.9876, 1.0145, 0.9997, 1.0114, 0.9955, 0.9667,\n",
       "                      0.9897, 0.9821, 0.9665, 0.9852, 0.9926, 1.0020, 1.0241, 0.9907, 1.0053,\n",
       "                      1.0351, 0.9899, 0.9932, 1.0028, 0.9865, 0.9820, 1.0209, 0.9899, 0.9784,\n",
       "                      0.9996, 0.9640, 0.9624, 0.9544, 0.9867, 0.9664, 1.0192, 0.9974, 0.9960,\n",
       "                      1.0109, 1.0068], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.bias',\n",
       "              tensor([-0.0245, -0.0117, -0.0490, -0.0334, -0.0348, -0.0347, -0.0302, -0.0535,\n",
       "                      -0.0292, -0.0456, -0.0287, -0.0351, -0.0453, -0.0285, -0.0263, -0.0344,\n",
       "                      -0.0157, -0.0439, -0.0019, -0.0507, -0.0381, -0.0074, -0.0258, -0.0577,\n",
       "                      -0.0518, -0.0505,  0.0125, -0.0022, -0.0596, -0.0167, -0.0782, -0.0443,\n",
       "                      -0.0332, -0.0394, -0.0435, -0.0652, -0.0429, -0.0184, -0.0079, -0.0680,\n",
       "                      -0.0286, -0.0778, -0.0121, -0.0300, -0.0235, -0.0173, -0.0072, -0.0211,\n",
       "                      -0.0169, -0.0305, -0.0632, -0.0184, -0.0488, -0.0398, -0.0551, -0.0326,\n",
       "                      -0.0176, -0.0434, -0.0432, -0.0224, -0.0458, -0.0608, -0.0604, -0.0022,\n",
       "                      -0.0093, -0.0074, -0.0357,  0.0165, -0.0574, -0.0289, -0.0624, -0.0211,\n",
       "                      -0.0220, -0.0131, -0.0106, -0.0435, -0.0291, -0.0525, -0.0243, -0.0104,\n",
       "                      -0.0426, -0.0441, -0.0529, -0.0372, -0.0455, -0.0192, -0.0391, -0.0161,\n",
       "                      -0.0423, -0.0136, -0.0399, -0.0284, -0.0555, -0.0176, -0.0162,  0.0074,\n",
       "                      -0.0208, -0.0454, -0.0352, -0.0455, -0.0048, -0.0681, -0.0690, -0.0472,\n",
       "                      -0.0331, -0.0287, -0.0413, -0.0320, -0.0316, -0.0282, -0.0574, -0.0448,\n",
       "                      -0.0054, -0.0704, -0.0390, -0.0201, -0.0452, -0.0340, -0.0327, -0.0514,\n",
       "                      -0.0322, -0.0242, -0.0246, -0.0466, -0.0511, -0.0269, -0.0080, -0.0498],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm3.running_mean',\n",
       "              tensor([ 0.5059,  0.2329,  2.0122, -0.4227,  0.4565,  0.0596,  0.8636,  0.6002,\n",
       "                      -0.3047,  0.0782,  0.1671, -0.1650, -0.3431, -0.8382,  0.7188, -0.3843,\n",
       "                      -0.8871, -1.4133, -0.2619, -0.1243,  0.6920, -0.7132,  0.0845,  1.8491,\n",
       "                      -0.1251, -0.5045, -1.0239, -1.2987,  0.9607,  0.3907,  0.7305,  0.4139,\n",
       "                       0.5688, -1.0110,  1.4836,  1.5118,  0.1780, -0.9637, -0.5862,  1.2802,\n",
       "                       0.2333,  2.1474,  1.6301,  1.4149,  0.0371, -0.5074, -1.0022,  0.8218,\n",
       "                      -0.7512, -0.7939,  0.9089, -0.7035,  0.3462,  0.6996,  0.6871, -0.5330,\n",
       "                      -1.5817, -0.4048,  1.9989, -0.8051,  2.0025,  0.4362,  0.8290,  0.0255,\n",
       "                      -1.0038, -0.3501,  1.7882,  0.0685, -0.3549, -0.2087,  0.2896, -1.1963,\n",
       "                      -0.5679, -1.4404, -0.4417,  1.5830,  0.6359,  2.2520,  0.0059, -1.7413,\n",
       "                       0.7729,  0.5822,  0.3300, -0.3311,  1.4858,  2.4929, -0.2143, -1.8599,\n",
       "                       0.5325, -0.3366, -0.9365,  0.0329,  1.3908, -0.3480, -1.3968, -0.6599,\n",
       "                      -0.7016,  0.9780,  0.3179, -0.6548,  0.5869,  1.0208,  1.4245, -0.2683,\n",
       "                       0.0769, -0.2538,  0.2961, -0.2723,  0.3726,  1.0614,  0.6042,  1.3697,\n",
       "                      -1.0085,  0.9768,  0.3825,  0.4797,  1.8562,  0.6381, -0.3878,  1.7992,\n",
       "                      -0.5722,  0.1140, -2.0658,  0.3701,  0.0299, -0.6061,  0.5533,  0.1067],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm3.running_var',\n",
       "              tensor([0.9137, 0.4367, 0.9402, 1.1753, 0.8700, 0.5630, 0.8018, 0.6762, 0.9537,\n",
       "                      0.4230, 0.3279, 0.3548, 0.5047, 0.4809, 0.3486, 1.1517, 0.3919, 0.8090,\n",
       "                      0.7206, 0.7784, 0.2729, 1.1331, 0.6141, 0.9798, 0.6250, 0.9728, 0.8514,\n",
       "                      0.7135, 0.4900, 0.9793, 0.4123, 0.4976, 0.7103, 0.2312, 1.3027, 0.7222,\n",
       "                      1.0689, 0.4862, 0.8490, 0.8168, 0.8437, 0.9697, 1.0517, 1.0605, 0.3901,\n",
       "                      0.2130, 1.3461, 2.2624, 0.5069, 0.6767, 0.6665, 0.3457, 0.8009, 0.9839,\n",
       "                      1.1796, 0.4368, 0.6026, 0.6528, 1.4550, 0.4901, 0.8402, 0.4488, 0.7690,\n",
       "                      0.8948, 0.5823, 0.7680, 0.8636, 0.6246, 0.6430, 0.8393, 0.5873, 0.5772,\n",
       "                      1.1334, 0.7706, 0.3818, 0.5482, 0.6363, 0.9873, 0.5734, 1.4573, 0.9909,\n",
       "                      0.3462, 0.8381, 0.4892, 0.9154, 1.3675, 0.4886, 1.1103, 0.6141, 0.4786,\n",
       "                      0.7903, 0.5108, 0.8104, 0.6505, 1.4757, 0.5772, 0.3497, 0.7686, 0.4845,\n",
       "                      0.3415, 0.8280, 0.6043, 0.6122, 0.6136, 0.6006, 0.8857, 0.7288, 0.9341,\n",
       "                      0.5351, 0.6235, 0.6434, 0.4363, 0.5978, 0.5305, 0.2798, 0.2967, 0.8184,\n",
       "                      1.0539, 0.2061, 0.5566, 0.4049, 0.8667, 0.8653, 0.9068, 0.6136, 0.3431,\n",
       "                      0.6260, 0.5385], device='cuda:0')),\n",
       "             ('cnn.batchnorm3.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0')),\n",
       "             ('cnn.conv4.weight',\n",
       "              tensor([[[[ 0.0279,  0.0065, -0.0165],\n",
       "                        [-0.0196,  0.0231,  0.0214],\n",
       "                        [ 0.0139,  0.0203, -0.0027]],\n",
       "              \n",
       "                       [[-0.0157, -0.0042, -0.0007],\n",
       "                        [-0.0392, -0.0114,  0.0071],\n",
       "                        [-0.0016,  0.0151, -0.0022]],\n",
       "              \n",
       "                       [[-0.0023,  0.0265,  0.0213],\n",
       "                        [ 0.0067,  0.0304,  0.0189],\n",
       "                        [ 0.0371, -0.0006, -0.0065]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0250, -0.0202,  0.0083],\n",
       "                        [-0.0188, -0.0213,  0.0095],\n",
       "                        [-0.0082,  0.0224, -0.0073]],\n",
       "              \n",
       "                       [[ 0.0163,  0.0097, -0.0416],\n",
       "                        [-0.0214, -0.0273, -0.0218],\n",
       "                        [-0.0273,  0.0059, -0.0114]],\n",
       "              \n",
       "                       [[ 0.0202,  0.0008,  0.0299],\n",
       "                        [-0.0016,  0.0019,  0.0476],\n",
       "                        [ 0.0001,  0.0060,  0.0107]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0338, -0.0118,  0.0140],\n",
       "                        [-0.0145, -0.0430,  0.0252],\n",
       "                        [-0.0027,  0.0131,  0.0257]],\n",
       "              \n",
       "                       [[ 0.0017,  0.0099,  0.0182],\n",
       "                        [-0.0233,  0.0061,  0.0375],\n",
       "                        [-0.0280, -0.0048,  0.0316]],\n",
       "              \n",
       "                       [[-0.0145, -0.0264,  0.0101],\n",
       "                        [ 0.0104, -0.0250,  0.0145],\n",
       "                        [-0.0023, -0.0283, -0.0203]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0057,  0.0007,  0.0128],\n",
       "                        [ 0.0277,  0.0054, -0.0286],\n",
       "                        [-0.0211,  0.0037, -0.0027]],\n",
       "              \n",
       "                       [[-0.0276, -0.0277, -0.0452],\n",
       "                        [-0.0272, -0.0301, -0.0063],\n",
       "                        [-0.0023, -0.0283, -0.0188]],\n",
       "              \n",
       "                       [[-0.0029, -0.0100, -0.0243],\n",
       "                        [ 0.0199, -0.0119, -0.0197],\n",
       "                        [ 0.0271, -0.0289,  0.0102]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0316,  0.0332, -0.0152],\n",
       "                        [ 0.0196,  0.0404, -0.0167],\n",
       "                        [ 0.0149,  0.0121, -0.0280]],\n",
       "              \n",
       "                       [[-0.0133,  0.0138,  0.0159],\n",
       "                        [ 0.0262,  0.0260,  0.0329],\n",
       "                        [ 0.0293,  0.0036,  0.0001]],\n",
       "              \n",
       "                       [[-0.0068, -0.0253, -0.0419],\n",
       "                        [-0.0297, -0.0332, -0.0321],\n",
       "                        [-0.0426, -0.0619, -0.0280]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0042,  0.0159, -0.0300],\n",
       "                        [-0.0176,  0.0027,  0.0089],\n",
       "                        [-0.0380, -0.0008, -0.0390]],\n",
       "              \n",
       "                       [[-0.0159, -0.0256,  0.0049],\n",
       "                        [-0.0199, -0.0030, -0.0204],\n",
       "                        [-0.0113, -0.0040, -0.0226]],\n",
       "              \n",
       "                       [[ 0.0081, -0.0461, -0.0209],\n",
       "                        [ 0.0107, -0.0165, -0.0078],\n",
       "                        [-0.0151, -0.0262,  0.0291]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0184,  0.0240, -0.0036],\n",
       "                        [ 0.0439, -0.0210,  0.0305],\n",
       "                        [ 0.0292,  0.0241,  0.0233]],\n",
       "              \n",
       "                       [[-0.0165,  0.0181,  0.0030],\n",
       "                        [ 0.0031,  0.0306, -0.0006],\n",
       "                        [ 0.0212, -0.0074, -0.0008]],\n",
       "              \n",
       "                       [[-0.0084,  0.0198,  0.0075],\n",
       "                        [-0.0236,  0.0354,  0.0398],\n",
       "                        [ 0.0072, -0.0007,  0.0358]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0038,  0.0001,  0.0200],\n",
       "                        [-0.0187, -0.0183,  0.0132],\n",
       "                        [-0.0288, -0.0133, -0.0077]],\n",
       "              \n",
       "                       [[ 0.0118, -0.0125,  0.0150],\n",
       "                        [-0.0358, -0.0010, -0.0068],\n",
       "                        [-0.0266, -0.0398,  0.0327]],\n",
       "              \n",
       "                       [[-0.0090, -0.0267, -0.0273],\n",
       "                        [-0.0163, -0.0216,  0.0020],\n",
       "                        [-0.0021,  0.0197, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0047, -0.0328, -0.0268],\n",
       "                        [ 0.0086,  0.0159, -0.0104],\n",
       "                        [ 0.0167,  0.0042, -0.0066]],\n",
       "              \n",
       "                       [[-0.0265, -0.0241,  0.0078],\n",
       "                        [-0.0052, -0.0249,  0.0060],\n",
       "                        [-0.0056,  0.0040, -0.0370]],\n",
       "              \n",
       "                       [[ 0.0100, -0.0073,  0.0107],\n",
       "                        [ 0.0110,  0.0273,  0.0253],\n",
       "                        [ 0.0260, -0.0049,  0.0101]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0083, -0.0165, -0.0007],\n",
       "                        [ 0.0385, -0.0208, -0.0147],\n",
       "                        [ 0.0197,  0.0281,  0.0073]],\n",
       "              \n",
       "                       [[-0.0348,  0.0262, -0.0287],\n",
       "                        [-0.0142,  0.0118,  0.0100],\n",
       "                        [-0.0123, -0.0065, -0.0368]],\n",
       "              \n",
       "                       [[ 0.0131, -0.0090,  0.0351],\n",
       "                        [-0.0028, -0.0389,  0.0443],\n",
       "                        [ 0.0005,  0.0053,  0.0133]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0228, -0.0237,  0.0169],\n",
       "                        [ 0.0313,  0.0165, -0.0055],\n",
       "                        [-0.0148, -0.0255, -0.0255]],\n",
       "              \n",
       "                       [[ 0.0099,  0.0012, -0.0115],\n",
       "                        [ 0.0037, -0.0125, -0.0299],\n",
       "                        [ 0.0108, -0.0105, -0.0067]],\n",
       "              \n",
       "                       [[ 0.0174, -0.0011,  0.0211],\n",
       "                        [ 0.0119, -0.0040,  0.0141],\n",
       "                        [ 0.0078,  0.0054, -0.0118]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0372, -0.0339, -0.0066],\n",
       "                        [-0.0360, -0.0385,  0.0088],\n",
       "                        [-0.0096, -0.0162, -0.0361]],\n",
       "              \n",
       "                       [[-0.0072, -0.0143, -0.0065],\n",
       "                        [ 0.0081, -0.0100, -0.0219],\n",
       "                        [-0.0185, -0.0035,  0.0035]],\n",
       "              \n",
       "                       [[ 0.0191, -0.0161, -0.0048],\n",
       "                        [ 0.0176,  0.0129,  0.0337],\n",
       "                        [-0.0123,  0.0379, -0.0068]]]], device='cuda:0')),\n",
       "             ('cnn.conv4.bias',\n",
       "              tensor([-2.5533e-02, -1.0640e-02, -5.6015e-03, -8.2303e-03,  1.8189e-02,\n",
       "                       8.6488e-03, -1.1043e-02,  2.4797e-03,  2.0378e-02,  1.8944e-02,\n",
       "                       2.5462e-02, -7.9090e-03,  1.4755e-04,  1.7236e-02, -1.7460e-02,\n",
       "                      -2.5775e-02,  1.5736e-02, -2.9601e-02,  1.6512e-02,  1.5574e-02,\n",
       "                      -7.5782e-03, -5.0879e-03, -9.6258e-03,  3.6475e-03,  1.0041e-02,\n",
       "                       1.2731e-02, -7.5507e-03, -7.2463e-03,  2.3060e-02, -1.0526e-02,\n",
       "                      -2.7555e-02,  2.3600e-03, -1.2420e-02, -1.5841e-02, -3.7699e-03,\n",
       "                      -2.5798e-02,  2.3888e-02,  1.8775e-02, -1.4385e-02, -5.8615e-03,\n",
       "                      -2.2558e-02, -1.9266e-02, -1.6742e-02, -2.8082e-02,  1.8588e-02,\n",
       "                       3.5377e-03,  6.6651e-03,  1.7505e-02, -1.7545e-02,  1.0317e-02,\n",
       "                       1.5247e-02, -2.6647e-03,  2.8812e-02, -1.3009e-02,  2.3862e-02,\n",
       "                      -2.3913e-02,  2.0249e-03,  2.3879e-03,  9.1318e-03,  7.1086e-03,\n",
       "                      -1.3091e-02,  1.0811e-02, -1.6134e-02,  2.6355e-02, -2.6882e-02,\n",
       "                       5.1510e-03, -2.5185e-02,  6.1542e-04,  9.1448e-03,  1.5615e-02,\n",
       "                      -2.7561e-02, -2.9135e-02, -2.5604e-02,  3.4669e-03, -1.6745e-02,\n",
       "                      -2.3904e-02,  7.2161e-03,  2.0480e-02,  8.4396e-03, -1.3134e-02,\n",
       "                      -1.9794e-02, -1.0774e-02, -2.0597e-03, -3.8828e-03,  1.9355e-03,\n",
       "                       1.2183e-03,  1.8962e-02,  2.8274e-03,  8.8664e-03, -7.5878e-03,\n",
       "                       9.6779e-04, -1.9319e-02, -4.3572e-03,  2.5153e-02,  1.6003e-02,\n",
       "                      -2.2517e-02,  1.1811e-02, -9.2012e-03, -9.2588e-03,  2.2607e-02,\n",
       "                      -1.1676e-02,  1.1441e-02, -2.3967e-02,  1.7761e-02,  6.2680e-03,\n",
       "                      -8.0898e-03, -2.0059e-02,  5.1739e-03,  2.6476e-02,  9.5113e-04,\n",
       "                       6.7505e-03, -2.0030e-02,  3.4196e-03, -2.1747e-03,  5.0771e-03,\n",
       "                      -1.4968e-04, -1.1981e-02, -1.7930e-02,  2.2812e-02,  1.7370e-02,\n",
       "                      -7.7682e-03, -2.4517e-02,  6.3457e-03, -2.4111e-02,  7.6612e-03,\n",
       "                      -1.1493e-02, -2.8865e-02,  1.0510e-02, -1.5708e-02,  1.6294e-02,\n",
       "                      -2.4533e-03,  2.4874e-02, -6.1241e-03,  2.2508e-02,  2.1227e-02,\n",
       "                      -1.6246e-02,  1.1870e-02,  1.1950e-02, -2.0308e-02, -3.2469e-04,\n",
       "                       1.6758e-02,  1.9523e-02,  1.4846e-02, -2.7481e-02, -7.6016e-03,\n",
       "                      -2.6956e-02,  2.4121e-02,  5.4609e-03,  2.4439e-02,  1.3691e-02,\n",
       "                       1.8545e-02,  4.8675e-03,  2.7395e-03, -7.6311e-03,  2.2166e-02,\n",
       "                      -5.2550e-03, -1.3565e-02, -9.9207e-03,  6.3413e-03,  7.1618e-04,\n",
       "                       2.2503e-02,  4.4625e-03, -1.3341e-02,  8.3043e-05, -2.7614e-02,\n",
       "                       1.4686e-02,  2.3038e-02, -1.3430e-02, -1.2895e-03, -2.0604e-02,\n",
       "                      -1.5742e-02,  2.7688e-02, -5.4202e-03,  2.6264e-02, -2.3236e-02,\n",
       "                       8.6664e-03,  8.1608e-03,  2.6338e-02,  6.3797e-03, -9.1481e-03,\n",
       "                      -2.0428e-02, -2.2989e-02, -7.5867e-03,  1.9474e-02,  1.6356e-02,\n",
       "                       6.9798e-03,  2.8144e-02, -1.2807e-02,  8.8562e-03, -1.9220e-02,\n",
       "                       1.8671e-03,  9.2373e-03, -9.4284e-03, -2.0818e-02, -2.8018e-02,\n",
       "                       1.9570e-02, -1.1841e-02, -1.3978e-02,  2.7091e-02, -2.0850e-02,\n",
       "                      -3.3633e-03,  2.8162e-02, -2.3012e-02,  9.9612e-03,  7.2641e-03,\n",
       "                      -1.3978e-02,  1.2546e-02,  2.6714e-02, -1.7287e-02, -8.5149e-03,\n",
       "                       2.2459e-02,  2.8846e-03,  2.3142e-02,  1.6076e-02, -1.7247e-02,\n",
       "                      -1.1270e-02, -2.6459e-02, -2.1249e-02, -6.3662e-03, -8.8915e-03,\n",
       "                      -2.3593e-02,  2.6167e-02, -2.8721e-02,  1.8002e-02,  1.3629e-02,\n",
       "                      -2.0253e-02, -6.8885e-03,  1.7994e-02, -2.2948e-02, -1.4004e-03,\n",
       "                       9.2824e-03, -1.1406e-02,  2.2038e-02, -8.5617e-03, -1.3886e-02,\n",
       "                      -2.1301e-02, -1.8235e-02, -1.0759e-02, -1.0247e-02,  2.8230e-02,\n",
       "                       1.4747e-03,  5.1925e-03, -5.4214e-03, -1.0767e-02, -1.4446e-02,\n",
       "                      -1.6027e-02,  1.8888e-02,  7.5114e-03, -1.4883e-02, -2.4915e-02,\n",
       "                      -1.0121e-02,  8.2377e-03,  6.8800e-03,  7.9700e-03, -1.0430e-02,\n",
       "                       6.7519e-04], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.weight',\n",
       "              tensor([0.9872, 1.0074, 1.0223, 1.0048, 0.9659, 1.0098, 1.0074, 1.0028, 1.0148,\n",
       "                      0.9556, 0.9918, 1.0476, 1.0167, 0.9864, 1.0123, 0.9762, 1.0154, 1.0042,\n",
       "                      1.0165, 0.9898, 0.9803, 0.9835, 0.9744, 1.0059, 0.9990, 1.0005, 1.0147,\n",
       "                      0.9995, 1.0185, 1.0088, 1.0106, 0.9691, 0.9707, 0.9763, 0.9864, 1.0338,\n",
       "                      0.9910, 1.0182, 0.9962, 0.9643, 1.0104, 0.9886, 0.9978, 0.9865, 0.9972,\n",
       "                      1.0053, 1.0145, 1.0148, 0.9561, 0.9874, 0.9931, 1.0126, 0.9788, 0.9662,\n",
       "                      1.0117, 0.9976, 0.9936, 0.9996, 0.9815, 0.9873, 0.9837, 0.9840, 0.9987,\n",
       "                      0.9869, 0.9770, 0.9907, 0.9940, 1.0216, 1.0163, 0.9843, 0.9857, 0.9801,\n",
       "                      1.0042, 1.0073, 0.9957, 0.9984, 0.9961, 1.0033, 0.9888, 0.9897, 1.0135,\n",
       "                      1.0241, 0.9944, 0.9916, 0.9974, 0.9670, 1.0171, 0.9815, 0.9829, 0.9969,\n",
       "                      0.9840, 0.9868, 1.0114, 0.9889, 0.9948, 1.0128, 0.9859, 0.9840, 0.9771,\n",
       "                      1.0204, 0.9975, 0.9799, 0.9876, 1.0160, 1.0071, 1.0040, 0.9879, 1.0083,\n",
       "                      0.9846, 0.9913, 1.0187, 0.9714, 0.9929, 0.9957, 1.0049, 1.0027, 0.9852,\n",
       "                      0.9881, 0.9954, 0.9807, 0.9741, 0.9886, 1.0191, 1.0158, 0.9904, 0.9813,\n",
       "                      0.9776, 0.9488, 1.0016, 0.9922, 1.0104, 0.9855, 1.0155, 1.0050, 1.0239,\n",
       "                      1.0174, 0.9767, 1.0166, 0.9694, 1.0042, 0.9983, 0.9778, 0.9930, 1.0073,\n",
       "                      1.0087, 1.0085, 0.9757, 0.9901, 1.0031, 1.0098, 0.9714, 1.0095, 1.0018,\n",
       "                      0.9853, 1.0252, 1.0109, 1.0212, 0.9919, 1.0075, 1.0077, 1.0018, 1.0219,\n",
       "                      1.0090, 0.9844, 0.9989, 0.9799, 0.9869, 1.0017, 1.0111, 1.0192, 1.0063,\n",
       "                      1.0122, 0.9654, 1.0103, 1.0220, 0.9838, 1.0052, 0.9960, 1.0058, 1.0165,\n",
       "                      1.0127, 0.9994, 0.9794, 0.9978, 0.9879, 1.0165, 1.0564, 0.9677, 0.9691,\n",
       "                      0.9956, 0.9911, 1.0048, 0.9914, 1.0029, 1.0012, 0.9899, 0.9800, 0.9991,\n",
       "                      0.9909, 1.0091, 0.9749, 0.9964, 0.9786, 0.9981, 1.0139, 1.0001, 0.9753,\n",
       "                      1.0003, 0.9822, 1.0031, 1.0092, 0.9865, 0.9615, 0.9924, 0.9700, 1.0151,\n",
       "                      0.9968, 1.0187, 0.9631, 0.9965, 0.9789, 1.0158, 0.9916, 1.0105, 1.0121,\n",
       "                      0.9744, 1.0013, 1.0102, 0.9948, 0.9933, 1.0089, 1.0150, 1.0018, 0.9981,\n",
       "                      0.9962, 1.0100, 0.9863, 1.0030, 0.9877, 0.9728, 1.0148, 1.0087, 1.0086,\n",
       "                      0.9887, 1.0011, 0.9890, 0.9856, 1.0134, 1.0097, 0.9953, 0.9960, 1.0127,\n",
       "                      0.9979, 1.0079, 0.9979, 0.9605], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.bias',\n",
       "              tensor([-0.0431, -0.0544, -0.0034, -0.0223, -0.0661, -0.0473,  0.0167, -0.0227,\n",
       "                       0.0401, -0.0646, -0.0667, -0.0258,  0.0152, -0.0265, -0.0657, -0.0459,\n",
       "                       0.0123, -0.0414, -0.0368, -0.0012, -0.0455, -0.0620, -0.0283, -0.0140,\n",
       "                      -0.0501, -0.0015, -0.0323, -0.0103, -0.0401, -0.0166, -0.0417, -0.0319,\n",
       "                      -0.0245, -0.0091, -0.0114, -0.0136, -0.0211, -0.0109, -0.0301, -0.0696,\n",
       "                       0.0142, -0.0362, -0.0630, -0.0600,  0.0021, -0.0561, -0.0449, -0.0276,\n",
       "                      -0.0370, -0.0513, -0.0080, -0.0435, -0.0637, -0.0744, -0.0490, -0.0108,\n",
       "                      -0.0025, -0.0171, -0.0196, -0.0394, -0.0337, -0.0020,  0.0004, -0.0372,\n",
       "                      -0.0046, -0.0149,  0.0055,  0.0231,  0.0092, -0.0450, -0.0603, -0.0443,\n",
       "                      -0.0240, -0.0073, -0.0230, -0.0267, -0.0105, -0.0543, -0.0301, -0.0206,\n",
       "                      -0.0268,  0.0080, -0.0596,  0.0023,  0.0015, -0.0365,  0.0021, -0.0035,\n",
       "                      -0.0510,  0.0044, -0.0717,  0.0037,  0.0033, -0.0101, -0.0516, -0.0264,\n",
       "                      -0.0198, -0.0409, -0.0297,  0.0037, -0.0315, -0.0318, -0.0242, -0.0592,\n",
       "                      -0.0592, -0.0513, -0.0545,  0.0085, -0.0289, -0.0080, -0.0509, -0.0348,\n",
       "                      -0.0214,  0.0015, -0.0047, -0.0623, -0.0269, -0.0075, -0.0388, -0.0689,\n",
       "                      -0.0650, -0.0557, -0.0452,  0.0096, -0.0119, -0.0240, -0.0276, -0.0467,\n",
       "                       0.0111, -0.0413, -0.0517, -0.0131, -0.0696, -0.0144, -0.0606,  0.0253,\n",
       "                      -0.0297, -0.0052, -0.0630, -0.0437, -0.0078, -0.0465, -0.0015, -0.0060,\n",
       "                      -0.0443, -0.0010, -0.0323, -0.0105, -0.0012, -0.0105, -0.0661,  0.0002,\n",
       "                      -0.0148, -0.0279, -0.0600, -0.0067, -0.0606,  0.0039, -0.0205, -0.0446,\n",
       "                      -0.0423, -0.0134, -0.0260, -0.0435, -0.0076, -0.0246, -0.0639,  0.0119,\n",
       "                       0.0219, -0.0422, -0.0284,  0.0211, -0.0675,  0.0028, -0.0112, -0.0490,\n",
       "                       0.0080, -0.0136,  0.0085, -0.0389,  0.0118, -0.0056,  0.0031, -0.0521,\n",
       "                      -0.0320, -0.0502, -0.0118, -0.0645, -0.0449, -0.0192, -0.0497, -0.0069,\n",
       "                      -0.0167, -0.0364, -0.0459, -0.0389, -0.0585, -0.0371, -0.0185, -0.0025,\n",
       "                      -0.0640, -0.0215, -0.0477,  0.0044, -0.0420, -0.0352, -0.0197, -0.0110,\n",
       "                      -0.0502,  0.0061, -0.0537, -0.0565, -0.0659, -0.0074, -0.0492,  0.0024,\n",
       "                      -0.0089, -0.0405, -0.0542,  0.0056, -0.0694,  0.0080, -0.0402, -0.0051,\n",
       "                      -0.0379, -0.0468, -0.0613,  0.0233, -0.0021, -0.0130,  0.0174,  0.0034,\n",
       "                       0.0107, -0.0576, -0.0112, -0.0144, -0.0170, -0.0060, -0.0319, -0.0318,\n",
       "                       0.0185, -0.0221, -0.0560, -0.0489, -0.0119, -0.0505, -0.0409,  0.0021,\n",
       "                      -0.0170, -0.0476, -0.0548, -0.0204, -0.0276, -0.0096, -0.0507, -0.0680],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm4.running_mean',\n",
       "              tensor([ 2.7704,  1.8593, -3.4148,  1.6473,  0.8161,  1.9041, -2.8632, -0.4246,\n",
       "                      -2.0613, -1.5235,  0.3738, -0.8573, -2.3396, -1.9544,  0.9619,  2.0078,\n",
       "                      -0.5464,  2.0794,  1.5922, -2.1763,  2.1918,  1.0766, -1.0055,  1.8109,\n",
       "                       2.3614, -2.5700,  1.8489, -3.3604,  2.3355, -0.9349,  3.0242, -2.6121,\n",
       "                      -2.3165, -2.4760, -2.1865, -0.6223, -1.9611,  0.6517, -1.5423,  2.5080,\n",
       "                      -3.7038, -0.9139,  1.9724,  0.9692, -3.0222,  3.0954,  1.1311,  0.6353,\n",
       "                      -2.5061,  3.3675, -2.1289,  2.7515,  1.0089,  2.0540,  2.4291, -2.4046,\n",
       "                      -1.8356,  1.2550, -0.1289,  2.0893, -2.1270, -2.5310, -1.8931,  2.3247,\n",
       "                      -1.8913, -2.3588, -1.9566, -2.2075, -2.3223,  2.7308,  1.1081, -0.2862,\n",
       "                      -2.0705, -1.8771,  2.0120,  1.9895, -2.6328,  1.7277, -1.1052, -1.7249,\n",
       "                       1.6610, -2.3585,  2.0555, -0.5067, -1.5751, -0.7524, -1.2325, -1.6261,\n",
       "                       0.2941, -2.2943,  1.6094, -2.9387, -2.0518, -2.2478,  1.5958,  0.7020,\n",
       "                      -1.7069, -2.1477, -2.5714, -3.1850,  2.9064,  2.5761, -0.7873,  1.7574,\n",
       "                       3.1532,  1.0057,  2.7793, -1.5192, -2.0464, -2.3619,  2.1536, -2.0554,\n",
       "                      -1.9062, -1.7571, -2.6465,  1.1497,  0.0278, -1.7688,  0.5399,  2.1916,\n",
       "                       3.4872,  3.1943,  1.5154, -2.6957, -1.3864, -2.4028, -1.6261, -0.6040,\n",
       "                      -1.9908,  1.2536,  1.6471, -2.4213,  0.1802,  1.0614,  0.5497, -3.5461,\n",
       "                      -1.8913, -2.1844,  1.3666,  1.9381, -1.1841,  1.0410, -2.4385, -1.6339,\n",
       "                       3.1978, -2.4310, -2.7156, -2.0404, -1.8874,  1.7339,  0.3188, -2.0136,\n",
       "                      -1.6960, -2.2746,  0.1979, -2.3297,  0.6840, -1.8817, -2.6897,  1.7838,\n",
       "                       0.7992,  2.0074, -1.1156,  1.5395, -2.3291, -0.4111,  0.4665, -1.4120,\n",
       "                      -2.7434,  1.1942,  1.9471, -1.8915,  1.7312, -0.9258,  1.5937, -0.2252,\n",
       "                      -3.8698, -2.7178, -1.0228, -0.3591, -3.5198, -2.9992, -2.5160,  2.3504,\n",
       "                      -1.0032,  1.1139,  1.7743,  1.2787, -1.3075,  0.7103,  1.8713, -2.2438,\n",
       "                      -2.4972,  2.0999,  1.6534, -1.4161,  2.2157,  0.2299, -1.2413, -2.2893,\n",
       "                       0.7399, -1.3419,  1.0443, -1.1311,  1.0326, -0.5817, -2.6660, -1.6502,\n",
       "                       2.9385, -2.4635,  3.0591,  1.7883, -0.0891, -2.7748, -0.2025, -2.9840,\n",
       "                      -2.1400,  1.9651,  0.2939, -1.7701, -0.2005, -2.2928,  2.5761, -2.6061,\n",
       "                       0.9699,  1.8391,  4.3654, -2.2567, -1.5525, -3.2325, -2.3223,  1.3380,\n",
       "                      -1.8037,  2.0438, -1.0594, -2.7760, -2.3087, -1.4949, -1.7218, -3.2107,\n",
       "                      -2.2724, -1.2707,  2.8405,  1.9514, -1.9527,  1.6398, -1.5020,  1.1610,\n",
       "                      -1.4143,  3.1555,  2.7525,  2.1330,  1.8218,  1.4646,  2.8210,  0.4799],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm4.running_var',\n",
       "              tensor([6.3978, 2.6235, 4.7397, 4.2226, 1.8106, 4.1408, 5.1021, 1.8926, 1.5908,\n",
       "                      2.2305, 1.7729, 2.7145, 3.4315, 2.7841, 1.4278, 5.3773, 2.2999, 3.0582,\n",
       "                      2.5421, 1.7344, 5.6743, 2.5939, 1.6843, 3.6928, 4.6978, 4.3925, 3.2852,\n",
       "                      6.1408, 4.9797, 2.6198, 6.0754, 3.3324, 5.2540, 5.1134, 6.0166, 2.8767,\n",
       "                      3.1429, 1.7540, 2.8369, 2.8673, 5.3666, 1.0671, 3.2541, 2.1754, 7.5197,\n",
       "                      4.1003, 1.9737, 1.6083, 4.3741, 6.3216, 3.8787, 2.4702, 2.1912, 4.5532,\n",
       "                      2.9650, 3.6054, 3.0037, 3.3366, 3.1339, 1.2606, 3.3726, 5.0850, 2.6464,\n",
       "                      5.2528, 3.0249, 2.7459, 3.3594, 2.6564, 3.3893, 4.1017, 2.7442, 1.5252,\n",
       "                      4.1013, 3.4576, 4.7123, 4.7051, 2.4498, 1.5999, 1.5766, 3.0482, 4.3611,\n",
       "                      4.2786, 1.4343, 1.3932, 4.6772, 1.8486, 4.6230, 2.1055, 1.3992, 2.8311,\n",
       "                      2.7189, 6.2761, 3.7423, 6.2724, 3.2456, 2.2026, 1.6399, 2.7188, 3.8644,\n",
       "                      5.1442, 4.3107, 6.5820, 6.1111, 3.3996, 3.2311, 2.4760, 5.3816, 2.3645,\n",
       "                      3.0006, 3.3733, 3.1295, 3.0793, 2.9827, 1.5969, 3.7291, 1.5769, 1.3075,\n",
       "                      3.0250, 1.9638, 4.5402, 5.8942, 4.9710, 2.1864, 3.5489, 2.7790, 4.2401,\n",
       "                      2.7087, 1.7673, 4.8047, 2.8338, 3.1713, 6.4951, 1.7717, 4.1078, 1.5641,\n",
       "                      4.3772, 3.2855, 3.0695, 2.2745, 3.5816, 2.8259, 2.8772, 4.5738, 2.2352,\n",
       "                      4.9541, 3.6639, 6.3439, 2.3209, 5.1463, 3.4504, 1.5049, 5.6264, 2.7268,\n",
       "                      3.3017, 1.3483, 5.1527, 1.8686, 2.1949, 2.8510, 3.8541, 3.9161, 3.9734,\n",
       "                      1.9920, 1.9962, 5.0461, 0.5596, 1.4278, 4.9470, 4.3950, 1.7546, 5.0035,\n",
       "                      5.6324, 1.2088, 1.4121, 5.1583, 1.4166, 4.8832, 5.6010, 3.8364, 1.4089,\n",
       "                      4.6396, 2.8979, 2.7409, 3.8119, 1.9797, 3.6145, 5.6131, 2.7874, 1.8528,\n",
       "                      4.1515, 4.1400, 4.3446, 4.9825, 4.0439, 3.0222, 2.2853, 4.5890, 1.1743,\n",
       "                      3.2091, 3.6845, 1.8537, 3.1621, 3.0130, 2.5782, 2.4870, 1.2841, 5.2840,\n",
       "                      3.8044, 4.0426, 3.0360, 5.7133, 3.4859, 0.4505, 5.2408, 1.0128, 3.7668,\n",
       "                      5.4057, 4.2245, 1.8594, 4.3998, 1.7337, 3.2638, 3.1335, 3.4976, 1.6670,\n",
       "                      2.8571, 9.3585, 4.0778, 2.6651, 6.1402, 3.1230, 4.7924, 2.2817, 3.1654,\n",
       "                      6.4806, 4.6547, 5.9091, 3.0910, 3.4012, 4.1657, 5.9187, 3.4633, 6.3407,\n",
       "                      2.1375, 3.3906, 2.9389, 3.0474, 4.7883, 3.4055, 6.5479, 4.6500, 3.4710,\n",
       "                      6.0093, 4.6583, 3.0219, 1.4717], device='cuda:0')),\n",
       "             ('cnn.batchnorm4.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0')),\n",
       "             ('cnn.conv5.weight',\n",
       "              tensor([[[[-9.9105e-03,  5.0881e-03,  9.9552e-04],\n",
       "                        [ 6.5876e-03, -5.2251e-03, -2.5752e-02],\n",
       "                        [-1.5357e-02, -2.0334e-03,  1.7639e-03]],\n",
       "              \n",
       "                       [[-1.1817e-02, -2.4243e-02, -1.3528e-02],\n",
       "                        [-2.6796e-02, -2.4476e-02, -8.6744e-03],\n",
       "                        [-2.3200e-02, -6.3545e-04, -1.7537e-02]],\n",
       "              \n",
       "                       [[-1.5704e-02, -2.1384e-02, -1.8813e-02],\n",
       "                        [-1.0131e-02, -1.0990e-02, -2.9603e-02],\n",
       "                        [ 1.4874e-03, -2.7923e-02, -2.6052e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.4356e-02, -7.6465e-03, -1.9559e-02],\n",
       "                        [ 1.3351e-02, -1.1684e-02, -1.6849e-02],\n",
       "                        [ 5.5105e-03, -8.5722e-04,  6.8238e-03]],\n",
       "              \n",
       "                       [[-6.9137e-03,  1.0152e-02,  6.3584e-03],\n",
       "                        [ 1.3459e-02, -2.5697e-02, -1.8382e-02],\n",
       "                        [ 1.0654e-02,  5.8893e-03, -2.6264e-02]],\n",
       "              \n",
       "                       [[-2.4217e-03,  1.6365e-02, -3.1929e-03],\n",
       "                        [ 1.4426e-02, -1.3768e-02, -8.6159e-03],\n",
       "                        [ 1.9781e-02, -1.4786e-02, -3.3201e-03]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.0291e-03, -2.5827e-02, -1.7787e-02],\n",
       "                        [-9.7054e-03,  7.6608e-03, -1.2709e-03],\n",
       "                        [ 4.1976e-03, -1.6152e-02,  8.9184e-03]],\n",
       "              \n",
       "                       [[-2.3833e-02, -9.3956e-03, -4.1254e-03],\n",
       "                        [-8.6296e-03,  3.4739e-03, -1.7143e-02],\n",
       "                        [ 1.0912e-02, -6.8337e-03,  1.6208e-02]],\n",
       "              \n",
       "                       [[ 1.2281e-02, -3.0015e-02, -2.8168e-02],\n",
       "                        [-7.0948e-03, -2.7709e-02, -1.4430e-02],\n",
       "                        [-1.9545e-03, -1.9053e-02,  1.3170e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.1040e-02,  2.0952e-02, -3.7780e-03],\n",
       "                        [-1.3648e-03,  1.6339e-02,  5.2838e-03],\n",
       "                        [ 6.9154e-03,  8.2068e-03,  1.0713e-02]],\n",
       "              \n",
       "                       [[-8.6108e-03, -1.5106e-02, -1.5774e-02],\n",
       "                        [-7.7077e-03,  8.4933e-03, -4.6085e-03],\n",
       "                        [-1.3037e-02, -6.4615e-03, -1.7400e-02]],\n",
       "              \n",
       "                       [[-1.3599e-02,  5.6890e-03, -2.0346e-02],\n",
       "                        [-1.2213e-02,  3.6872e-03, -2.7173e-02],\n",
       "                        [-6.7447e-03,  7.4798e-03, -2.6648e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.1563e-02, -1.5175e-02, -1.5712e-02],\n",
       "                        [-1.9370e-02, -1.4399e-03,  5.6553e-03],\n",
       "                        [ 2.6027e-03, -1.6744e-02, -3.0995e-02]],\n",
       "              \n",
       "                       [[-2.3301e-04,  4.2526e-03, -1.5448e-02],\n",
       "                        [-2.2832e-02, -1.2586e-02,  9.3673e-03],\n",
       "                        [-2.6144e-02,  6.5604e-03,  3.0611e-03]],\n",
       "              \n",
       "                       [[ 2.0666e-03, -4.0328e-02, -1.4563e-02],\n",
       "                        [-2.3650e-02, -2.4427e-02, -4.9779e-02],\n",
       "                        [-2.8678e-02, -3.2169e-02, -2.5739e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 2.5899e-03, -4.9803e-03, -1.2054e-02],\n",
       "                        [-6.6354e-03, -7.8827e-04, -1.0273e-04],\n",
       "                        [ 1.5024e-03,  1.4836e-02, -1.1892e-02]],\n",
       "              \n",
       "                       [[ 4.2522e-03, -5.1049e-03, -1.5433e-02],\n",
       "                        [-2.0216e-02, -1.1001e-03, -1.9713e-02],\n",
       "                        [-1.9315e-02,  7.5687e-03, -2.8282e-02]],\n",
       "              \n",
       "                       [[ 1.8728e-02, -2.1318e-02,  6.4302e-03],\n",
       "                        [-1.5248e-03, -2.5871e-03,  1.3181e-02],\n",
       "                        [ 1.9310e-02, -1.0916e-02, -2.1063e-03]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 1.6819e-03, -1.0692e-02, -5.8505e-03],\n",
       "                        [-2.9454e-02,  4.4423e-03, -2.5349e-02],\n",
       "                        [-5.9157e-03,  9.4766e-03, -3.1415e-02]],\n",
       "              \n",
       "                       [[-9.1317e-03, -8.4035e-03,  2.4786e-03],\n",
       "                        [-1.2555e-02,  1.4145e-02,  1.4925e-03],\n",
       "                        [ 1.6165e-03,  1.4537e-02,  6.6124e-03]],\n",
       "              \n",
       "                       [[-1.8692e-02, -8.5453e-03, -8.3313e-03],\n",
       "                        [ 2.2578e-03, -1.3199e-02,  4.6859e-03],\n",
       "                        [-6.6310e-03, -2.5104e-02, -1.6849e-02]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 6.2902e-04, -4.5276e-03,  1.0671e-02],\n",
       "                        [-1.1067e-02, -1.1113e-03, -1.7643e-02],\n",
       "                        [ 1.8444e-03, -1.8776e-02,  1.3804e-02]],\n",
       "              \n",
       "                       [[-1.3142e-02, -1.7618e-02,  8.8498e-03],\n",
       "                        [-1.1833e-02, -2.2386e-02, -1.4244e-02],\n",
       "                        [ 1.0100e-02, -6.2318e-03, -7.5215e-03]],\n",
       "              \n",
       "                       [[ 1.5018e-03, -8.6095e-03,  3.9582e-03],\n",
       "                        [ 4.9231e-03, -2.4835e-02,  3.0023e-03],\n",
       "                        [ 4.1969e-03,  2.8045e-04, -1.2835e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 2.2918e-03,  1.8646e-04, -2.0927e-02],\n",
       "                        [-1.1238e-02, -1.4006e-02, -1.2475e-02],\n",
       "                        [ 1.8089e-02, -1.5592e-02,  1.2789e-02]],\n",
       "              \n",
       "                       [[-5.8122e-03, -3.5031e-03, -2.3352e-02],\n",
       "                        [-5.2801e-03, -3.4526e-03, -1.7480e-02],\n",
       "                        [-2.2615e-02,  4.0514e-03, -3.7598e-03]],\n",
       "              \n",
       "                       [[-1.3475e-02,  2.0648e-02, -2.0799e-02],\n",
       "                        [ 8.9264e-03,  1.3050e-02, -1.5168e-02],\n",
       "                        [-1.2982e-02,  2.4715e-02, -9.4350e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-1.9337e-02, -2.2640e-02,  9.4552e-03],\n",
       "                        [ 1.9247e-02, -1.3963e-02, -7.5157e-04],\n",
       "                        [ 1.3532e-02,  8.7022e-03, -1.5578e-03]],\n",
       "              \n",
       "                       [[-2.3707e-02, -3.7195e-03, -1.0987e-02],\n",
       "                        [-2.2522e-02, -1.4604e-02, -3.2032e-04],\n",
       "                        [ 6.2877e-03,  2.0782e-03, -1.6919e-02]],\n",
       "              \n",
       "                       [[-9.5905e-03,  1.3192e-02,  1.4105e-02],\n",
       "                        [-7.8220e-05, -1.5463e-02,  3.0862e-03],\n",
       "                        [-7.4289e-03,  1.7795e-03, -2.3573e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4902e-03, -1.7842e-02,  1.6582e-02],\n",
       "                        [-4.2197e-03,  1.1563e-02, -1.6236e-02],\n",
       "                        [-1.9954e-02,  1.4292e-02,  1.8648e-02]],\n",
       "              \n",
       "                       [[-1.9943e-03, -1.7842e-02,  1.1983e-02],\n",
       "                        [ 2.2385e-02,  2.4104e-02,  3.4949e-02],\n",
       "                        [ 4.6157e-03,  3.7805e-03,  1.8651e-02]],\n",
       "              \n",
       "                       [[ 1.6437e-02,  3.3211e-02, -1.6296e-03],\n",
       "                        [ 2.1675e-02,  4.4266e-03,  7.3381e-03],\n",
       "                        [-8.8860e-03,  8.6363e-03, -4.0965e-03]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-3.1461e-02, -3.6829e-02, -1.6676e-02],\n",
       "                        [-3.5488e-02, -2.3685e-02, -4.3222e-02],\n",
       "                        [-1.6111e-02, -2.5092e-02, -3.5732e-02]],\n",
       "              \n",
       "                       [[ 1.4965e-02, -8.0039e-03,  2.9944e-02],\n",
       "                        [-8.6791e-03, -7.4382e-03,  1.8083e-02],\n",
       "                        [ 1.5949e-02,  1.9121e-02,  2.1357e-02]],\n",
       "              \n",
       "                       [[-2.1287e-02, -2.5077e-02, -1.1159e-02],\n",
       "                        [ 6.6412e-03,  7.1254e-03, -2.0548e-02],\n",
       "                        [ 2.8322e-03, -2.5448e-02,  1.1743e-03]]]], device='cuda:0')),\n",
       "             ('cnn.conv5.bias',\n",
       "              tensor([ 9.0781e-03,  6.9708e-03,  5.3602e-03,  9.6525e-03, -1.5185e-02,\n",
       "                       1.9179e-02, -1.7746e-02, -8.1950e-03,  1.5985e-02, -1.5222e-02,\n",
       "                      -3.2510e-03,  1.8997e-05, -1.7530e-02, -7.5858e-04,  5.6476e-03,\n",
       "                       1.7313e-02,  1.2706e-02,  7.6228e-03,  1.5704e-02,  1.3592e-02,\n",
       "                       8.4982e-03,  1.5946e-02, -1.5003e-02, -1.1627e-02, -1.6307e-02,\n",
       "                      -1.8454e-02,  1.1398e-02,  1.4587e-02, -1.9734e-02, -1.2400e-02,\n",
       "                      -7.4495e-03, -7.1043e-03,  1.0336e-02,  1.1629e-03,  1.0886e-03,\n",
       "                       1.2836e-02,  1.3923e-02, -1.6926e-02, -7.8380e-03, -8.0105e-04,\n",
       "                      -1.9629e-02, -1.9895e-02,  1.5217e-02, -1.5288e-02,  1.4418e-02,\n",
       "                       3.7252e-04, -1.7195e-02, -1.1564e-02, -6.8419e-03, -5.1520e-03,\n",
       "                       7.2490e-03,  5.6697e-03,  1.1583e-02,  3.9799e-03, -1.5815e-02,\n",
       "                       6.4893e-03, -7.0038e-03, -1.7235e-03,  9.7266e-03, -1.6671e-02,\n",
       "                      -1.6959e-02,  1.3068e-02,  5.7045e-03, -2.4528e-03, -9.9147e-03,\n",
       "                      -1.1893e-02, -7.6194e-03,  2.0818e-02,  1.9561e-02, -1.8892e-02,\n",
       "                      -1.8302e-02,  1.5704e-02, -1.9821e-02,  2.0318e-02,  8.1148e-03,\n",
       "                       1.7984e-02, -1.7804e-03, -3.2116e-05,  1.6056e-02,  1.3214e-02,\n",
       "                       1.1307e-02, -1.2094e-02, -6.2731e-04,  6.8944e-03, -2.0384e-02,\n",
       "                       6.0541e-03,  4.5479e-03,  1.3317e-02, -1.3693e-02,  9.6821e-03,\n",
       "                       1.0565e-02,  7.0692e-04, -5.7593e-03,  9.9500e-03,  8.0837e-03,\n",
       "                      -9.2584e-03,  2.0077e-02, -6.1963e-03, -6.7813e-03, -7.4090e-04,\n",
       "                       1.7773e-02, -1.7879e-02, -1.4196e-02,  1.7306e-02, -4.5926e-03,\n",
       "                      -1.8869e-02, -1.6112e-02,  1.4453e-02, -1.3015e-02,  1.6357e-02,\n",
       "                      -1.9891e-02, -1.9920e-02, -1.5094e-02,  5.5177e-05, -6.5969e-03,\n",
       "                       6.4228e-03, -6.9173e-03, -1.4536e-02, -2.0072e-02, -9.3665e-03,\n",
       "                      -7.1432e-03, -6.1461e-03, -2.2443e-03, -1.7324e-02,  1.9429e-02,\n",
       "                      -1.4209e-02, -1.9694e-02,  8.4819e-03, -9.6268e-03, -1.1777e-02,\n",
       "                       1.3364e-02,  1.6542e-02, -1.0733e-02,  1.7867e-03, -1.2979e-02,\n",
       "                       1.3481e-02,  1.4075e-02,  1.6146e-02, -9.1942e-03,  1.9856e-02,\n",
       "                      -1.2485e-02, -1.0883e-02,  1.9898e-02,  1.6124e-02,  1.8287e-02,\n",
       "                       1.6696e-02,  7.1417e-03,  1.7680e-02, -1.2320e-02,  3.7885e-03,\n",
       "                      -1.8643e-02, -2.3296e-03,  8.0621e-04,  3.5308e-03,  1.8653e-02,\n",
       "                       1.9549e-02, -1.6417e-02,  1.8311e-02,  1.6021e-02,  2.8754e-03,\n",
       "                       1.4584e-02, -2.5327e-03, -1.7048e-02, -5.4908e-03,  1.9781e-02,\n",
       "                      -2.6718e-03,  1.3394e-02, -1.2277e-02,  2.0675e-02, -1.1030e-02,\n",
       "                       6.1107e-03,  4.7356e-03,  6.8522e-03, -1.3430e-02,  7.8482e-03,\n",
       "                       2.0034e-02, -8.3906e-03,  2.0276e-02,  2.0776e-02, -4.3885e-03,\n",
       "                       4.2836e-03,  1.5299e-02,  1.1357e-02, -1.0369e-02,  1.4647e-02,\n",
       "                      -1.6527e-04,  9.9819e-03, -6.6031e-03,  9.8456e-03, -7.1884e-03,\n",
       "                      -3.0537e-03,  1.6077e-02,  8.2823e-03, -1.7368e-02, -8.5117e-03,\n",
       "                       8.8158e-03, -1.9151e-02, -5.6777e-03, -6.9004e-04, -6.4146e-03,\n",
       "                       4.3306e-03,  9.2899e-03,  5.9611e-03, -9.4275e-03, -8.9645e-03,\n",
       "                       4.7441e-03, -1.8388e-02,  4.5451e-03, -1.7562e-02,  2.6508e-03,\n",
       "                       1.7268e-03,  1.7125e-02, -1.3516e-02,  1.2782e-03,  7.6653e-03,\n",
       "                       1.0225e-02,  1.3232e-02, -1.7046e-02, -1.2918e-02, -1.5552e-02,\n",
       "                      -1.9969e-03, -6.1073e-03, -7.2600e-03, -6.1634e-03, -9.5254e-03,\n",
       "                       1.4629e-02, -1.3622e-02,  1.3776e-02,  1.5544e-02,  4.6247e-03,\n",
       "                       1.6149e-02,  3.1743e-03,  1.4950e-02, -9.8640e-03,  8.8034e-03,\n",
       "                       8.6911e-03,  1.5695e-02,  2.0055e-02, -1.5908e-02,  9.8214e-03,\n",
       "                       1.9559e-03,  7.2837e-03,  1.2895e-02,  1.3439e-03,  1.2424e-02,\n",
       "                       1.3652e-02,  2.1177e-03, -5.3939e-03, -1.6339e-02,  1.6754e-02,\n",
       "                      -4.3267e-03,  6.5973e-03,  1.1543e-02,  1.3834e-02,  1.6240e-02,\n",
       "                      -5.8860e-03], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.weight',\n",
       "              tensor([0.9959, 0.9931, 0.9947, 0.9711, 0.9805, 0.9611, 0.9705, 0.9880, 0.9858,\n",
       "                      0.9976, 0.9962, 1.0020, 0.9708, 0.9946, 0.9919, 0.9563, 0.9527, 0.9942,\n",
       "                      0.9906, 0.9132, 0.9795, 0.9852, 0.9785, 0.9403, 0.9791, 0.9722, 0.9374,\n",
       "                      1.0023, 0.9700, 0.9980, 0.9761, 0.9541, 0.9751, 0.9840, 0.9853, 0.9781,\n",
       "                      0.9945, 0.9713, 0.9770, 1.0018, 0.9635, 0.9834, 0.9711, 0.9632, 0.9580,\n",
       "                      0.9695, 0.9621, 0.9616, 0.9686, 0.9923, 0.9771, 0.9865, 0.9846, 0.9936,\n",
       "                      0.9974, 0.9665, 0.9967, 0.9898, 0.9975, 0.9438, 0.9388, 0.9852, 0.9841,\n",
       "                      0.9953, 0.9970, 0.9734, 0.9712, 0.9296, 0.9954, 0.9898, 0.9395, 0.9860,\n",
       "                      0.9903, 0.9813, 0.9898, 0.9669, 0.9668, 0.9770, 0.9687, 0.9958, 0.9703,\n",
       "                      0.9729, 0.9614, 0.9743, 0.9751, 0.9654, 0.9361, 0.9857, 0.9966, 0.9955,\n",
       "                      0.9914, 0.9853, 0.9704, 0.9637, 0.9560, 0.9870, 0.9858, 1.0098, 0.9470,\n",
       "                      0.9830, 1.0051, 0.9638, 0.9931, 0.9769, 0.9971, 0.9840, 0.9811, 1.0047,\n",
       "                      0.9904, 0.9906, 0.9732, 0.9868, 0.9628, 0.9948, 0.9819, 1.0010, 0.9955,\n",
       "                      0.9614, 0.9893, 0.9865, 0.9686, 0.9738, 0.9828, 0.9708, 0.9723, 0.9989,\n",
       "                      0.9918, 0.9589, 0.9983, 0.9843, 0.9910, 0.9890, 0.9953, 0.9772, 0.9802,\n",
       "                      0.9681, 0.9696, 0.9811, 0.9963, 0.9559, 0.9970, 0.9604, 0.9629, 0.9805,\n",
       "                      0.9748, 0.9899, 0.9570, 0.9854, 0.9966, 0.9697, 0.9914, 0.9884, 0.9960,\n",
       "                      0.9769, 1.0060, 0.9553, 0.9692, 0.9958, 1.0087, 0.9820, 0.9737, 0.9659,\n",
       "                      0.9913, 0.9789, 0.9973, 1.0025, 0.9937, 0.9952, 0.9884, 0.9767, 0.9930,\n",
       "                      0.9797, 0.9670, 0.9472, 0.9864, 0.9720, 1.0028, 0.9798, 0.9835, 1.0004,\n",
       "                      0.9800, 0.9981, 0.9738, 0.9734, 0.9826, 0.9286, 0.9595, 0.9924, 0.9931,\n",
       "                      0.9930, 0.9853, 0.9792, 0.9880, 0.9972, 0.9663, 0.9930, 0.9861, 0.9964,\n",
       "                      0.9888, 0.9971, 0.9568, 0.9968, 0.9821, 0.9748, 0.9949, 1.0032, 0.9591,\n",
       "                      0.9862, 0.9745, 0.9799, 0.9979, 0.9631, 1.0081, 0.9850, 0.9266, 0.9765,\n",
       "                      0.9924, 0.9976, 0.9963, 0.9951, 1.0022, 0.9599, 1.0032, 0.9694, 0.9881,\n",
       "                      0.9934, 0.9722, 0.9486, 1.0000, 0.9893, 0.9839, 0.9983, 1.0042, 0.9967,\n",
       "                      0.9620, 0.9819, 0.9665, 0.9653, 0.9758, 0.9920, 0.9980, 0.9860, 1.0013,\n",
       "                      0.9680, 0.9909, 0.9795, 0.9957, 0.9745, 0.9652, 0.9909, 0.9763, 0.9769,\n",
       "                      0.9873, 0.9821, 0.9881, 0.9991], device='cuda:0')),\n",
       "             ('cnn.batchnorm5.bias',\n",
       "              tensor([-0.0061, -0.0074, -0.0100, -0.0399, -0.0299, -0.0548, -0.0394, -0.0343,\n",
       "                      -0.0345, -0.0205, -0.0146, -0.0178, -0.0217, -0.0162, -0.0271, -0.0531,\n",
       "                      -0.0492, -0.0083, -0.0156, -0.0993, -0.0317, -0.0283, -0.0358, -0.0456,\n",
       "                      -0.0089, -0.0452, -0.0788, -0.0198, -0.0416, -0.0205, -0.0336, -0.0323,\n",
       "                      -0.0351, -0.0182, -0.0207, -0.0343, -0.0105, -0.0400, -0.0399, -0.0145,\n",
       "                      -0.0454, -0.0132, -0.0347, -0.0320, -0.0580, -0.0373, -0.0578, -0.0297,\n",
       "                      -0.0475, -0.0118, -0.0187, -0.0173, -0.0171, -0.0102, -0.0027, -0.0412,\n",
       "                      -0.0041, -0.0279, -0.0062, -0.0727, -0.0747, -0.0167, -0.0193, -0.0171,\n",
       "                      -0.0037, -0.0345, -0.0275, -0.0845, -0.0294, -0.0168, -0.0609, -0.0164,\n",
       "                      -0.0273, -0.0257, -0.0129, -0.0511, -0.0460, -0.0446, -0.0391, -0.0051,\n",
       "                      -0.0283, -0.0303, -0.0485, -0.0337, -0.0267, -0.0474, -0.0758, -0.0170,\n",
       "                      -0.0052, -0.0074, -0.0055, -0.0395, -0.0394, -0.0465, -0.0461, -0.0216,\n",
       "                      -0.0196, -0.0093, -0.0707, -0.0124, -0.0144, -0.0425, -0.0110, -0.0349,\n",
       "                      -0.0043, -0.0063, -0.0170, -0.0194, -0.0316, -0.0125, -0.0349, -0.0150,\n",
       "                      -0.0471, -0.0081, -0.0329, -0.0179, -0.0073, -0.0643, -0.0159, -0.0105,\n",
       "                      -0.0367, -0.0399, -0.0334, -0.0475, -0.0471, -0.0206, -0.0041, -0.0409,\n",
       "                      -0.0028, -0.0153, -0.0160, -0.0149, -0.0064, -0.0269, -0.0333, -0.0462,\n",
       "                      -0.0264, -0.0176, -0.0271, -0.0470, -0.0047, -0.0448, -0.0548, -0.0319,\n",
       "                      -0.0286, -0.0141, -0.0592, -0.0228, -0.0046, -0.0399, -0.0136, -0.0095,\n",
       "                      -0.0060, -0.0368, -0.0161, -0.0496, -0.0339, -0.0058, -0.0162, -0.0225,\n",
       "                      -0.0423, -0.0487, -0.0106, -0.0355, -0.0063, -0.0141, -0.0199, -0.0105,\n",
       "                      -0.0199, -0.0236, -0.0109, -0.0247, -0.0392, -0.0659, -0.0197, -0.0309,\n",
       "                      -0.0163, -0.0278, -0.0253, -0.0128, -0.0213, -0.0136, -0.0359, -0.0450,\n",
       "                      -0.0214, -0.0885, -0.0588, -0.0108, -0.0120, -0.0262, -0.0203, -0.0169,\n",
       "                      -0.0135, -0.0043, -0.0443, -0.0106, -0.0054, -0.0029, -0.0164, -0.0203,\n",
       "                      -0.0588, -0.0045, -0.0249, -0.0399, -0.0043, -0.0178, -0.0541, -0.0206,\n",
       "                      -0.0267, -0.0251, -0.0030, -0.0501, -0.0187, -0.0207, -0.0899, -0.0247,\n",
       "                      -0.0142, -0.0147, -0.0049, -0.0002, -0.0151, -0.0417, -0.0170, -0.0395,\n",
       "                      -0.0130, -0.0035, -0.0469, -0.0503, -0.0035, -0.0052, -0.0390, -0.0041,\n",
       "                      -0.0111, -0.0071, -0.0474, -0.0232, -0.0420, -0.0369, -0.0396, -0.0105,\n",
       "                      -0.0021, -0.0320, -0.0139, -0.0436, -0.0148, -0.0327, -0.0094, -0.0324,\n",
       "                      -0.0370, -0.0149, -0.0352, -0.0265, -0.0153, -0.0208, -0.0098, -0.0245],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm5.running_mean',\n",
       "              tensor([-3.8097, -3.4453, -6.2907, -3.3500, -4.8094, -4.0192, -5.0830, -1.3932,\n",
       "                      -0.0646,  1.8262,  0.6534,  2.0314,  0.4103, -1.0477,  1.9577, -5.5561,\n",
       "                      -5.6088, -4.7008, -4.7505, -0.2177, -5.0253,  1.0186, -3.3763, -1.4977,\n",
       "                       1.1721, -6.4351, -7.1502, -1.9208, -3.6615,  2.6544, -2.0483, -2.5951,\n",
       "                      -2.2685, -1.5685, -5.5853, -5.4804, -4.4955, -2.6762, -1.8326,  0.8567,\n",
       "                      -6.1424,  2.0700, -0.8821, -6.3348, -4.3338, -2.3965, -7.0434, -2.6829,\n",
       "                      -3.2040, -5.7487, -0.9081, -0.9901, -0.2566, -4.2500, -4.2888, -6.1615,\n",
       "                      -4.4272,  1.4121, -4.9481, -6.1164, -7.9336, -0.5015, -1.2765,  1.4617,\n",
       "                      -4.3321, -4.5602, -6.8169, -0.8996, -0.9048, -0.8637, -6.5507, -1.3224,\n",
       "                       1.5727, -1.3775, -3.4517, -2.6161, -3.6126, -1.8002, -6.7309, -4.0641,\n",
       "                      -0.5015,  0.1311, -4.3423, -2.1541, -1.0705, -5.0455, -6.6221, -0.8447,\n",
       "                      -4.0207, -4.5668, -3.5813, -2.2766, -7.4784, -7.3328, -5.5882, -6.0564,\n",
       "                      -0.2377, -1.6601, -8.2978,  0.5780,  1.7381, -6.1106, -4.8824, -1.3387,\n",
       "                      -4.7440,  0.9413,  0.2176, -1.0971,  2.7045, -4.5609, -8.4793, -0.9671,\n",
       "                      -1.4802, -4.4976,  1.1855,  1.6188, -3.4622, -6.3342, -4.8297, -0.1463,\n",
       "                      -6.0920,  1.9552,  1.8477, -4.4349, -4.9119,  1.9620, -3.6329, -8.5334,\n",
       "                      -3.9840, -4.5837, -1.0199, -4.5056, -3.7909, -2.5311, -2.3563, -2.7958,\n",
       "                      -5.6850, -5.6313, -1.5752, -8.9613, -4.4836, -5.6017, -3.9521, -5.1619,\n",
       "                      -5.9972, -4.4042, -6.1120, -5.6501, -4.2793, -3.1356, -5.0291, -1.2989,\n",
       "                      -4.0947,  1.3361, -1.5938, -0.1841, -8.6792, -5.0076, -1.7578, -1.1333,\n",
       "                      -2.7933, -2.7461, -0.1578, -6.4565, -4.9289, -1.9431, -0.8760,  0.4602,\n",
       "                       1.2437, -5.3493, -4.0524,  1.1390, -7.7736, -6.4521, -5.3256, -0.9128,\n",
       "                      -1.7131, -3.1008, -1.1511, -1.4104, -4.9928, -0.9439, -4.4570, -5.5024,\n",
       "                      -8.6431, -5.1635, -5.8880, -4.0611, -4.3159, -1.1614, -4.3422,  0.4875,\n",
       "                      -0.4021, -3.9230, -2.4868, -3.8322, -2.0860, -2.3348, -5.2389,  2.0210,\n",
       "                      -3.5641, -4.0560, -5.8844, -5.4420, -4.1252,  1.1012, -3.9632, -0.5415,\n",
       "                      -3.7575, -1.0923, -5.5527, -3.4528, -1.1473, -0.0930, -8.0392, -9.2886,\n",
       "                      -0.6909,  2.1272, -4.2953, -3.0008,  2.3083, -7.6035,  1.8278, -2.9162,\n",
       "                      -3.5604, -2.7528, -2.6090, -6.1161, -4.5878,  0.1171,  1.6609, -4.7235,\n",
       "                       1.8688, -4.4118, -7.7397, -1.3471, -6.5164, -1.9980, -3.0259, -6.1213,\n",
       "                      -4.1623, -2.2063,  0.2147, -2.3617, -0.8195, -2.1231, -5.2320, -4.1194,\n",
       "                       0.5777, -4.1851, -2.4358,  1.2566, -0.1398, -2.0559, -3.5192, -1.4569],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm5.running_var',\n",
       "              tensor([ 5.6971, 10.4517,  8.2683,  5.6161,  6.5643,  4.5683,  6.0814,  8.3840,\n",
       "                       5.4483,  8.7909,  4.6945,  7.6019, 11.5494,  3.8130, 10.1463,  7.6505,\n",
       "                       6.6773,  7.9003,  7.3406, 15.3627,  7.2003,  7.1462,  3.8900, 26.0765,\n",
       "                      14.5332,  9.3672, 11.3865,  5.7832,  3.3038,  9.6823,  3.4874, 52.3670,\n",
       "                       2.7005,  3.4714,  8.8380,  8.9619,  6.1436,  3.4593,  6.1967,  6.4960,\n",
       "                       7.7014, 10.3665,  4.4562,  8.3242,  5.1571,  2.8393, 10.4726, 14.2754,\n",
       "                       2.6722,  7.6064, 10.3895,  8.2786,  3.3059,  5.3221,  7.6354, 10.5384,\n",
       "                       4.9709,  7.0013,  7.0563,  9.4007, 11.9970,  4.6814,  7.7507,  6.1906,\n",
       "                       6.6576,  4.8871, 12.6655,  4.6600,  5.0990,  3.8364,  8.5078,  6.0003,\n",
       "                       9.1256,  3.9003,  4.6067,  9.9727,  2.8461,  6.4917, 10.0906,  5.8031,\n",
       "                      17.8564,  5.2943,  5.5348,  6.1215,  5.4541,  6.4422,  9.9307, 13.6873,\n",
       "                       5.7702,  6.1046,  5.3844,  8.3863, 12.0128, 10.6926,  6.5982,  8.2718,\n",
       "                       2.0732,  4.7006, 13.3701, 10.6154,  6.2349,  9.4385,  6.3416,  4.0169,\n",
       "                       6.8414, 12.3397,  3.9915,  5.0723, 11.1414,  7.9709, 11.7143,  9.2085,\n",
       "                       7.5873,  6.0917,  8.0744,  7.4095,  5.3175, 10.0830,  7.7851, 12.1171,\n",
       "                       7.1643, 10.4831,  9.7375,  6.1259,  6.0849,  7.8620, 11.5257, 14.2096,\n",
       "                       5.6393, 11.9252,  3.2822,  6.3099,  5.3691,  5.0939,  5.9904,  4.8174,\n",
       "                       7.9631, 18.5945,  5.5557, 14.2661,  6.3801,  8.2993,  4.1916,  5.8876,\n",
       "                      12.8299,  6.2295,  7.4619,  7.5213,  6.1711,  5.2088,  6.5847, 16.0642,\n",
       "                       5.4295,  9.7059,  4.9017,  3.4544, 12.8252,  7.3914,  4.8543,  3.0268,\n",
       "                       3.4257,  3.8371,  7.1369,  9.4832,  6.1721,  5.8479,  4.6129,  3.8022,\n",
       "                       7.4471,  7.8277,  6.3101,  6.3547, 12.0224,  9.2003,  8.4341,  6.0586,\n",
       "                       4.4480,  5.7550,  3.7447,  4.6230, 38.0793,  3.8095,  4.9767,  6.1487,\n",
       "                       9.8529,  8.8416,  6.5420,  7.0353,  6.2510,  5.9101,  6.0308,  4.9405,\n",
       "                       3.5146,  5.9601,  5.4074,  6.3725,  4.3840, 14.8527,  6.5244,  7.0803,\n",
       "                       3.8171,  5.3081,  7.8286,  7.5785, 13.0877,  7.1632,  4.3491,  4.1801,\n",
       "                      10.4721,  3.3037,  8.4485,  4.5506,  5.0235,  1.4403, 11.8504, 14.2809,\n",
       "                       2.9365,  5.2629,  5.4130, 14.3307,  8.1390, 11.1943,  8.4710,  3.5320,\n",
       "                       7.9786,  4.9447,  7.4521, 10.3007,  5.7485,  7.9451, 11.7006,  7.1511,\n",
       "                       6.3722,  5.7002, 12.0661,  3.2261, 10.0074,  5.4252,  2.4766,  8.8476,\n",
       "                       6.0900,  7.6067,  7.8518,  4.4816,  3.8196,  7.8417,  6.6239,  4.0017,\n",
       "                       6.9533,  5.5262,  3.9255,  6.6995,  2.2176,  8.7448, 13.2279,  5.8117],\n",
       "                     device='cuda:0')),\n",
       "             ('cnn.batchnorm5.num_batches_tracked',\n",
       "              tensor(1040, device='cuda:0'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aff62a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(args.train_data_folder)\n",
    "num_patient_files = len(patient_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "652112c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data = load_patient_data(patient_files[1])\n",
    "recordings = load_recordings(args.train_data_folder, patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b5a320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9979 4 4000\\nAV 9979_AV.hea 9979_AV.wav 9979_AV.tsv\\nPV 9979_PV.hea 9979_PV.wav 9979_PV.tsv\\nTV 9979_TV.hea 9979_TV.wav 9979_TV.tsv\\nMV 9979_MV.hea 9979_MV.wav 9979_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 103.0\\n#Weight: 13.1\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Diamond\\n#Systolic murmur grading: III/VI\\n#Systolic murmur pitch: High\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8e7d81f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1653, 3815, 3101, ...,  187,  348,   53], dtype=int16),\n",
       " array([32596, 28290,  8851, ...,  6449,  6299,  7167], dtype=int16),\n",
       " array([   244,  -3588, -22579, ...,   -207,   -205,   -204], dtype=int16),\n",
       " array([5039, 5952, 5754, ...,  344,  229,   87], dtype=int16)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f991cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "num_recordings = len(recordings)\n",
    "recordings_list=[]\n",
    "for i in range(num_recordings):\n",
    "    recording = recordings[i]\n",
    "    length = 20*4000  \n",
    "    if recording.shape[0] <= length:\n",
    "        shortage = length - recording.shape[0]\n",
    "        recording = np.pad(recording, (0, shortage), 'wrap')\n",
    "    start_frame = np.int64(random.random()*(recording.shape[0]-length))\n",
    "    recording = recording[start_frame:start_frame + length] \n",
    "    \n",
    "    recordings_list.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "48335d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings_list[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49438a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(data):\n",
    "    num_locations = get_num_locations(data)\n",
    "    locations = list()\n",
    "    for i, l in enumerate(data.split('\\n')):\n",
    "        entries = l.split(' ')\n",
    "        if i==0:\n",
    "            pass\n",
    "        elif 1<=i<=num_locations:\n",
    "            locations.append(entries[0])\n",
    "        else:\n",
    "            break\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5051aef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9979 4 4000',\n",
       " 'AV 9979_AV.hea 9979_AV.wav 9979_AV.tsv',\n",
       " 'PV 9979_PV.hea 9979_PV.wav 9979_PV.tsv',\n",
       " 'TV 9979_TV.hea 9979_TV.wav 9979_TV.tsv',\n",
       " 'MV 9979_MV.hea 9979_MV.wav 9979_MV.tsv',\n",
       " '#Age: Child',\n",
       " '#Sex: Female',\n",
       " '#Height: 103.0',\n",
       " '#Weight: 13.1',\n",
       " '#Pregnancy status: False',\n",
       " '#Murmur: Present',\n",
       " '#Murmur locations: AV+MV+PV+TV',\n",
       " '#Most audible location: TV',\n",
       " '#Systolic murmur timing: Holosystolic',\n",
       " '#Systolic murmur shape: Diamond',\n",
       " '#Systolic murmur grading: III/VI',\n",
       " '#Systolic murmur pitch: High',\n",
       " '#Systolic murmur quality: Harsh',\n",
       " '#Diastolic murmur timing: nan',\n",
       " '#Diastolic murmur shape: nan',\n",
       " '#Diastolic murmur grading: nan',\n",
       " '#Diastolic murmur pitch: nan',\n",
       " '#Diastolic murmur quality: nan',\n",
       " '#Outcome: Abnormal',\n",
       " '#Campaign: CC2015',\n",
       " '#Additional ID: nan',\n",
       " '']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8450d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MV']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_locations(patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51782385",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= {}\n",
    "a['key']=[3]\n",
    "a['key'].append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "13a238df",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[0.1,0.2,0.3],[0.5,0.7,0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da724211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f847bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jh20/narin/physionet/python-classifier-2022/model\")\n",
    "\n",
    "from CNN_outcome import CNN as CNN_outcome\n",
    "from CNN_murmur import CNN as CNN_murmur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b718c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jh20/narin/physionet/python-classifier-2022/model\")\n",
    "\n",
    "from CNN_outcome import CNN as CNN_outcome\n",
    "from CNN_murmur import CNN as CNN_murmur\n",
    "\n",
    "\n",
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    murmur_model , outcome_model = model\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print ('Available devices ', torch.cuda.device_count())\n",
    "        \n",
    "    GPU_NUM = args.gpu #  GPU  \n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    murmur_classifier = CNN_murmur()\n",
    "    murmur_classifier = murmur_classifier.cuda(device)\n",
    "    \n",
    "    outcome_classifier = CNN_outcome()\n",
    "    outcome_classifier = outcome_classifier.cuda(device)\n",
    "    \n",
    "    murmur_classifier.load_state_dict(murmur_model)\n",
    "    outcome_classifier.load_state_dict(outcome_model)\n",
    "    \n",
    "#     wav_files = glob.glob(data_folder + '*.wav')\n",
    "#     num_wav_files = len(wav_files)\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    num_outcome_classes = len(outcome_classes)\n",
    "    \n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "    \n",
    "    num_recordings = len(recordings)\n",
    "    recordings_list=[]\n",
    "    for i in range(num_recordings):\n",
    "        recording = recordings[i]\n",
    "        length = 20*4000  \n",
    "        if recording.shape[0] <= length:\n",
    "            shortage = length - recording.shape[0]\n",
    "            recording = np.pad(recording, (0, shortage), 'wrap')\n",
    "        start_frame = np.int64(random.random()*(recording.shape[0]-length))\n",
    "        recording = recording[start_frame:start_frame + length] \n",
    "        \n",
    "        recordings_list.append(recording)\n",
    "        \n",
    "\n",
    "    features = get_features(data, recordings_list)\n",
    "    \n",
    "    predict_murmur_arr= np.zeros((num_recordings,3))\n",
    "    predict_outcome_arr= np.zeros((num_recordings,2))\n",
    "    \n",
    "    for i in range(num_recordings):\n",
    "        \n",
    "        logmel = torch.tensor(features['mel'][i]).cuda()\n",
    "        age = torch.tensor(features['age']).cuda()\n",
    "        sex = torch.tensor(features['sex']).cuda()\n",
    "        hw = torch.tensor(features['hw']).cuda()\n",
    "        preg = torch.tensor(features['preg']).cuda()\n",
    "        loc = torch.tensor(features['loc'][i]).cuda()\n",
    "        \n",
    "        logmel = logmel.unsqueeze(0)\n",
    "        age = age.unsqueeze(0)\n",
    "        sex = sex.unsqueeze(0)\n",
    "        hw = hw.unsqueeze(0)\n",
    "        preg = preg.unsqueeze(0)\n",
    "        loc = loc.unsqueeze(0)\n",
    "        \n",
    "        \n",
    "        predict_murmur = murmur_classifier(logmel,age,sex,hw,preg,loc)\n",
    "        predict_outcome = outcome_classifier(logmel,age,sex,hw,preg,loc)\n",
    "        \n",
    "        predict_murmur_arr[i,:]= predict_murmur.data.detach().cpu().numpy()\n",
    "        predict_outcome_arr[i,:] = predict_outcome.data.detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    # Get classifier probabilities.\n",
    "    idx1 = predict_murmur_arr.argmax(axis=0)[0]\n",
    "    murmur_probabilities = predict_murmur_arr[idx1,] \n",
    "    idx2 = predict_outcome_arr.argmax(axis=0)[0]\n",
    "    outcome_probabilities = predict_outcome_arr[idx2,]\n",
    "\n",
    "\n",
    "    # Choose label with highest probability.\n",
    "    murmur_labels = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "    idx = np.argmax(murmur_probabilities)\n",
    "    murmur_labels[idx] = 1\n",
    "    outcome_labels = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "    idx = np.argmax(outcome_probabilities)\n",
    "    outcome_labels[idx] = 1\n",
    "\n",
    "    # Concatenate classes, labels, and probabilities.\n",
    "    classes = murmur_classes + outcome_classes\n",
    "    labels = np.concatenate((murmur_labels, outcome_labels))\n",
    "    probabilities = np.concatenate((murmur_probabilities, outcome_probabilities))\n",
    "\n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2df52fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent', 'Abnormal', 'Normal'],\n",
       " array([0, 0, 1, 1, 0]),\n",
       " array([-1.40384877, -2.05678463,  2.85122705, -0.57514155, -0.86318201]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model, patient_data, recordings, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b418f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math\n",
    "import random\n",
    "\n",
    "def get_features(data, recordings):\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    num_outcome_classes = len(outcome_classes)\n",
    "    \n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "    \n",
    "    num_recordings = len(recordings)\n",
    "    \n",
    "    \n",
    "    feature_dict={}\n",
    "    \n",
    "    feature_dict['mel']=[]\n",
    "    for i in range(num_recordings):\n",
    "        #log mel feature\n",
    "        log_mel_feature = librosa.power_to_db(librosa.feature.melspectrogram(y = recordings[i].astype(np.float32),\n",
    "                                                         sr= 4000,\n",
    "                                                             n_mels=128,\n",
    "                                                             n_fft=400, \n",
    "                                                             hop_length=128, \n",
    "                                                             win_length=400))\n",
    "        feature_dict['mel'].append(log_mel_feature)\n",
    "\n",
    "    # age\n",
    "    current_patient_age = get_age(data)\n",
    "    current_age_group = np.zeros(6, dtype=np.float32)\n",
    "    if current_patient_age in age_classes:\n",
    "        j = age_classes.index(current_patient_age)\n",
    "        current_age_group[j] = 1.0\n",
    "    else :\n",
    "        current_age_group[5] = 1.0\n",
    "\n",
    "    feature_dict['age']=current_age_group\n",
    "\n",
    "\n",
    "\n",
    "    # sex\n",
    "    sex = get_sex(data)\n",
    "    sex_feature = np.zeros(2, dtype=np.float32)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_feature[0] = 1.0\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_feature[1] = 1.0\n",
    "\n",
    "    feature_dict['sex']=sex_feature\n",
    "\n",
    "    # height and weight.\n",
    "    height = get_height(data)\n",
    "    weight = get_weight(data)\n",
    "\n",
    "    ## simple impute\n",
    "    if math.isnan(height) :\n",
    "        height = 110.846  #mean\n",
    "    if math.isnan(weight) :\n",
    "        weight = 23.767   #mean\n",
    "\n",
    "    height_weight = np.array([height, weight], dtype=np.float32)\n",
    "\n",
    "\n",
    "    feature_dict['hw']=height_weight\n",
    "\n",
    "    # Extract pregnancy\n",
    "    preg_feature = np.zeros(2, dtype=np.float32)\n",
    "    is_pregnant = get_pregnancy_status(data)\n",
    "    if is_pregnant == True:\n",
    "        preg_feature[0] = 1.0\n",
    "    elif is_pregnant == False:\n",
    "        preg_feature[1] = 1.0\n",
    "\n",
    "    feature_dict['preg']=preg_feature\n",
    "\n",
    "    # Extract location\n",
    "    feature_dict['loc']=[]\n",
    "    locations = get_locations(data)\n",
    "    for j in range(num_recordings):\n",
    "        \n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_feature = np.zeros(num_recording_locations, dtype=np.float32)\n",
    "        if locations[j] in recording_locations:\n",
    "            idx = recording_locations.index(locations[j])\n",
    "            loc_feature[idx] = 1.0\n",
    "            \n",
    "        feature_dict['loc'].append(loc_feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # label\n",
    "\n",
    "    current_murmur = np.zeros(num_murmur_classes, dtype=np.float32)\n",
    "    murmur = get_murmur(data)\n",
    "    if murmur in murmur_classes:\n",
    "        j = murmur_classes.index(murmur)\n",
    "        current_murmur[j] = 1\n",
    "    \n",
    "    feature_dict['murmur']=current_murmur\n",
    "    \n",
    "    current_outcome = np.zeros(num_outcome_classes, dtype=np.float32)\n",
    "    outcome = get_outcome(data)\n",
    "    if outcome in outcome_classes:\n",
    "        j = outcome_classes.index(outcome)\n",
    "        current_outcome[j] = 1\n",
    "\n",
    "    feature_dict['outcome']=current_outcome\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a7033f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_features(patient_data, recordings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1c08bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mel': [array([[75.30934 , 77.00927 , 83.088776, ..., 80.8318  , 86.529884,\n",
       "          88.27096 ],\n",
       "         [58.634106, 79.64537 , 87.44248 , ..., 82.98573 , 92.76573 ,\n",
       "          91.85199 ],\n",
       "         [78.831764, 88.22189 , 89.22766 , ..., 90.28073 , 98.51665 ,\n",
       "          92.334145],\n",
       "         ...,\n",
       "         [45.663227, 39.849247, 34.70859 , ..., 38.355736, 34.141945,\n",
       "          28.862543],\n",
       "         [50.000633, 40.511135, 28.31018 , ..., 34.58299 , 33.24843 ,\n",
       "          28.69713 ],\n",
       "         [47.834988, 36.78199 , 29.275002, ..., 35.732143, 35.664078,\n",
       "          30.107384]], dtype=float32),\n",
       "  array([[87.601845, 76.43325 , 79.42252 , ..., 70.45413 , 73.94233 ,\n",
       "          69.83109 ],\n",
       "         [87.891075, 81.897766, 84.23372 , ..., 77.206055, 77.980606,\n",
       "          61.839455],\n",
       "         [83.59927 , 81.24837 , 84.21284 , ..., 77.60032 , 81.69162 ,\n",
       "          69.34163 ],\n",
       "         ...,\n",
       "         [44.50908 , 44.98036 , 46.852917, ..., 38.21012 , 35.58448 ,\n",
       "          37.258762],\n",
       "         [38.52517 , 43.29669 , 45.468174, ..., 34.238922, 36.61655 ,\n",
       "          40.568928],\n",
       "         [39.374683, 34.329056, 35.068207, ..., 30.554483, 27.64943 ,\n",
       "          31.554401]], dtype=float32),\n",
       "  array([[ 83.575485,  80.42129 ,  87.126076, ...,  91.36433 ,  90.087524,\n",
       "           98.449715],\n",
       "         [ 84.10002 ,  85.36175 ,  86.8987  , ...,  99.30607 ,  95.90527 ,\n",
       "          102.18408 ],\n",
       "         [ 88.86778 ,  92.90735 ,  92.17537 , ..., 103.40753 ,  96.47781 ,\n",
       "          101.29808 ],\n",
       "         ...,\n",
       "         [ 33.926476,  33.926476,  33.926476, ...,  44.3729  ,  44.664326,\n",
       "           46.9543  ],\n",
       "         [ 33.926476,  33.926476,  33.926476, ...,  41.511917,  47.45037 ,\n",
       "           51.784477],\n",
       "         [ 33.926476,  33.926476,  33.926476, ...,  38.226547,  45.15282 ,\n",
       "           50.299217]], dtype=float32),\n",
       "  array([[91.97228 , 88.49718 , 80.079025, ..., 87.13054 , 87.555786,\n",
       "          81.278656],\n",
       "         [91.13924 , 93.52594 , 82.306595, ..., 92.18573 , 87.561455,\n",
       "          80.347176],\n",
       "         [95.11983 , 95.427704, 87.771904, ..., 91.808624, 88.62027 ,\n",
       "          86.02583 ],\n",
       "         ...,\n",
       "         [38.659233, 40.499054, 47.24563 , ..., 39.26707 , 40.917053,\n",
       "          47.899544],\n",
       "         [35.93311 , 37.711285, 42.34684 , ..., 34.691097, 34.730503,\n",
       "          41.299088],\n",
       "         [38.331238, 42.046665, 44.04294 , ..., 34.2641  , 33.651844,\n",
       "          33.482124]], dtype=float32)],\n",
       " 'age': array([0., 0., 1., 0., 0., 0.], dtype=float32),\n",
       " 'sex': array([1., 0.], dtype=float32),\n",
       " 'hw': array([103. ,  13.1], dtype=float32),\n",
       " 'preg': array([0., 1.], dtype=float32),\n",
       " 'loc': [array([1., 0., 0., 0., 0.], dtype=float32),\n",
       "  array([0., 0., 1., 0., 0.], dtype=float32),\n",
       "  array([0., 0., 0., 1., 0.], dtype=float32),\n",
       "  array([0., 1., 0., 0., 0.], dtype=float32)],\n",
       " 'murmur': array([1., 0., 0.], dtype=float32),\n",
       " 'outcome': array([1., 0.], dtype=float32)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b53e4a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9979 4 4000\\nAV 9979_AV.hea 9979_AV.wav 9979_AV.tsv\\nPV 9979_PV.hea 9979_PV.wav 9979_PV.tsv\\nTV 9979_TV.hea 9979_TV.wav 9979_TV.tsv\\nMV 9979_MV.hea 9979_MV.wav 9979_MV.tsv\\n#Age: Child\\n#Sex: Female\\n#Height: 103.0\\n#Weight: 13.1\\n#Pregnancy status: False\\n#Murmur: Present\\n#Murmur locations: AV+MV+PV+TV\\n#Most audible location: TV\\n#Systolic murmur timing: Holosystolic\\n#Systolic murmur shape: Diamond\\n#Systolic murmur grading: III/VI\\n#Systolic murmur pitch: High\\n#Systolic murmur quality: Harsh\\n#Diastolic murmur timing: nan\\n#Diastolic murmur shape: nan\\n#Diastolic murmur grading: nan\\n#Diastolic murmur pitch: nan\\n#Diastolic murmur quality: nan\\n#Outcome: Abnormal\\n#Campaign: CC2015\\n#Additional ID: nan\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4c8dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    murmur_train_model = torch.load(model_folder + '/' + 'hmd_CNN_model_40.model')\n",
    "    outcome_train_model = torch.load(model_folder + '/' + 'hmd_CNN_outcome_model_25.model')\n",
    "    return [murmur_train_model, outcome_train_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce5dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff9595a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, sys\n",
    "# from helper_code import *\n",
    "# from team_code import load_challenge_model, run_challenge_model\n",
    "\n",
    "# Run model.\n",
    "def run_model(model_folder, data_folder, output_folder, allow_failures, verbose):\n",
    "    # Load models.\n",
    "    if verbose >= 1:\n",
    "        print('Loading Challenge model...')\n",
    "\n",
    "    model = load_challenge_model(model_folder, verbose) ### Teams: Implement this function!!!\n",
    "\n",
    "    # Find the patient data files.\n",
    "    patient_files = find_patient_files(data_folder)\n",
    "    num_patient_files = len(patient_files)\n",
    "\n",
    "    if num_patient_files==0:\n",
    "        raise Exception('No data was provided.')\n",
    "\n",
    "    # Create a folder for the Challenge outputs if it does not already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Run the team's model on the Challenge data.\n",
    "    if verbose >= 1:\n",
    "        print('Running model on Challenge data...')\n",
    "\n",
    "    # Iterate over the patient files.\n",
    "    for i in range(num_patient_files):\n",
    "        if verbose >= 2:\n",
    "            print('    {}/{}...'.format(i+1, num_patient_files))\n",
    "\n",
    "        patient_data = load_patient_data(patient_files[i])\n",
    "        recordings = load_recordings(data_folder, patient_data)\n",
    "\n",
    "        # Allow or disallow the model to fail on parts of the data; helpful for debugging.\n",
    "        try:\n",
    "            classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "        except:\n",
    "            if allow_failures:\n",
    "                if verbose >= 2:\n",
    "                    print('... failed.')\n",
    "                classes, labels, probabilities = list(), list(), list()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Save Challenge outputs.\n",
    "        head, tail = os.path.split(patient_files[i])\n",
    "        root, extension = os.path.splitext(tail)\n",
    "        output_file = os.path.join(output_folder, root + '.csv')\n",
    "        patient_id = get_patient_id(patient_data)\n",
    "        save_challenge_outputs(output_file, patient_id, classes, labels, probabilities)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9605e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n",
      "    1/191...\n",
      "    2/191...\n",
      "    3/191...\n",
      "    4/191...\n",
      "    5/191...\n",
      "    6/191...\n",
      "    7/191...\n",
      "    8/191...\n",
      "    9/191...\n",
      "    10/191...\n",
      "    11/191...\n",
      "    12/191...\n",
      "    13/191...\n",
      "    14/191...\n",
      "    15/191...\n",
      "    16/191...\n",
      "    17/191...\n",
      "    18/191...\n",
      "    19/191...\n",
      "    20/191...\n",
      "    21/191...\n",
      "    22/191...\n",
      "    23/191...\n",
      "    24/191...\n",
      "    25/191...\n",
      "    26/191...\n",
      "    27/191...\n",
      "    28/191...\n",
      "    29/191...\n",
      "    30/191...\n",
      "    31/191...\n",
      "    32/191...\n",
      "    33/191...\n",
      "    34/191...\n",
      "    35/191...\n",
      "    36/191...\n",
      "    37/191...\n",
      "    38/191...\n",
      "    39/191...\n",
      "    40/191...\n",
      "    41/191...\n",
      "    42/191...\n",
      "    43/191...\n",
      "    44/191...\n",
      "    45/191...\n",
      "    46/191...\n",
      "    47/191...\n",
      "    48/191...\n",
      "    49/191...\n",
      "    50/191...\n",
      "    51/191...\n",
      "    52/191...\n",
      "    53/191...\n",
      "    54/191...\n",
      "    55/191...\n",
      "    56/191...\n",
      "    57/191...\n",
      "    58/191...\n",
      "    59/191...\n",
      "    60/191...\n",
      "    61/191...\n",
      "    62/191...\n",
      "    63/191...\n",
      "    64/191...\n",
      "    65/191...\n",
      "    66/191...\n",
      "    67/191...\n",
      "    68/191...\n",
      "    69/191...\n",
      "    70/191...\n",
      "    71/191...\n",
      "    72/191...\n",
      "    73/191...\n",
      "    74/191...\n",
      "    75/191...\n",
      "    76/191...\n",
      "    77/191...\n",
      "    78/191...\n",
      "    79/191...\n",
      "    80/191...\n",
      "    81/191...\n",
      "    82/191...\n",
      "    83/191...\n",
      "    84/191...\n",
      "    85/191...\n",
      "    86/191...\n",
      "    87/191...\n",
      "    88/191...\n",
      "    89/191...\n",
      "    90/191...\n",
      "    91/191...\n",
      "    92/191...\n",
      "    93/191...\n",
      "    94/191...\n",
      "    95/191...\n",
      "    96/191...\n",
      "    97/191...\n",
      "    98/191...\n",
      "    99/191...\n",
      "    100/191...\n",
      "    101/191...\n",
      "    102/191...\n",
      "    103/191...\n",
      "    104/191...\n",
      "    105/191...\n",
      "    106/191...\n",
      "    107/191...\n",
      "    108/191...\n",
      "    109/191...\n",
      "    110/191...\n",
      "    111/191...\n",
      "    112/191...\n",
      "    113/191...\n",
      "    114/191...\n",
      "    115/191...\n",
      "    116/191...\n",
      "    117/191...\n",
      "    118/191...\n",
      "    119/191...\n",
      "    120/191...\n",
      "    121/191...\n",
      "    122/191...\n",
      "    123/191...\n",
      "    124/191...\n",
      "    125/191...\n",
      "    126/191...\n",
      "    127/191...\n",
      "    128/191...\n",
      "    129/191...\n",
      "    130/191...\n",
      "    131/191...\n",
      "    132/191...\n",
      "    133/191...\n",
      "    134/191...\n",
      "    135/191...\n",
      "    136/191...\n",
      "    137/191...\n",
      "    138/191...\n",
      "    139/191...\n",
      "    140/191...\n",
      "    141/191...\n",
      "    142/191...\n",
      "    143/191...\n",
      "    144/191...\n",
      "    145/191...\n",
      "    146/191...\n",
      "    147/191...\n",
      "    148/191...\n",
      "    149/191...\n",
      "    150/191...\n",
      "    151/191...\n",
      "    152/191...\n",
      "    153/191...\n",
      "    154/191...\n",
      "    155/191...\n",
      "    156/191...\n",
      "    157/191...\n",
      "    158/191...\n",
      "    159/191...\n",
      "    160/191...\n",
      "    161/191...\n",
      "    162/191...\n",
      "    163/191...\n",
      "    164/191...\n",
      "    165/191...\n",
      "    166/191...\n",
      "    167/191...\n",
      "    168/191...\n",
      "    169/191...\n",
      "    170/191...\n",
      "    171/191...\n",
      "    172/191...\n",
      "    173/191...\n",
      "    174/191...\n",
      "    175/191...\n",
      "    176/191...\n",
      "    177/191...\n",
      "    178/191...\n",
      "    179/191...\n",
      "    180/191...\n",
      "    181/191...\n",
      "    182/191...\n",
      "    183/191...\n",
      "    184/191...\n",
      "    185/191...\n",
      "    186/191...\n",
      "    187/191...\n",
      "    188/191...\n",
      "    189/191...\n",
      "    190/191...\n",
      "    191/191...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run_model(args.model_path, args.valid_data_folder, args.output_folder, allow_failures=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46bbe896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(label_folder, output_folder):\n",
    "    # Define murmur and outcome classes.\n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "    # Load and parse label and model output files.\n",
    "    label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "    murmur_labels = load_murmurs(label_files, murmur_classes)\n",
    "    murmur_binary_outputs, murmur_scalar_outputs = load_classifier_outputs(output_files, murmur_classes)\n",
    "    outcome_labels = load_outcomes(label_files, outcome_classes)\n",
    "    outcome_binary_outputs, outcome_scalar_outputs = load_classifier_outputs(output_files, outcome_classes)\n",
    "\n",
    "    # For each patient, set the 'Present' or 'Abnormal' class to positive if no class is positive or if multiple classes are positive.\n",
    "    murmur_labels = enforce_positives(murmur_labels, murmur_classes, 'Present')\n",
    "    murmur_binary_outputs = enforce_positives(murmur_binary_outputs, murmur_classes, 'Present')\n",
    "    outcome_labels = enforce_positives(outcome_labels, outcome_classes, 'Abnormal')\n",
    "    outcome_binary_outputs = enforce_positives(outcome_binary_outputs, outcome_classes, 'Abnormal')\n",
    "\n",
    "    # Evaluate the murmur model by comparing the labels and model outputs.\n",
    "    murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes = compute_auc(murmur_labels, murmur_scalar_outputs)\n",
    "    murmur_f_measure, murmur_f_measure_classes = compute_f_measure(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_accuracy, murmur_accuracy_classes = compute_accuracy(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_weighted_accuracy = compute_weighted_accuracy(murmur_labels, murmur_binary_outputs, murmur_classes) # This is the murmur scoring metric.\n",
    "    murmur_cost = compute_cost(outcome_labels, murmur_binary_outputs, outcome_classes, murmur_classes) # Use *outcomes* to score *murmurs* for the Challenge cost metric, but this is not the actual murmur scoring metric.\n",
    "    murmur_scores = (murmur_classes, murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes, \\\n",
    "        murmur_f_measure, murmur_f_measure_classes, murmur_accuracy, murmur_accuracy_classes, murmur_weighted_accuracy, murmur_cost)\n",
    "\n",
    "    # Evaluate the outcome model by comparing the labels and model outputs.\n",
    "    outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes = compute_auc(outcome_labels, outcome_scalar_outputs)\n",
    "    outcome_f_measure, outcome_f_measure_classes = compute_f_measure(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_accuracy, outcome_accuracy_classes = compute_accuracy(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_weighted_accuracy = compute_weighted_accuracy(outcome_labels, outcome_binary_outputs, outcome_classes)\n",
    "    outcome_cost = compute_cost(outcome_labels, outcome_binary_outputs, outcome_classes, outcome_classes) # This is the clinical outcomes scoring metric.\n",
    "    outcome_scores = (outcome_classes, outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes, \\\n",
    "        outcome_f_measure, outcome_f_measure_classes, outcome_accuracy, outcome_accuracy_classes, outcome_weighted_accuracy, outcome_cost)\n",
    "\n",
    "    # Return the results.\n",
    "    return murmur_scores, outcome_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881fe20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79343a1f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_challenge_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18945/3539651219.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_data_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_18945/1790548728.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(label_folder, output_folder)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load and parse label and model output files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mlabel_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_challenge_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmurmur_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_murmurs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmurmur_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmurmur_binary_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmurmur_scalar_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_classifier_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmurmur_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'find_challenge_files' is not defined"
     ]
    }
   ],
   "source": [
    "evaluate_model(args.valid_data_folder, args.output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3faceb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Challenge files.\n",
    "def find_challenge_files(label_folder, output_folder):\n",
    "    label_files = list()\n",
    "    output_files = list()\n",
    "    for label_file in sorted(os.listdir(label_folder)):\n",
    "        label_file_path = os.path.join(label_folder, label_file) # Full path for label file\n",
    "        if os.path.isfile(label_file_path) and label_file.lower().endswith('.txt') and not label_file.lower().startswith('.'):\n",
    "            root, ext = os.path.splitext(label_file)\n",
    "            output_file = root + '.csv'\n",
    "            output_file_path = os.path.join(output_folder, output_file) # Full path for corresponding output file\n",
    "            if os.path.isfile(output_file_path):\n",
    "                label_files.append(label_file_path)\n",
    "                output_files.append(output_file_path)\n",
    "            else:\n",
    "                raise IOError('Output file {} not found for label file {}.'.format(output_file, label_file))\n",
    "\n",
    "    if label_files and output_files:\n",
    "        return label_files, output_files\n",
    "    else:\n",
    "        raise IOError('No label or output files found.')\n",
    "\n",
    "# Load murmurs from label files.\n",
    "def load_murmurs(label_files, classes):\n",
    "    num_patients = len(label_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the labels.\n",
    "    labels = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        data = load_patient_data(label_files[i])\n",
    "        label = get_murmur(data)\n",
    "        for j, x in enumerate(classes):\n",
    "            if compare_strings(label, x):\n",
    "                labels[i, j] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Load outcomes from label files.\n",
    "def load_outcomes(label_files, classes):\n",
    "    num_patients = len(label_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the labels.\n",
    "    labels = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        data = load_patient_data(label_files[i])\n",
    "        label = get_outcome(data)\n",
    "        for j, x in enumerate(classes):\n",
    "            if compare_strings(label, x):\n",
    "                labels[i, j] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Load outputs from output files.\n",
    "def load_classifier_outputs(output_files, classes):\n",
    "    # The outputs should have the following form:\n",
    "    #\n",
    "    # #Record ID\n",
    "    # class_1, class_2, class_3\n",
    "    #       0,       1,       1\n",
    "    #    0.12,    0.34,    0.56\n",
    "    #\n",
    "    num_patients = len(output_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the outputs.\n",
    "    binary_outputs = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "    scalar_outputs = np.zeros((num_patients, num_classes), dtype=np.float64)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        patient_id, patient_classes, patient_binary_outputs, patient_scalar_outputs = load_challenge_outputs(output_files[i])\n",
    "\n",
    "        # Allow for unordered or reordered classes.\n",
    "        for j, x in enumerate(classes):\n",
    "            for k, y in enumerate(patient_classes):\n",
    "                if compare_strings(x, y):\n",
    "                    binary_outputs[i, j] = patient_binary_outputs[k]\n",
    "                    scalar_outputs[i, j] = patient_scalar_outputs[k]\n",
    "\n",
    "    return binary_outputs, scalar_outputs\n",
    "\n",
    "# For each patient, set a specific class to positive if no class is positive or multiple classes are positive.\n",
    "def enforce_positives(outputs, classes, positive_class):\n",
    "    num_patients, num_classes = np.shape(outputs)\n",
    "    j = classes.index(positive_class)\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        if np.sum(outputs[i, :]) != 1:\n",
    "            outputs[i, :] = 0\n",
    "            outputs[i, j] = 1\n",
    "    return outputs\n",
    "\n",
    "# Compute macro AUROC and macro AUPRC.\n",
    "def compute_auc(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    # Compute and summarize the confusion matrices for each class across at distinct output values.\n",
    "    auroc = np.zeros(num_classes)\n",
    "    auprc = np.zeros(num_classes)\n",
    "\n",
    "    for k in range(num_classes):\n",
    "        # We only need to compute TPs, FPs, FNs, and TNs at distinct output values.\n",
    "        thresholds = np.unique(outputs[:, k])\n",
    "        thresholds = np.append(thresholds, thresholds[-1]+1)\n",
    "        thresholds = thresholds[::-1]\n",
    "        num_thresholds = len(thresholds)\n",
    "\n",
    "        # Initialize the TPs, FPs, FNs, and TNs.\n",
    "        tp = np.zeros(num_thresholds)\n",
    "        fp = np.zeros(num_thresholds)\n",
    "        fn = np.zeros(num_thresholds)\n",
    "        tn = np.zeros(num_thresholds)\n",
    "        fn[0] = np.sum(labels[:, k] == 1)\n",
    "        tn[0] = np.sum(labels[:, k] == 0)\n",
    "\n",
    "        # Find the indices that result in sorted output values.\n",
    "        idx = np.argsort(outputs[:, k])[::-1]\n",
    "\n",
    "        # Compute the TPs, FPs, FNs, and TNs for class k across thresholds.\n",
    "        i = 0\n",
    "        for j in range(1, num_thresholds):\n",
    "            # Initialize TPs, FPs, FNs, and TNs using values at previous threshold.\n",
    "            tp[j] = tp[j-1]\n",
    "            fp[j] = fp[j-1]\n",
    "            fn[j] = fn[j-1]\n",
    "            tn[j] = tn[j-1]\n",
    "\n",
    "            # Update the TPs, FPs, FNs, and TNs at i-th output value.\n",
    "            while i < num_patients and outputs[idx[i], k] >= thresholds[j]:\n",
    "                if labels[idx[i], k]:\n",
    "                    tp[j] += 1\n",
    "                    fn[j] -= 1\n",
    "                else:\n",
    "                    fp[j] += 1\n",
    "                    tn[j] -= 1\n",
    "                i += 1\n",
    "\n",
    "        # Summarize the TPs, FPs, FNs, and TNs for class k.\n",
    "        tpr = np.zeros(num_thresholds)\n",
    "        tnr = np.zeros(num_thresholds)\n",
    "        ppv = np.zeros(num_thresholds)\n",
    "        for j in range(num_thresholds):\n",
    "            if tp[j] + fn[j]:\n",
    "                tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n",
    "            else:\n",
    "                tpr[j] = float('nan')\n",
    "            if fp[j] + tn[j]:\n",
    "                tnr[j] = float(tn[j]) / float(fp[j] + tn[j])\n",
    "            else:\n",
    "                tnr[j] = float('nan')\n",
    "            if tp[j] + fp[j]:\n",
    "                ppv[j] = float(tp[j]) / float(tp[j] + fp[j])\n",
    "            else:\n",
    "                ppv[j] = float('nan')\n",
    "\n",
    "        # Compute AUROC as the area under a piecewise linear function with TPR/\n",
    "        # sensitivity (x-axis) and TNR/specificity (y-axis) and AUPRC as the area\n",
    "        # under a piecewise constant with TPR/recall (x-axis) and PPV/precision\n",
    "        # (y-axis) for class k.\n",
    "        for j in range(num_thresholds-1):\n",
    "            auroc[k] += 0.5 * (tpr[j+1] - tpr[j]) * (tnr[j+1] + tnr[j])\n",
    "            auprc[k] += (tpr[j+1] - tpr[j]) * ppv[j+1]\n",
    "\n",
    "    # Compute macro AUROC and macro AUPRC across classes.\n",
    "    if np.any(np.isfinite(auroc)):\n",
    "        macro_auroc = np.nanmean(auroc)\n",
    "    else:\n",
    "        macro_auroc = float('nan')\n",
    "    if np.any(np.isfinite(auprc)):\n",
    "        macro_auprc = np.nanmean(auprc)\n",
    "    else:\n",
    "        macro_auprc = float('nan')\n",
    "\n",
    "    return macro_auroc, macro_auprc, auroc, auprc\n",
    "\n",
    "# Compute a binary confusion matrix, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels)[0] == np.shape(outputs)[0])\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients = np.shape(labels)[0]\n",
    "    num_label_classes = np.shape(labels)[1]\n",
    "    num_output_classes = np.shape(outputs)[1]\n",
    "\n",
    "    A = np.zeros((num_output_classes, num_label_classes))\n",
    "    for k in range(num_patients):\n",
    "        for i in range(num_output_classes):\n",
    "            for j in range(num_label_classes):\n",
    "                if outputs[k, i] == 1 and labels[k, j] == 1:\n",
    "                    A[i, j] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute binary one-vs-rest confusion matrices, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_patients):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels, outputs)\n",
    "\n",
    "    f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(f_measure)):\n",
    "        macro_f_measure = np.nanmean(f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, f_measure\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_accuracy(labels, outputs):\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Compute accuracy.\n",
    "    if np.sum(A) > 0:\n",
    "        accuracy = np.trace(A) / np.sum(A)\n",
    "    else:\n",
    "        accuracy = float('nan')\n",
    "\n",
    "    # Compute per-class accuracy.\n",
    "    accuracy_classes = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        if np.sum(A[:, i]) > 0:\n",
    "            accuracy_classes[i] = A[i, i] / np.sum(A[:, i])\n",
    "        else:\n",
    "            accuracy_classes[i] = float('nan')\n",
    "\n",
    "    return accuracy, accuracy_classes\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_weighted_accuracy(labels, outputs, classes):\n",
    "    # Define constants.\n",
    "    if classes == ['Present', 'Unknown', 'Absent']:\n",
    "        weights = np.array([[5, 3, 1], [5, 3, 1], [5, 3, 1]])\n",
    "    elif classes == ['Abnormal', 'Normal']:\n",
    "        weights = np.array([[5, 1], [5, 1]])\n",
    "    else:\n",
    "        raise NotImplementedError('Weighted accuracy undefined for classes {}'.format(', '.join(classes)))\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Multiply the confusion matrix by the weight matrix.\n",
    "    assert(np.shape(A) == np.shape(weights))\n",
    "    B = weights * A\n",
    "\n",
    "    # Compute weighted_accuracy.\n",
    "    if np.sum(B) > 0:\n",
    "        weighted_accuracy = np.trace(B) / np.sum(B)\n",
    "    else:\n",
    "        weighted_accuracy = float('nan')\n",
    "\n",
    "    return weighted_accuracy\n",
    "\n",
    "# Define total cost for algorithmic prescreening of m patients.\n",
    "def cost_algorithm(m):\n",
    "    return 10*m\n",
    "\n",
    "# Define total cost for expert screening of m patients out of a total of n total patients.\n",
    "def cost_expert(m, n):\n",
    "    return (25 + 397*(m/n) -1718*(m/n)**2 + 11296*(m/n)**4) * n\n",
    "\n",
    "# Define total cost for treatment of m patients.\n",
    "def cost_treatment(m):\n",
    "    return 10000*m\n",
    "\n",
    "# Define total cost for missed/late treatement of m patients.\n",
    "def cost_error(m):\n",
    "    return 50000*m\n",
    "\n",
    "# Compute Challenge cost metric.\n",
    "def compute_cost(labels, outputs, label_classes, output_classes):\n",
    "    # Define positive and negative classes for referral and treatment.\n",
    "    positive_classes = ['Present', 'Unknown', 'Abnormal']\n",
    "    negative_classes = ['Absent', 'Normal']\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Identify positive and negative classes for referral.\n",
    "    idx_label_positive = [i for i, x in enumerate(label_classes) if x in positive_classes]\n",
    "    idx_label_negative = [i for i, x in enumerate(label_classes) if x in negative_classes]\n",
    "    idx_output_positive = [i for i, x in enumerate(output_classes) if x in positive_classes]\n",
    "    idx_output_negative = [i for i, x in enumerate(output_classes) if x in negative_classes]\n",
    "\n",
    "    # Identify true positives, false positives, false negatives, and true negatives.\n",
    "    tp = np.sum(A[np.ix_(idx_output_positive, idx_label_positive)])\n",
    "    fp = np.sum(A[np.ix_(idx_output_positive, idx_label_negative)])\n",
    "    fn = np.sum(A[np.ix_(idx_output_negative, idx_label_positive)])\n",
    "    tn = np.sum(A[np.ix_(idx_output_negative, idx_label_negative)])\n",
    "    total_patients = tp + fp + fn + tn\n",
    "\n",
    "    # Compute total cost for all patients.\n",
    "    total_cost = cost_algorithm(total_patients) \\\n",
    "        + cost_expert(tp + fp, total_patients) \\\n",
    "        + cost_treatment(tp) \\\n",
    "        + cost_error(fn)\n",
    "\n",
    "    # Compute mean cost per patient.\n",
    "    if total_patients > 0:\n",
    "        mean_cost = total_cost / total_patients\n",
    "    else:\n",
    "        mean_cost = float('nan')\n",
    "\n",
    "    return mean_cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55601b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.292,0.265,0.281,0.728,0.375,25689.450\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.518,0.554,0.467,0.565,0.837,12676.239\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.231,0.435,0.211\n",
      "AUPRC,0.130,0.087,0.578\n",
      "F-measure,0.000,0.000,0.842\n",
      "Accuracy,0.000,0.000,1.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.604,0.432\n",
      "AUPRC,0.601,0.507\n",
      "F-measure,0.696,0.239\n",
      "Accuracy,0.969,0.140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "murmur_scores, outcome_scores = evaluate_model(args.valid_data_folder, args.output_folder)\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "    + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "\n",
    "\n",
    "print(output_string)\n",
    "\n",
    "with open('./output_score/score,txt', 'wt') as f:\n",
    "    f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10444554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
